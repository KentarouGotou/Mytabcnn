{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23801,"status":"ok","timestamp":1648660339543,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"},"user_tz":-540},"id":"mE1PVbn3rLEQ","outputId":"ce3cf6e4-57b7-43d3-d20e-f8aaf808b434"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1648660407143,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"},"user_tz":-540},"id":"8JsWRStaYriO","outputId":"9d92d254-eff5-4b77-d9df-a01082e7d920"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Mar 30 17:13:26 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uPq7xplyrCz0","executionInfo":{"status":"ok","timestamp":1648660508291,"user_tz":-540,"elapsed":332,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["import numpy as np\n","from torch.utils.data import Dataset\n","import os\n","import torch\n","import torch.nn.functional as f\n","from torch.utils.data import DataLoader\n","\n","\n","class DataGenerator(Dataset):\n","    \n","    def __init__(self, list_IDs, data_path=\"/content/drive/MyDrive/lab/2021/MyTabCNN/data/spec_repr/\", batch_size=128, shuffle=True, label_dim = (6,21), spec_repr=\"c\", con_win_size=9):\n","        \n","        self.list_IDs = list_IDs\n","        self.data_path = data_path\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.label_dim = label_dim\n","        self.spec_repr = spec_repr\n","        self.con_win_size = con_win_size\n","        self.halfwin = con_win_size // 2\n","        \n","        if self.spec_repr == \"c\":\n","            self.X_dim = (self.batch_size, 192, self.con_win_size, 1)\n","        elif self.spec_repr == \"m\":\n","            self.X_dim = (self.batch_size, 128, self.con_win_size, 1)\n","        elif self.spec_repr == \"cm\":\n","            self.X_dim = (self.batch_size, 320, self.con_win_size, 1)\n","        elif self.spec_repr == \"s\":\n","            self.X_dim = (self.batch_size, 1025, self.con_win_size, 1)\n","            \n","        self.y_dim = (self.batch_size, self.label_dim[0], self.label_dim[1])\n","        \n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # number of batches per epoch\n","        return int(np.floor(float(len(self.list_IDs)) / self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        # generate indices of the batch(バッチごとのインデクス)\n","        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n","        \n","        # find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","        \n","        return X, y\n","    \n","    def on_epoch_end(self):\n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self, list_IDs_temp):\n","        #Generates data containing batch_size samples\n","        # X : (n_samples, *dim, n_channels)\n","        \n","        # Initialization\n","        X = np.empty(self.X_dim)\n","        y = np.empty(self.y_dim)\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            # determine filename\n","            data_dir = self.data_path + self.spec_repr + \"/\"\n","            filename = \"_\".join(ID.split(\"_\")[:-1]) + \".npz\"\n","            frame_idx = int(ID.split(\"_\")[-1])\n","            \n","            # load a context window centered around the frame index\n","            loaded = np.load(data_dir + filename)\n","            full_x = np.pad(loaded[\"repr\"], [(self.halfwin,self.halfwin), (0,0)], mode='constant')\n","            sample_x = full_x[frame_idx : frame_idx + self.con_win_size]\n","            X[i,] = np.expand_dims(np.swapaxes(sample_x, 0, 1), -1)\n","\n","            # Store label\n","            y[i,] = loaded[\"labels\"][frame_idx]\n","\n","        return X, y"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bs5q5PYOrCz7","executionInfo":{"status":"ok","timestamp":1648660513687,"user_tz":-540,"elapsed":3027,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["import datetime\n","import pandas as pd\n","\n","batch_size=128\n","epochs=8\n","con_win_size = 9\n","spec_repr=\"c\"\n","data_path=\"/content/drive/MyDrive/lab/2021/MyTabCNN/data/spec_repr/\"\n","id_file=\"id.csv\"\n","\n","csv_file = data_path + id_file\n","list_IDs = list(pd.read_csv(csv_file, header=None)[0])\n","\n","def partition_data(data_split):\n","    data_split = data_split\n","    partition = {}\n","    partition[\"training\"] = []\n","    partition[\"validation\"] = []\n","    for ID in list_IDs:\n","        guitarist = int(ID.split(\"_\")[0])\n","        if guitarist == data_split:\n","            partition[\"validation\"].append(ID)\n","        else:\n","            partition[\"training\"].append(ID)\n","    training_generator = DataGenerator(partition['training'], \n","                                            data_path=data_path, \n","                                            batch_size=batch_size, \n","                                            shuffle=True,\n","                                            spec_repr=spec_repr, \n","                                            con_win_size=con_win_size)\n","    \n","    validation_generator = DataGenerator(partition['validation'], \n","                                            data_path=data_path, \n","                                            batch_size=batch_size, \n","                                            shuffle=False,\n","                                            spec_repr=spec_repr, \n","                                            con_win_size=con_win_size)\n","    return training_generator, validation_generator\n","    "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"sDcWO8LkTr63","executionInfo":{"status":"ok","timestamp":1648660520660,"user_tz":-540,"elapsed":489,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jWDGLMk51pAl","executionInfo":{"status":"ok","timestamp":1648660521015,"user_tz":-540,"elapsed":2,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["import torch.onnx as onnx\n","import torchvision.models as models"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"56Z4Udj5o-ud","executionInfo":{"status":"ok","timestamp":1648660522870,"user_tz":-540,"elapsed":480,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["from torch.nn.modules.conv import Conv2d\n","class MyVGG(torch.nn.Module):\n","  def __init__(self):\n","    super(MyVGG, self).__init__()\n","    self.conv1 = torch.nn.Conv2d(1, 32, 3, padding=1)\n","    self.bn1 = nn.BatchNorm2d(32)\n","    self.conv2 = torch.nn.Conv2d(32, 32, 3, padding=1)\n","    self.bn2 = nn.BatchNorm2d(32)\n","    self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n","    self.bn3 = nn.BatchNorm2d(64)\n","    self.conv4 = torch.nn.Conv2d(64, 64, 3, padding=1)\n","    self.bn4 = nn.BatchNorm2d(64)\n","    self.conv5 = torch.nn.Conv2d(64, 128, 3, padding=1)\n","    self.bn5 = nn.BatchNorm2d(128)\n","    self.conv6 = torch.nn.Conv2d(128, 256, 3, padding=1)\n","    self.bn6 = nn.BatchNorm2d(256)\n","    self.conv7 = torch.nn.Conv2d(256, 256, 3, padding=1)\n","    self.bn7 = nn.BatchNorm2d(256)\n","    self.conv8 = torch.nn.Conv2d(256, 512, 3, padding=1)\n","    self.bn8 = nn.BatchNorm2d(512)\n","    self.conv9 = torch.nn.Conv2d(512, 512, 3, padding=1)\n","    self.bn9 = nn.BatchNorm2d(512)\n","    self.relu = nn.ReLU(inplace=True)\n","\n","    self.pool = torch.nn.MaxPool2d(2, 2)\n","\n","    self.drop1 = torch.nn.Dropout2d(0.25)\n","    self.drop2 = torch.nn.Dropout(0.5)\n","    self.flatten = torch.nn.Flatten()\n","\n","    self.fc1 = torch.nn.Linear(196608,128)\n","    self.fc2 = torch.nn.Linear(128,126)\n","\n","  def forward(self, x):\n","    #print(x.size())\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv3(out)\n","    out = self.bn3(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv4(out)\n","    out = self.bn4(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv5(out)\n","    out = self.bn5(out)\n","    out = self.relu(out)\n","    out = self.conv6(out)\n","    out = self.bn6(out)\n","    out = self.relu(out)\n","    out = self.conv7(out)\n","    out = self.bn7(out)\n","    out = self.relu(out)\n","    out = self.conv8(out)\n","    out = self.bn8(out)\n","    out = self.relu(out)\n","    out = self.conv9(out)\n","    out = self.bn9(out)\n","    out = self.relu(out)\n","\n","    out = self.pool(out)\n","    out = self.drop1(out)\n","    #print(out.size())\n","    out = self.flatten(out)\n","    #print(out.size())\n","    out = self.fc1(out)\n","    out = self.relu(out)\n","    out = self.fc2(out)\n","    out = torch.reshape(out, (128, 6, 21)) \n","    x_out = out\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"LrbKeEpmrCz_","outputId":"a4037adf-958e-45a4-d627-1ac23961002c"},"outputs":[{"name":"stdout","output_type":"stream","text":["training log: 0 epoch, 0/3076 loss=18.631317138671875\n","training log: 0 epoch, 10/3076 loss=11.61350154876709\n","training log: 0 epoch, 20/3076 loss=10.2649507522583\n","training log: 0 epoch, 30/3076 loss=8.926521301269531\n","training log: 0 epoch, 40/3076 loss=7.99122428894043\n","training log: 0 epoch, 50/3076 loss=7.248771667480469\n","training log: 0 epoch, 60/3076 loss=7.375607490539551\n","training log: 0 epoch, 70/3076 loss=6.954869270324707\n","training log: 0 epoch, 80/3076 loss=7.360713005065918\n","training log: 0 epoch, 90/3076 loss=5.9394211769104\n","training log: 0 epoch, 100/3076 loss=7.356283187866211\n","training log: 0 epoch, 110/3076 loss=6.256516456604004\n","training log: 0 epoch, 120/3076 loss=6.693115234375\n","training log: 0 epoch, 130/3076 loss=4.974355697631836\n","training log: 0 epoch, 140/3076 loss=5.533995151519775\n","training log: 0 epoch, 150/3076 loss=5.115541458129883\n","training log: 0 epoch, 160/3076 loss=5.194180965423584\n","training log: 0 epoch, 170/3076 loss=5.22303581237793\n","training log: 0 epoch, 180/3076 loss=6.0245819091796875\n","training log: 0 epoch, 190/3076 loss=5.16840124130249\n","training log: 0 epoch, 200/3076 loss=5.801542282104492\n","training log: 0 epoch, 210/3076 loss=4.52789306640625\n","training log: 0 epoch, 220/3076 loss=4.150794982910156\n","training log: 0 epoch, 230/3076 loss=5.006357192993164\n","training log: 0 epoch, 240/3076 loss=4.544564247131348\n","training log: 0 epoch, 250/3076 loss=4.971286773681641\n","training log: 0 epoch, 260/3076 loss=4.736966133117676\n","training log: 0 epoch, 270/3076 loss=5.014521598815918\n","training log: 0 epoch, 280/3076 loss=4.132544994354248\n","training log: 0 epoch, 290/3076 loss=4.614043235778809\n","training log: 0 epoch, 300/3076 loss=5.1389570236206055\n","training log: 0 epoch, 310/3076 loss=4.4005584716796875\n","training log: 0 epoch, 320/3076 loss=4.4048285484313965\n","training log: 0 epoch, 330/3076 loss=3.98689603805542\n","training log: 0 epoch, 340/3076 loss=3.867811441421509\n","training log: 0 epoch, 350/3076 loss=4.003584384918213\n","training log: 0 epoch, 360/3076 loss=3.6251261234283447\n","training log: 0 epoch, 370/3076 loss=3.9454402923583984\n","training log: 0 epoch, 380/3076 loss=3.6640872955322266\n","training log: 0 epoch, 390/3076 loss=3.572514295578003\n","training log: 0 epoch, 400/3076 loss=3.6906471252441406\n","training log: 0 epoch, 410/3076 loss=4.165279388427734\n","training log: 0 epoch, 420/3076 loss=3.9914116859436035\n","training log: 0 epoch, 430/3076 loss=3.1719651222229004\n","training log: 0 epoch, 440/3076 loss=3.783179998397827\n","training log: 0 epoch, 450/3076 loss=4.211324691772461\n","training log: 0 epoch, 460/3076 loss=3.846748113632202\n","training log: 0 epoch, 470/3076 loss=3.7150306701660156\n","training log: 0 epoch, 480/3076 loss=3.2471907138824463\n","training log: 0 epoch, 490/3076 loss=3.0258476734161377\n","training log: 0 epoch, 500/3076 loss=3.9236106872558594\n","training log: 0 epoch, 510/3076 loss=3.152893543243408\n","training log: 0 epoch, 520/3076 loss=3.4884345531463623\n","training log: 0 epoch, 530/3076 loss=3.86311674118042\n","training log: 0 epoch, 540/3076 loss=2.859797239303589\n","training log: 0 epoch, 550/3076 loss=3.882335662841797\n","training log: 0 epoch, 560/3076 loss=3.608929395675659\n","training log: 0 epoch, 570/3076 loss=3.110743999481201\n","training log: 0 epoch, 580/3076 loss=3.3882813453674316\n","training log: 0 epoch, 590/3076 loss=3.5470521450042725\n","training log: 0 epoch, 600/3076 loss=3.0869202613830566\n","training log: 0 epoch, 610/3076 loss=3.3449463844299316\n","training log: 0 epoch, 620/3076 loss=2.8918943405151367\n","training log: 0 epoch, 630/3076 loss=3.2104809284210205\n","training log: 0 epoch, 640/3076 loss=3.618100881576538\n","training log: 0 epoch, 650/3076 loss=3.5320565700531006\n","training log: 0 epoch, 660/3076 loss=3.3256804943084717\n","training log: 0 epoch, 670/3076 loss=3.062116861343384\n","training log: 0 epoch, 680/3076 loss=3.0935847759246826\n","training log: 0 epoch, 690/3076 loss=3.029815673828125\n","training log: 0 epoch, 700/3076 loss=3.4618489742279053\n","training log: 0 epoch, 710/3076 loss=3.04278564453125\n","training log: 0 epoch, 720/3076 loss=3.2199506759643555\n","training log: 0 epoch, 730/3076 loss=3.576434373855591\n","training log: 0 epoch, 740/3076 loss=3.383559226989746\n","training log: 0 epoch, 750/3076 loss=3.1280925273895264\n","training log: 0 epoch, 760/3076 loss=4.1927924156188965\n","training log: 0 epoch, 770/3076 loss=2.955925941467285\n","training log: 0 epoch, 780/3076 loss=3.39963960647583\n","training log: 0 epoch, 790/3076 loss=3.2096469402313232\n","training log: 0 epoch, 800/3076 loss=2.830965280532837\n","training log: 0 epoch, 810/3076 loss=3.7224693298339844\n","training log: 0 epoch, 820/3076 loss=2.9962563514709473\n","training log: 0 epoch, 830/3076 loss=3.144347667694092\n","training log: 0 epoch, 840/3076 loss=2.9936728477478027\n","training log: 0 epoch, 850/3076 loss=3.4840426445007324\n","training log: 0 epoch, 860/3076 loss=3.5015339851379395\n","training log: 0 epoch, 870/3076 loss=3.70815372467041\n","training log: 0 epoch, 880/3076 loss=3.295330762863159\n","training log: 0 epoch, 890/3076 loss=3.191878080368042\n","training log: 0 epoch, 900/3076 loss=3.113919734954834\n","training log: 0 epoch, 910/3076 loss=3.0972952842712402\n","training log: 0 epoch, 920/3076 loss=2.762779474258423\n","training log: 0 epoch, 930/3076 loss=3.295499801635742\n","training log: 0 epoch, 940/3076 loss=2.9889655113220215\n","training log: 0 epoch, 950/3076 loss=3.3222413063049316\n","training log: 0 epoch, 960/3076 loss=2.8689019680023193\n","training log: 0 epoch, 970/3076 loss=2.7535321712493896\n","training log: 0 epoch, 980/3076 loss=2.7632787227630615\n","training log: 0 epoch, 990/3076 loss=3.307183027267456\n","training log: 0 epoch, 1000/3076 loss=2.9741342067718506\n","training log: 0 epoch, 1010/3076 loss=3.053895950317383\n","training log: 0 epoch, 1020/3076 loss=3.098280191421509\n","training log: 0 epoch, 1030/3076 loss=2.691862106323242\n","training log: 0 epoch, 1040/3076 loss=2.705533742904663\n","training log: 0 epoch, 1050/3076 loss=2.564206600189209\n","training log: 0 epoch, 1060/3076 loss=3.2988638877868652\n","training log: 0 epoch, 1070/3076 loss=2.5759451389312744\n","training log: 0 epoch, 1080/3076 loss=2.6918797492980957\n","training log: 0 epoch, 1090/3076 loss=3.005479335784912\n","training log: 0 epoch, 1100/3076 loss=2.7214581966400146\n","training log: 0 epoch, 1110/3076 loss=3.062544345855713\n","training log: 0 epoch, 1120/3076 loss=3.412898302078247\n","training log: 0 epoch, 1130/3076 loss=2.971100330352783\n","training log: 0 epoch, 1140/3076 loss=3.1070642471313477\n","training log: 0 epoch, 1150/3076 loss=2.483006238937378\n","training log: 0 epoch, 1160/3076 loss=3.3305468559265137\n","training log: 0 epoch, 1170/3076 loss=3.0268971920013428\n","training log: 0 epoch, 1180/3076 loss=2.7636356353759766\n","training log: 0 epoch, 1190/3076 loss=2.682352304458618\n","training log: 0 epoch, 1200/3076 loss=2.7478411197662354\n","training log: 0 epoch, 1210/3076 loss=3.2326056957244873\n","training log: 0 epoch, 1220/3076 loss=2.793438673019409\n","training log: 0 epoch, 1230/3076 loss=2.7576279640197754\n","training log: 0 epoch, 1240/3076 loss=3.297926187515259\n","training log: 0 epoch, 1250/3076 loss=2.7371020317077637\n","training log: 0 epoch, 1260/3076 loss=2.8806440830230713\n","training log: 0 epoch, 1270/3076 loss=2.7219014167785645\n","training log: 0 epoch, 1280/3076 loss=2.8848953247070312\n","training log: 0 epoch, 1290/3076 loss=2.668107271194458\n","training log: 0 epoch, 1300/3076 loss=2.8944225311279297\n","training log: 0 epoch, 1310/3076 loss=2.8927056789398193\n","training log: 0 epoch, 1320/3076 loss=2.626521110534668\n","training log: 0 epoch, 1330/3076 loss=2.651348114013672\n","training log: 0 epoch, 1340/3076 loss=2.909348964691162\n","training log: 0 epoch, 1350/3076 loss=2.6740951538085938\n","training log: 0 epoch, 1360/3076 loss=2.849395513534546\n","training log: 0 epoch, 1370/3076 loss=2.5442590713500977\n","training log: 0 epoch, 1380/3076 loss=2.8419992923736572\n","training log: 0 epoch, 1390/3076 loss=2.873138666152954\n","training log: 0 epoch, 1400/3076 loss=2.766057014465332\n","training log: 0 epoch, 1410/3076 loss=2.665351390838623\n","training log: 0 epoch, 1420/3076 loss=2.5992836952209473\n","training log: 0 epoch, 1430/3076 loss=2.578052043914795\n","training log: 0 epoch, 1440/3076 loss=2.6918563842773438\n","training log: 0 epoch, 1450/3076 loss=2.503202438354492\n","training log: 0 epoch, 1460/3076 loss=3.4823076725006104\n","training log: 0 epoch, 1470/3076 loss=2.8049280643463135\n","training log: 0 epoch, 1480/3076 loss=3.351067304611206\n","training log: 0 epoch, 1490/3076 loss=2.994169235229492\n","training log: 0 epoch, 1500/3076 loss=2.6919729709625244\n","training log: 0 epoch, 1510/3076 loss=2.2154338359832764\n","training log: 0 epoch, 1520/3076 loss=3.088168144226074\n","training log: 0 epoch, 1530/3076 loss=2.4762842655181885\n","training log: 0 epoch, 1540/3076 loss=2.9825024604797363\n","training log: 0 epoch, 1550/3076 loss=2.658299446105957\n","training log: 0 epoch, 1560/3076 loss=2.8031766414642334\n","training log: 0 epoch, 1570/3076 loss=2.68898868560791\n","training log: 0 epoch, 1580/3076 loss=2.7482874393463135\n","training log: 0 epoch, 1590/3076 loss=2.7816238403320312\n","training log: 0 epoch, 1600/3076 loss=2.524653196334839\n","training log: 0 epoch, 1610/3076 loss=2.691943883895874\n","training log: 0 epoch, 1620/3076 loss=3.0859687328338623\n","training log: 0 epoch, 1630/3076 loss=3.0925841331481934\n","training log: 0 epoch, 1640/3076 loss=2.785303831100464\n","training log: 0 epoch, 1650/3076 loss=3.162116527557373\n","training log: 0 epoch, 1660/3076 loss=3.065321683883667\n","training log: 0 epoch, 1670/3076 loss=2.520820140838623\n","training log: 0 epoch, 1680/3076 loss=2.731889247894287\n","training log: 0 epoch, 1690/3076 loss=2.958505868911743\n","training log: 0 epoch, 1700/3076 loss=2.973196268081665\n","training log: 0 epoch, 1710/3076 loss=2.774852991104126\n","training log: 0 epoch, 1720/3076 loss=2.8387341499328613\n","training log: 0 epoch, 1730/3076 loss=2.7681658267974854\n","training log: 0 epoch, 1740/3076 loss=2.7312309741973877\n","training log: 0 epoch, 1750/3076 loss=2.5029211044311523\n","training log: 0 epoch, 1760/3076 loss=2.3611533641815186\n","training log: 0 epoch, 1770/3076 loss=2.351728916168213\n","training log: 0 epoch, 1780/3076 loss=2.781827688217163\n","training log: 0 epoch, 1790/3076 loss=2.936420202255249\n","training log: 0 epoch, 1800/3076 loss=2.701838970184326\n","training log: 0 epoch, 1810/3076 loss=2.2520065307617188\n","training log: 0 epoch, 1820/3076 loss=3.002368927001953\n","training log: 0 epoch, 1830/3076 loss=2.6979563236236572\n","training log: 0 epoch, 1840/3076 loss=2.578545331954956\n","training log: 0 epoch, 1850/3076 loss=2.3861801624298096\n","training log: 0 epoch, 1860/3076 loss=2.7526049613952637\n","training log: 0 epoch, 1870/3076 loss=2.465733528137207\n","training log: 0 epoch, 1880/3076 loss=2.894193172454834\n","training log: 0 epoch, 1890/3076 loss=2.1502134799957275\n","training log: 0 epoch, 1900/3076 loss=2.2568295001983643\n","training log: 0 epoch, 1910/3076 loss=2.7351722717285156\n","training log: 0 epoch, 1920/3076 loss=2.38472318649292\n","training log: 0 epoch, 1930/3076 loss=2.8463356494903564\n","training log: 0 epoch, 1940/3076 loss=2.8041062355041504\n","training log: 0 epoch, 1950/3076 loss=2.558621883392334\n","training log: 0 epoch, 1960/3076 loss=2.312673568725586\n","training log: 0 epoch, 1970/3076 loss=2.7635648250579834\n","training log: 0 epoch, 1980/3076 loss=2.9210634231567383\n","training log: 0 epoch, 1990/3076 loss=2.852141857147217\n","training log: 0 epoch, 2000/3076 loss=2.6728992462158203\n","training log: 0 epoch, 2010/3076 loss=2.591586112976074\n","training log: 0 epoch, 2020/3076 loss=2.6372427940368652\n","training log: 0 epoch, 2030/3076 loss=2.427854299545288\n","training log: 0 epoch, 2040/3076 loss=2.8457388877868652\n","training log: 0 epoch, 2050/3076 loss=2.6277642250061035\n","training log: 0 epoch, 2060/3076 loss=2.243375539779663\n","training log: 0 epoch, 2070/3076 loss=2.344027519226074\n","training log: 0 epoch, 2080/3076 loss=2.6336450576782227\n","training log: 0 epoch, 2090/3076 loss=2.7050554752349854\n","training log: 0 epoch, 2100/3076 loss=2.667311906814575\n","training log: 0 epoch, 2110/3076 loss=2.129185676574707\n","training log: 0 epoch, 2120/3076 loss=2.648242235183716\n","training log: 0 epoch, 2130/3076 loss=2.4310595989227295\n","training log: 0 epoch, 2140/3076 loss=2.870819330215454\n","training log: 0 epoch, 2150/3076 loss=2.4406559467315674\n","training log: 0 epoch, 2160/3076 loss=2.1233232021331787\n","training log: 0 epoch, 2170/3076 loss=2.2009377479553223\n","training log: 0 epoch, 2180/3076 loss=2.521465301513672\n","training log: 0 epoch, 2190/3076 loss=2.711350202560425\n","training log: 0 epoch, 2200/3076 loss=2.19853138923645\n","training log: 0 epoch, 2210/3076 loss=1.8311798572540283\n","training log: 0 epoch, 2220/3076 loss=2.3410465717315674\n","training log: 0 epoch, 2230/3076 loss=2.264772415161133\n","training log: 0 epoch, 2240/3076 loss=2.4161593914031982\n","training log: 0 epoch, 2250/3076 loss=2.522688865661621\n","training log: 0 epoch, 2260/3076 loss=2.179048776626587\n","training log: 0 epoch, 2270/3076 loss=2.4037861824035645\n","training log: 0 epoch, 2280/3076 loss=2.6863646507263184\n","training log: 0 epoch, 2290/3076 loss=2.2633113861083984\n","training log: 0 epoch, 2300/3076 loss=2.392080307006836\n","training log: 0 epoch, 2310/3076 loss=1.6924952268600464\n","training log: 0 epoch, 2320/3076 loss=2.711355686187744\n","training log: 0 epoch, 2330/3076 loss=2.186338424682617\n","training log: 0 epoch, 2340/3076 loss=2.8495211601257324\n","training log: 0 epoch, 2350/3076 loss=2.2934107780456543\n","training log: 0 epoch, 2360/3076 loss=2.559164524078369\n","training log: 0 epoch, 2370/3076 loss=2.062978506088257\n","training log: 0 epoch, 2380/3076 loss=2.5775113105773926\n","training log: 0 epoch, 2390/3076 loss=2.5488219261169434\n","training log: 0 epoch, 2400/3076 loss=2.1515209674835205\n","training log: 0 epoch, 2410/3076 loss=2.549410820007324\n","training log: 0 epoch, 2420/3076 loss=2.796093702316284\n","training log: 0 epoch, 2430/3076 loss=2.125836133956909\n","training log: 0 epoch, 2440/3076 loss=2.519648790359497\n","training log: 0 epoch, 2450/3076 loss=1.9068583250045776\n","training log: 0 epoch, 2460/3076 loss=2.2414934635162354\n","training log: 0 epoch, 2470/3076 loss=2.637831687927246\n","training log: 0 epoch, 2480/3076 loss=1.9222567081451416\n","training log: 0 epoch, 2490/3076 loss=2.489401340484619\n","training log: 0 epoch, 2500/3076 loss=2.213078260421753\n","training log: 0 epoch, 2510/3076 loss=2.001268148422241\n","training log: 0 epoch, 2520/3076 loss=1.9682378768920898\n","training log: 0 epoch, 2530/3076 loss=2.4105045795440674\n","training log: 0 epoch, 2540/3076 loss=2.3572278022766113\n","training log: 0 epoch, 2550/3076 loss=2.243565320968628\n","training log: 0 epoch, 2560/3076 loss=2.348299026489258\n","training log: 0 epoch, 2570/3076 loss=2.184830665588379\n","training log: 0 epoch, 2580/3076 loss=2.056722640991211\n","training log: 0 epoch, 2590/3076 loss=2.3954739570617676\n","training log: 0 epoch, 2600/3076 loss=2.3880133628845215\n","training log: 0 epoch, 2610/3076 loss=2.2102415561676025\n","training log: 0 epoch, 2620/3076 loss=2.23551869392395\n","training log: 0 epoch, 2630/3076 loss=2.5700995922088623\n","training log: 0 epoch, 2640/3076 loss=2.41522479057312\n","training log: 0 epoch, 2650/3076 loss=2.7933685779571533\n","training log: 0 epoch, 2660/3076 loss=2.3886919021606445\n","training log: 0 epoch, 2670/3076 loss=2.178402900695801\n","training log: 0 epoch, 2680/3076 loss=1.9875856637954712\n","training log: 0 epoch, 2690/3076 loss=2.430011510848999\n","training log: 0 epoch, 2700/3076 loss=2.1611294746398926\n","training log: 0 epoch, 2710/3076 loss=3.193410634994507\n","training log: 0 epoch, 2720/3076 loss=2.3589115142822266\n","training log: 0 epoch, 2730/3076 loss=2.4696528911590576\n","training log: 0 epoch, 2740/3076 loss=2.563023567199707\n","training log: 0 epoch, 2750/3076 loss=2.306819200515747\n","training log: 0 epoch, 2760/3076 loss=2.4559249877929688\n","training log: 0 epoch, 2770/3076 loss=2.1847541332244873\n","training log: 0 epoch, 2780/3076 loss=2.471203565597534\n","training log: 0 epoch, 2790/3076 loss=2.6405718326568604\n","training log: 0 epoch, 2800/3076 loss=2.5954012870788574\n","training log: 0 epoch, 2810/3076 loss=1.9674091339111328\n","training log: 0 epoch, 2820/3076 loss=2.307049512863159\n","training log: 0 epoch, 2830/3076 loss=2.450000762939453\n","training log: 0 epoch, 2840/3076 loss=2.1116316318511963\n","training log: 0 epoch, 2850/3076 loss=2.134247064590454\n","training log: 0 epoch, 2860/3076 loss=2.3031165599823\n","training log: 0 epoch, 2870/3076 loss=2.0993552207946777\n","training log: 0 epoch, 2880/3076 loss=2.0821661949157715\n","training log: 0 epoch, 2890/3076 loss=2.095163345336914\n","training log: 0 epoch, 2900/3076 loss=2.7819888591766357\n","training log: 0 epoch, 2910/3076 loss=2.293067455291748\n","training log: 0 epoch, 2920/3076 loss=2.596061944961548\n","training log: 0 epoch, 2930/3076 loss=2.556335687637329\n","training log: 0 epoch, 2940/3076 loss=2.4529905319213867\n","training log: 0 epoch, 2950/3076 loss=1.9770022630691528\n","training log: 0 epoch, 2960/3076 loss=1.9333609342575073\n","training log: 0 epoch, 2970/3076 loss=2.275407314300537\n","training log: 0 epoch, 2980/3076 loss=2.25219464302063\n","training log: 0 epoch, 2990/3076 loss=2.3901026248931885\n","training log: 0 epoch, 3000/3076 loss=2.1306140422821045\n","training log: 0 epoch, 3010/3076 loss=2.4180052280426025\n","training log: 0 epoch, 3020/3076 loss=2.054279327392578\n","training log: 0 epoch, 3030/3076 loss=2.4228880405426025\n","training log: 0 epoch, 3040/3076 loss=2.403083324432373\n","training log: 0 epoch, 3050/3076 loss=2.1179957389831543\n","training log: 0 epoch, 3060/3076 loss=2.504387617111206\n","training log: 0 epoch, 3070/3076 loss=2.4775421619415283\n","training log: 1 epoch, 0/3076 loss=2.649858236312866\n","training log: 1 epoch, 10/3076 loss=2.0398969650268555\n","training log: 1 epoch, 20/3076 loss=1.852761149406433\n","training log: 1 epoch, 30/3076 loss=1.9422670602798462\n","training log: 1 epoch, 40/3076 loss=2.1659469604492188\n","training log: 1 epoch, 50/3076 loss=2.5787789821624756\n","training log: 1 epoch, 60/3076 loss=2.0122501850128174\n","training log: 1 epoch, 70/3076 loss=2.2442259788513184\n","training log: 1 epoch, 80/3076 loss=2.0500996112823486\n","training log: 1 epoch, 90/3076 loss=2.14385724067688\n","training log: 1 epoch, 100/3076 loss=2.2485570907592773\n","training log: 1 epoch, 110/3076 loss=2.219026565551758\n","training log: 1 epoch, 120/3076 loss=2.4759678840637207\n","training log: 1 epoch, 130/3076 loss=2.01899790763855\n","training log: 1 epoch, 140/3076 loss=2.0730252265930176\n","training log: 1 epoch, 150/3076 loss=2.181464195251465\n","training log: 1 epoch, 160/3076 loss=2.263639450073242\n","training log: 1 epoch, 170/3076 loss=2.156669855117798\n","training log: 1 epoch, 180/3076 loss=1.8918505907058716\n","training log: 1 epoch, 190/3076 loss=1.8108127117156982\n","training log: 1 epoch, 200/3076 loss=2.1832168102264404\n","training log: 1 epoch, 210/3076 loss=2.289241075515747\n","training log: 1 epoch, 220/3076 loss=2.212083339691162\n","training log: 1 epoch, 230/3076 loss=2.2336325645446777\n","training log: 1 epoch, 240/3076 loss=1.8655999898910522\n","training log: 1 epoch, 250/3076 loss=2.3917386531829834\n","training log: 1 epoch, 260/3076 loss=2.387896776199341\n","training log: 1 epoch, 270/3076 loss=1.6834943294525146\n","training log: 1 epoch, 280/3076 loss=2.4507343769073486\n","training log: 1 epoch, 290/3076 loss=2.25252103805542\n","training log: 1 epoch, 300/3076 loss=2.200971841812134\n","training log: 1 epoch, 310/3076 loss=2.3746140003204346\n","training log: 1 epoch, 320/3076 loss=1.954698085784912\n","training log: 1 epoch, 330/3076 loss=2.045255422592163\n","training log: 1 epoch, 340/3076 loss=2.4071061611175537\n","training log: 1 epoch, 350/3076 loss=2.119410276412964\n","training log: 1 epoch, 360/3076 loss=2.1102304458618164\n","training log: 1 epoch, 370/3076 loss=2.1270477771759033\n","training log: 1 epoch, 380/3076 loss=1.7238521575927734\n","training log: 1 epoch, 390/3076 loss=2.5062220096588135\n","training log: 1 epoch, 400/3076 loss=2.6271181106567383\n","training log: 1 epoch, 410/3076 loss=2.2267587184906006\n","training log: 1 epoch, 420/3076 loss=2.031285047531128\n","training log: 1 epoch, 430/3076 loss=2.2304489612579346\n","training log: 1 epoch, 440/3076 loss=2.3279788494110107\n","training log: 1 epoch, 450/3076 loss=2.660487651824951\n","training log: 1 epoch, 460/3076 loss=2.258876085281372\n","training log: 1 epoch, 470/3076 loss=2.084972858428955\n","training log: 1 epoch, 480/3076 loss=1.896381139755249\n","training log: 1 epoch, 490/3076 loss=2.2427291870117188\n","training log: 1 epoch, 500/3076 loss=2.255547285079956\n","training log: 1 epoch, 510/3076 loss=2.7331714630126953\n","training log: 1 epoch, 520/3076 loss=2.3309924602508545\n","training log: 1 epoch, 530/3076 loss=2.0216095447540283\n","training log: 1 epoch, 540/3076 loss=2.691438674926758\n","training log: 1 epoch, 550/3076 loss=2.0983498096466064\n","training log: 1 epoch, 560/3076 loss=1.987513542175293\n","training log: 1 epoch, 570/3076 loss=2.3268229961395264\n","training log: 1 epoch, 580/3076 loss=1.8468008041381836\n","training log: 1 epoch, 590/3076 loss=1.8299446105957031\n","training log: 1 epoch, 600/3076 loss=1.9700543880462646\n","training log: 1 epoch, 610/3076 loss=2.0169286727905273\n","training log: 1 epoch, 620/3076 loss=1.7463029623031616\n","training log: 1 epoch, 630/3076 loss=2.6886658668518066\n","training log: 1 epoch, 640/3076 loss=2.002349376678467\n","training log: 1 epoch, 650/3076 loss=2.836426019668579\n","training log: 1 epoch, 660/3076 loss=2.215653896331787\n","training log: 1 epoch, 670/3076 loss=1.759749412536621\n","training log: 1 epoch, 680/3076 loss=2.2462480068206787\n","training log: 1 epoch, 690/3076 loss=2.3722152709960938\n","training log: 1 epoch, 700/3076 loss=2.3666486740112305\n","training log: 1 epoch, 710/3076 loss=2.378020763397217\n","training log: 1 epoch, 720/3076 loss=1.86732017993927\n","training log: 1 epoch, 730/3076 loss=1.9543453454971313\n","training log: 1 epoch, 740/3076 loss=2.00223970413208\n","training log: 1 epoch, 750/3076 loss=2.4266202449798584\n","training log: 1 epoch, 760/3076 loss=2.053647756576538\n","training log: 1 epoch, 770/3076 loss=2.2475154399871826\n","training log: 1 epoch, 780/3076 loss=2.0161068439483643\n","training log: 1 epoch, 790/3076 loss=2.038562774658203\n","training log: 1 epoch, 800/3076 loss=2.046671152114868\n","training log: 1 epoch, 810/3076 loss=1.8976542949676514\n","training log: 1 epoch, 820/3076 loss=2.3014798164367676\n","training log: 1 epoch, 830/3076 loss=2.6288113594055176\n","training log: 1 epoch, 840/3076 loss=2.0703961849212646\n","training log: 1 epoch, 850/3076 loss=1.9628556966781616\n","training log: 1 epoch, 860/3076 loss=1.8767685890197754\n","training log: 1 epoch, 870/3076 loss=2.24902081489563\n","training log: 1 epoch, 880/3076 loss=2.1108343601226807\n","training log: 1 epoch, 890/3076 loss=1.933682918548584\n","training log: 1 epoch, 900/3076 loss=1.8525404930114746\n","training log: 1 epoch, 910/3076 loss=2.1188111305236816\n","training log: 1 epoch, 920/3076 loss=2.4079205989837646\n","training log: 1 epoch, 930/3076 loss=1.8697491884231567\n","training log: 1 epoch, 940/3076 loss=1.902410626411438\n","training log: 1 epoch, 950/3076 loss=2.2143683433532715\n","training log: 1 epoch, 960/3076 loss=2.250404119491577\n","training log: 1 epoch, 970/3076 loss=2.583366870880127\n","training log: 1 epoch, 980/3076 loss=1.909641981124878\n","training log: 1 epoch, 990/3076 loss=1.719569206237793\n","training log: 1 epoch, 1000/3076 loss=2.2727670669555664\n","training log: 1 epoch, 1010/3076 loss=2.4792728424072266\n","training log: 1 epoch, 1020/3076 loss=2.354018211364746\n","training log: 1 epoch, 1030/3076 loss=2.0903992652893066\n","training log: 1 epoch, 1040/3076 loss=2.141474723815918\n","training log: 1 epoch, 1050/3076 loss=2.0798416137695312\n","training log: 1 epoch, 1060/3076 loss=1.783476710319519\n","training log: 1 epoch, 1070/3076 loss=2.4307119846343994\n","training log: 1 epoch, 1080/3076 loss=2.265122413635254\n","training log: 1 epoch, 1090/3076 loss=2.412142515182495\n","training log: 1 epoch, 1100/3076 loss=1.8732820749282837\n","training log: 1 epoch, 1110/3076 loss=2.164069414138794\n","training log: 1 epoch, 1120/3076 loss=1.812462329864502\n","training log: 1 epoch, 1130/3076 loss=2.402315139770508\n","training log: 1 epoch, 1140/3076 loss=1.9948076009750366\n","training log: 1 epoch, 1150/3076 loss=2.0621700286865234\n","training log: 1 epoch, 1160/3076 loss=1.812887191772461\n","training log: 1 epoch, 1170/3076 loss=2.1764354705810547\n","training log: 1 epoch, 1180/3076 loss=1.9075335264205933\n","training log: 1 epoch, 1190/3076 loss=2.33127760887146\n","training log: 1 epoch, 1200/3076 loss=2.1023123264312744\n","training log: 1 epoch, 1210/3076 loss=2.095154047012329\n","training log: 1 epoch, 1220/3076 loss=2.1297807693481445\n","training log: 1 epoch, 1230/3076 loss=2.434072971343994\n","training log: 1 epoch, 1240/3076 loss=2.0339725017547607\n","training log: 1 epoch, 1250/3076 loss=1.9952119588851929\n","training log: 1 epoch, 1260/3076 loss=2.244309186935425\n","training log: 1 epoch, 1270/3076 loss=1.697061538696289\n","training log: 1 epoch, 1280/3076 loss=2.0640347003936768\n","training log: 1 epoch, 1290/3076 loss=2.36724853515625\n","training log: 1 epoch, 1300/3076 loss=2.1325297355651855\n","training log: 1 epoch, 1310/3076 loss=2.166266679763794\n","training log: 1 epoch, 1320/3076 loss=2.067317008972168\n","training log: 1 epoch, 1330/3076 loss=2.230409860610962\n","training log: 1 epoch, 1340/3076 loss=2.0693142414093018\n","training log: 1 epoch, 1350/3076 loss=2.0986366271972656\n","training log: 1 epoch, 1360/3076 loss=2.13096284866333\n","training log: 1 epoch, 1370/3076 loss=2.0358669757843018\n","training log: 1 epoch, 1380/3076 loss=2.378718376159668\n","training log: 1 epoch, 1390/3076 loss=2.01955509185791\n","training log: 1 epoch, 1400/3076 loss=2.445221424102783\n","training log: 1 epoch, 1410/3076 loss=1.8314534425735474\n","training log: 1 epoch, 1420/3076 loss=2.088789463043213\n","training log: 1 epoch, 1430/3076 loss=2.2046661376953125\n","training log: 1 epoch, 1440/3076 loss=1.6845097541809082\n","training log: 1 epoch, 1450/3076 loss=2.2403032779693604\n","training log: 1 epoch, 1460/3076 loss=1.8550480604171753\n","training log: 1 epoch, 1470/3076 loss=2.0793378353118896\n","training log: 1 epoch, 1480/3076 loss=2.220019817352295\n","training log: 1 epoch, 1490/3076 loss=2.0437698364257812\n","training log: 1 epoch, 1500/3076 loss=1.995517611503601\n","training log: 1 epoch, 1510/3076 loss=2.127866744995117\n","training log: 1 epoch, 1520/3076 loss=1.8982762098312378\n","training log: 1 epoch, 1530/3076 loss=2.0774741172790527\n","training log: 1 epoch, 1540/3076 loss=1.9066082239151\n","training log: 1 epoch, 1550/3076 loss=1.8245905637741089\n","training log: 1 epoch, 1560/3076 loss=1.9887149333953857\n","training log: 1 epoch, 1570/3076 loss=2.2277960777282715\n","training log: 1 epoch, 1580/3076 loss=2.079782009124756\n","training log: 1 epoch, 1590/3076 loss=1.980839490890503\n","training log: 1 epoch, 1600/3076 loss=2.1966965198516846\n","training log: 1 epoch, 1610/3076 loss=1.9679656028747559\n","training log: 1 epoch, 1620/3076 loss=2.1522610187530518\n","training log: 1 epoch, 1630/3076 loss=1.9255945682525635\n","training log: 1 epoch, 1640/3076 loss=1.7296299934387207\n","training log: 1 epoch, 1650/3076 loss=1.8689721822738647\n","training log: 1 epoch, 1660/3076 loss=1.868844985961914\n","training log: 1 epoch, 1670/3076 loss=2.0275306701660156\n","training log: 1 epoch, 1680/3076 loss=1.852512240409851\n","training log: 1 epoch, 1690/3076 loss=2.2223939895629883\n","training log: 1 epoch, 1700/3076 loss=2.0810892581939697\n","training log: 1 epoch, 1710/3076 loss=1.6592860221862793\n","training log: 1 epoch, 1720/3076 loss=1.8588371276855469\n","training log: 1 epoch, 1730/3076 loss=1.8793022632598877\n","training log: 1 epoch, 1740/3076 loss=2.0083837509155273\n","training log: 1 epoch, 1750/3076 loss=2.1419942378997803\n","training log: 1 epoch, 1760/3076 loss=1.782540202140808\n","training log: 1 epoch, 1770/3076 loss=2.031721591949463\n","training log: 1 epoch, 1780/3076 loss=2.1149561405181885\n","training log: 1 epoch, 1790/3076 loss=2.819675922393799\n","training log: 1 epoch, 1800/3076 loss=1.8663225173950195\n","training log: 1 epoch, 1810/3076 loss=1.7477073669433594\n","training log: 1 epoch, 1820/3076 loss=1.648837924003601\n","training log: 1 epoch, 1830/3076 loss=1.9606781005859375\n","training log: 1 epoch, 1840/3076 loss=1.5267713069915771\n","training log: 1 epoch, 1850/3076 loss=1.9217565059661865\n","training log: 1 epoch, 1860/3076 loss=2.007519245147705\n","training log: 1 epoch, 1870/3076 loss=1.819130301475525\n","training log: 1 epoch, 1880/3076 loss=2.0863895416259766\n","training log: 1 epoch, 1890/3076 loss=2.0996620655059814\n","training log: 1 epoch, 1900/3076 loss=1.7742412090301514\n","training log: 1 epoch, 1910/3076 loss=2.076976776123047\n","training log: 1 epoch, 1920/3076 loss=2.094895839691162\n","training log: 1 epoch, 1930/3076 loss=1.8470054864883423\n","training log: 1 epoch, 1940/3076 loss=1.638865351676941\n","training log: 1 epoch, 1950/3076 loss=2.0099735260009766\n","training log: 1 epoch, 1960/3076 loss=2.2888455390930176\n","training log: 1 epoch, 1970/3076 loss=1.7061774730682373\n","training log: 1 epoch, 1980/3076 loss=1.6564593315124512\n","training log: 1 epoch, 1990/3076 loss=1.8741981983184814\n","training log: 1 epoch, 2000/3076 loss=2.1558303833007812\n","training log: 1 epoch, 2010/3076 loss=2.218744993209839\n","training log: 1 epoch, 2020/3076 loss=1.8331716060638428\n","training log: 1 epoch, 2030/3076 loss=2.1570937633514404\n","training log: 1 epoch, 2040/3076 loss=1.4360849857330322\n","training log: 1 epoch, 2050/3076 loss=1.7174935340881348\n","training log: 1 epoch, 2060/3076 loss=2.1574034690856934\n","training log: 1 epoch, 2070/3076 loss=2.359262704849243\n","training log: 1 epoch, 2080/3076 loss=1.7753925323486328\n","training log: 1 epoch, 2090/3076 loss=1.8909984827041626\n","training log: 1 epoch, 2100/3076 loss=1.5971453189849854\n","training log: 1 epoch, 2110/3076 loss=2.0273544788360596\n","training log: 1 epoch, 2120/3076 loss=2.6046242713928223\n","training log: 1 epoch, 2130/3076 loss=2.096083164215088\n","training log: 1 epoch, 2140/3076 loss=2.102860450744629\n","training log: 1 epoch, 2150/3076 loss=1.9738974571228027\n","training log: 1 epoch, 2160/3076 loss=1.826403021812439\n","training log: 1 epoch, 2170/3076 loss=2.1741302013397217\n","training log: 1 epoch, 2180/3076 loss=2.0846822261810303\n","training log: 1 epoch, 2190/3076 loss=2.0522804260253906\n","training log: 1 epoch, 2200/3076 loss=2.007237672805786\n","training log: 1 epoch, 2210/3076 loss=1.8566418886184692\n","training log: 1 epoch, 2220/3076 loss=1.9812674522399902\n","training log: 1 epoch, 2230/3076 loss=2.1415090560913086\n","training log: 1 epoch, 2240/3076 loss=2.1319265365600586\n","training log: 1 epoch, 2250/3076 loss=1.8296266794204712\n","training log: 1 epoch, 2260/3076 loss=1.821007251739502\n","training log: 1 epoch, 2270/3076 loss=1.6314483880996704\n","training log: 1 epoch, 2280/3076 loss=1.9312400817871094\n","training log: 1 epoch, 2290/3076 loss=2.112046003341675\n","training log: 1 epoch, 2300/3076 loss=1.982805609703064\n","training log: 1 epoch, 2310/3076 loss=2.407996892929077\n","training log: 1 epoch, 2320/3076 loss=1.7327228784561157\n","training log: 1 epoch, 2330/3076 loss=1.7817336320877075\n","training log: 1 epoch, 2340/3076 loss=2.3570187091827393\n","training log: 1 epoch, 2350/3076 loss=2.3255186080932617\n","training log: 1 epoch, 2360/3076 loss=2.0614521503448486\n","training log: 1 epoch, 2370/3076 loss=1.9712989330291748\n","training log: 1 epoch, 2380/3076 loss=2.0701208114624023\n","training log: 1 epoch, 2390/3076 loss=1.8632413148880005\n","training log: 1 epoch, 2400/3076 loss=1.6728354692459106\n","training log: 1 epoch, 2410/3076 loss=1.9740599393844604\n","training log: 1 epoch, 2420/3076 loss=1.7484685182571411\n","training log: 1 epoch, 2430/3076 loss=2.306603193283081\n","training log: 1 epoch, 2440/3076 loss=1.6680454015731812\n","training log: 1 epoch, 2450/3076 loss=1.654589295387268\n","training log: 1 epoch, 2460/3076 loss=1.7784878015518188\n","training log: 1 epoch, 2470/3076 loss=1.8662323951721191\n","training log: 1 epoch, 2480/3076 loss=1.863662838935852\n","training log: 1 epoch, 2490/3076 loss=2.332496404647827\n","training log: 1 epoch, 2500/3076 loss=1.8843261003494263\n","training log: 1 epoch, 2510/3076 loss=2.0479323863983154\n","training log: 1 epoch, 2520/3076 loss=1.95787513256073\n","training log: 1 epoch, 2530/3076 loss=1.6830939054489136\n","training log: 1 epoch, 2540/3076 loss=1.801347255706787\n","training log: 1 epoch, 2550/3076 loss=1.7514318227767944\n","training log: 1 epoch, 2560/3076 loss=1.810538649559021\n","training log: 1 epoch, 2570/3076 loss=1.5667258501052856\n","training log: 1 epoch, 2580/3076 loss=2.205063581466675\n","training log: 1 epoch, 2590/3076 loss=2.3262879848480225\n","training log: 1 epoch, 2600/3076 loss=2.005566358566284\n","training log: 1 epoch, 2610/3076 loss=1.9915119409561157\n","training log: 1 epoch, 2620/3076 loss=1.6014397144317627\n","training log: 1 epoch, 2630/3076 loss=1.4343136548995972\n","training log: 1 epoch, 2640/3076 loss=1.6455094814300537\n","training log: 1 epoch, 2650/3076 loss=2.1251800060272217\n","training log: 1 epoch, 2660/3076 loss=2.03584361076355\n","training log: 1 epoch, 2670/3076 loss=1.626950979232788\n","training log: 1 epoch, 2680/3076 loss=1.7884999513626099\n","training log: 1 epoch, 2690/3076 loss=1.5674749612808228\n","training log: 1 epoch, 2700/3076 loss=1.9543133974075317\n","training log: 1 epoch, 2710/3076 loss=1.853598713874817\n","training log: 1 epoch, 2720/3076 loss=2.0311834812164307\n","training log: 1 epoch, 2730/3076 loss=1.9205683469772339\n","training log: 1 epoch, 2740/3076 loss=1.7583812475204468\n","training log: 1 epoch, 2750/3076 loss=1.9233729839324951\n","training log: 1 epoch, 2760/3076 loss=1.673035740852356\n","training log: 1 epoch, 2770/3076 loss=1.899361252784729\n","training log: 1 epoch, 2780/3076 loss=1.6575607061386108\n","training log: 1 epoch, 2790/3076 loss=1.6934096813201904\n","training log: 1 epoch, 2800/3076 loss=1.887115716934204\n","training log: 1 epoch, 2810/3076 loss=1.5745505094528198\n","training log: 1 epoch, 2820/3076 loss=1.5162348747253418\n","training log: 1 epoch, 2830/3076 loss=1.5746949911117554\n","training log: 1 epoch, 2840/3076 loss=1.504516839981079\n","training log: 1 epoch, 2850/3076 loss=1.9815282821655273\n","training log: 1 epoch, 2860/3076 loss=1.7058154344558716\n","training log: 1 epoch, 2870/3076 loss=1.8495832681655884\n","training log: 1 epoch, 2880/3076 loss=1.4409162998199463\n","training log: 1 epoch, 2890/3076 loss=1.4277220964431763\n","training log: 1 epoch, 2900/3076 loss=2.205700635910034\n","training log: 1 epoch, 2910/3076 loss=1.5981942415237427\n","training log: 1 epoch, 2920/3076 loss=2.2698397636413574\n","training log: 1 epoch, 2930/3076 loss=1.9861820936203003\n","training log: 1 epoch, 2940/3076 loss=1.5474704504013062\n","training log: 1 epoch, 2950/3076 loss=1.424481987953186\n","training log: 1 epoch, 2960/3076 loss=1.9427931308746338\n","training log: 1 epoch, 2970/3076 loss=1.7649110555648804\n","training log: 1 epoch, 2980/3076 loss=1.8330942392349243\n","training log: 1 epoch, 2990/3076 loss=1.737334966659546\n","training log: 1 epoch, 3000/3076 loss=1.9433112144470215\n","training log: 1 epoch, 3010/3076 loss=1.8053295612335205\n","training log: 1 epoch, 3020/3076 loss=2.0792009830474854\n","training log: 1 epoch, 3030/3076 loss=2.060393810272217\n","training log: 1 epoch, 3040/3076 loss=1.884380578994751\n","training log: 1 epoch, 3050/3076 loss=1.821703553199768\n","training log: 1 epoch, 3060/3076 loss=1.9891164302825928\n","training log: 1 epoch, 3070/3076 loss=2.015561580657959\n"]}],"source":["#---train---\n","import matplotlib.pyplot as plt\n","\n","epoch = 2\n","\n","net: MyVGG = MyVGG()\n","criterion = torch.nn.CrossEntropyLoss()  # ロスの計算\n","optimizer = torch.optim.SGD(params=net.parameters(), lr=0.01, momentum=0.9)\n","\n","history = {\n","    'train_loss': [],\n","    'train_acc': [],\n","    'test_acc': []\n","}\n","\n","for e in range(epoch):\n","    net.train()\n","    loss = None\n","    training_generator, validation_generator = partition_data(0)\n","    for i in range(3076):\n","        input_data = training_generator[i]\n","        optimizer.zero_grad()\n","        images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2)))\n","        labels = torch.Tensor(input_data[1])\n","        #print(images.size())\n","\n","        output = net(images)\n","        loss = 0\n","        for j in range(6):\n","          loss += criterion(output[:,j,:], labels[:,j,:])\n","        #print(loss.item())\n","        #break\n","        loss.backward()\n","        optimizer.step()\n","\n","        if np.isnan(loss.item()):\n","          print(output,images,labels,loss)\n","          break\n","\n","        if i % 10 == 0:\n","            print(f\"training log: {e} epoch, {i}/{3076*128//128} loss={loss.item()}\")\n","            #print(output[0])\n","\n","    history['train_loss'].append(loss.item())\n","    torch.save(net, '/content/drive/MyDrive/2021/MyTabCNN/model/model_vgg_bekku.pth')\n","    # model = torch.load('model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHr2ojEzsKpS"},"outputs":[],"source":["training log: 0 epoch, 0/3076 loss=18.655574798583984\n","training log: 0 epoch, 10/3076 loss=6.632710933685303\n","training log: 0 epoch, 20/3076 loss=4.9796881675720215\n","training log: 0 epoch, 30/3076 loss=4.940411567687988\n","training log: 0 epoch, 40/3076 loss=4.189169406890869\n","training log: 0 epoch, 50/3076 loss=4.094576358795166\n","training log: 0 epoch, 60/3076 loss=3.896057605743408\n","training log: 0 epoch, 70/3076 loss=3.1941792964935303\n","training log: 0 epoch, 80/3076 loss=2.590235948562622\n","training log: 0 epoch, 90/3076 loss=2.639957904815674\n","training log: 0 epoch, 100/3076 loss=2.7781708240509033\n","training log: 0 epoch, 110/3076 loss=2.8821630477905273\n","training log: 0 epoch, 120/3076 loss=2.50978422164917\n","training log: 0 epoch, 130/3076 loss=2.519385814666748\n","training log: 0 epoch, 140/3076 loss=2.8347601890563965\n","training log: 0 epoch, 150/3076 loss=2.8411993980407715\n","training log: 0 epoch, 160/3076 loss=2.6272635459899902\n","training log: 0 epoch, 170/3076 loss=2.3158020973205566\n","training log: 0 epoch, 180/3076 loss=2.2782907485961914\n","training log: 0 epoch, 190/3076 loss=3.013498544692993\n","training log: 0 epoch, 200/3076 loss=2.9763550758361816\n","training log: 0 epoch, 210/3076 loss=2.6154837608337402\n","training log: 0 epoch, 220/3076 loss=2.3389389514923096\n","training log: 0 epoch, 230/3076 loss=2.0809526443481445\n","training log: 0 epoch, 240/3076 loss=1.8274176120758057\n","training log: 0 epoch, 250/3076 loss=1.9620435237884521\n","training log: 0 epoch, 260/3076 loss=2.1620755195617676\n","training log: 0 epoch, 270/3076 loss=2.227781057357788\n","training log: 0 epoch, 280/3076 loss=2.5955374240875244\n","training log: 0 epoch, 290/3076 loss=2.198411464691162\n","training log: 0 epoch, 300/3076 loss=2.182056188583374\n","training log: 0 epoch, 310/3076 loss=1.9548827409744263\n","training log: 0 epoch, 320/3076 loss=2.1316111087799072\n","training log: 0 epoch, 330/3076 loss=2.1951308250427246\n","training log: 0 epoch, 340/3076 loss=2.4221601486206055\n","training log: 0 epoch, 350/3076 loss=1.9269051551818848\n","training log: 0 epoch, 360/3076 loss=2.0358080863952637\n","training log: 0 epoch, 370/3076 loss=1.9938870668411255\n","training log: 0 epoch, 380/3076 loss=1.8768645524978638\n","training log: 0 epoch, 390/3076 loss=1.8561468124389648\n","training log: 0 epoch, 400/3076 loss=2.2516465187072754\n","training log: 0 epoch, 410/3076 loss=1.8045814037322998\n","training log: 0 epoch, 420/3076 loss=2.1962428092956543\n","training log: 0 epoch, 430/3076 loss=2.3164923191070557\n","training log: 0 epoch, 440/3076 loss=2.0675134658813477\n","training log: 0 epoch, 450/3076 loss=1.7475392818450928\n","training log: 0 epoch, 460/3076 loss=2.1347901821136475\n","training log: 0 epoch, 470/3076 loss=1.7554391622543335\n","training log: 0 epoch, 480/3076 loss=1.9414658546447754\n","training log: 0 epoch, 490/3076 loss=1.7803776264190674\n","training log: 0 epoch, 500/3076 loss=1.6489295959472656\n","training log: 0 epoch, 510/3076 loss=2.1715784072875977\n","training log: 0 epoch, 520/3076 loss=1.9965481758117676\n","training log: 0 epoch, 530/3076 loss=1.7212952375411987\n","training log: 0 epoch, 540/3076 loss=1.9902775287628174\n","training log: 0 epoch, 550/3076 loss=1.9134892225265503\n","training log: 0 epoch, 560/3076 loss=1.9150131940841675\n","training log: 0 epoch, 570/3076 loss=1.9161241054534912\n","training log: 0 epoch, 580/3076 loss=2.1218385696411133\n","training log: 0 epoch, 590/3076 loss=2.142918586730957\n","training log: 0 epoch, 600/3076 loss=1.6963281631469727\n","training log: 0 epoch, 610/3076 loss=1.8553863763809204\n","training log: 0 epoch, 620/3076 loss=2.0215821266174316\n","training log: 0 epoch, 630/3076 loss=1.643644094467163\n","training log: 0 epoch, 640/3076 loss=1.65672767162323\n","training log: 0 epoch, 650/3076 loss=1.971006989479065\n","training log: 0 epoch, 660/3076 loss=1.9867905378341675\n","training log: 0 epoch, 670/3076 loss=1.8034151792526245\n","training log: 0 epoch, 680/3076 loss=1.9484777450561523\n","training log: 0 epoch, 690/3076 loss=2.2159502506256104\n","training log: 0 epoch, 700/3076 loss=1.8129347562789917\n","training log: 0 epoch, 710/3076 loss=1.9352493286132812\n","training log: 0 epoch, 720/3076 loss=2.0341830253601074\n","training log: 0 epoch, 730/3076 loss=1.7420521974563599\n","training log: 0 epoch, 740/3076 loss=1.9703965187072754\n","training log: 0 epoch, 750/3076 loss=1.762255072593689\n","training log: 0 epoch, 760/3076 loss=2.0130748748779297\n","training log: 0 epoch, 770/3076 loss=1.7785651683807373\n","training log: 0 epoch, 780/3076 loss=1.7015806436538696\n","training log: 0 epoch, 790/3076 loss=1.734377145767212\n","training log: 0 epoch, 800/3076 loss=1.4940634965896606\n","training log: 0 epoch, 810/3076 loss=1.8909015655517578\n","training log: 0 epoch, 820/3076 loss=1.858972191810608\n","training log: 0 epoch, 830/3076 loss=1.468780755996704\n","training log: 0 epoch, 840/3076 loss=1.8987252712249756\n","training log: 0 epoch, 850/3076 loss=1.7936348915100098\n","training log: 0 epoch, 860/3076 loss=1.6745924949645996\n","training log: 0 epoch, 870/3076 loss=1.5514649152755737\n","training log: 0 epoch, 880/3076 loss=1.7875831127166748\n","training log: 0 epoch, 890/3076 loss=1.6510491371154785\n","training log: 0 epoch, 900/3076 loss=1.4768778085708618\n","training log: 0 epoch, 910/3076 loss=1.8857920169830322\n","training log: 0 epoch, 920/3076 loss=1.602579116821289\n","training log: 0 epoch, 930/3076 loss=2.021278142929077\n","training log: 0 epoch, 940/3076 loss=1.8323709964752197\n","training log: 0 epoch, 950/3076 loss=1.743021011352539\n","training log: 0 epoch, 960/3076 loss=1.613948941230774\n","training log: 0 epoch, 970/3076 loss=1.718564510345459\n","training log: 0 epoch, 980/3076 loss=1.6466145515441895\n","training log: 0 epoch, 990/3076 loss=1.7743291854858398\n","training log: 0 epoch, 1000/3076 loss=1.9688407182693481\n","training log: 0 epoch, 1010/3076 loss=1.3844749927520752\n","training log: 0 epoch, 1020/3076 loss=1.515810251235962\n","training log: 0 epoch, 1030/3076 loss=1.8571100234985352\n","training log: 0 epoch, 1040/3076 loss=1.9263532161712646\n","training log: 0 epoch, 1050/3076 loss=1.692480444908142\n","training log: 0 epoch, 1060/3076 loss=1.5043123960494995\n","training log: 0 epoch, 1070/3076 loss=1.8682788610458374\n","training log: 0 epoch, 1080/3076 loss=1.5288583040237427\n","training log: 0 epoch, 1090/3076 loss=1.9130851030349731\n","training log: 0 epoch, 1100/3076 loss=1.510827898979187\n","training log: 0 epoch, 1110/3076 loss=1.3814295530319214\n","training log: 0 epoch, 1120/3076 loss=1.6344282627105713\n","training log: 0 epoch, 1130/3076 loss=1.5833704471588135\n","training log: 0 epoch, 1140/3076 loss=1.382939100265503\n","training log: 0 epoch, 1150/3076 loss=1.5543720722198486\n","training log: 0 epoch, 1160/3076 loss=1.4587819576263428\n","training log: 0 epoch, 1170/3076 loss=1.3814644813537598\n","training log: 0 epoch, 1180/3076 loss=1.9649089574813843\n","training log: 0 epoch, 1190/3076 loss=1.6059812307357788\n","training log: 0 epoch, 1200/3076 loss=1.7658947706222534\n","training log: 0 epoch, 1210/3076 loss=1.3243722915649414\n","training log: 0 epoch, 1220/3076 loss=1.6695215702056885\n","training log: 0 epoch, 1230/3076 loss=1.280137062072754\n","training log: 0 epoch, 1240/3076 loss=1.631115198135376\n","training log: 0 epoch, 1250/3076 loss=1.845456838607788\n","training log: 0 epoch, 1260/3076 loss=1.5355606079101562\n","training log: 0 epoch, 1270/3076 loss=1.686040997505188\n","training log: 0 epoch, 1280/3076 loss=1.7379542589187622\n","training log: 0 epoch, 1290/3076 loss=1.4433176517486572\n","training log: 0 epoch, 1300/3076 loss=2.1144587993621826\n","training log: 0 epoch, 1310/3076 loss=1.549673318862915\n","training log: 0 epoch, 1320/3076 loss=1.5557327270507812\n","training log: 0 epoch, 1330/3076 loss=0.9940820336341858\n","training log: 0 epoch, 1340/3076 loss=1.6653032302856445\n","training log: 0 epoch, 1350/3076 loss=1.5192220211029053\n","training log: 0 epoch, 1360/3076 loss=1.337365984916687\n","training log: 0 epoch, 1370/3076 loss=1.4722753763198853\n","training log: 0 epoch, 1380/3076 loss=1.6591790914535522\n","training log: 0 epoch, 1390/3076 loss=1.3623733520507812\n","training log: 0 epoch, 1400/3076 loss=1.431106448173523\n","training log: 0 epoch, 1410/3076 loss=1.3832815885543823\n","training log: 0 epoch, 1420/3076 loss=1.6758074760437012\n","training log: 0 epoch, 1430/3076 loss=1.3835614919662476\n","training log: 0 epoch, 1440/3076 loss=1.4163099527359009\n","training log: 0 epoch, 1450/3076 loss=1.5927808284759521\n","training log: 0 epoch, 1460/3076 loss=1.4196025133132935\n","training log: 0 epoch, 1470/3076 loss=1.1781806945800781\n","training log: 0 epoch, 1480/3076 loss=1.284563422203064\n","training log: 0 epoch, 1490/3076 loss=1.6915901899337769\n","training log: 0 epoch, 1500/3076 loss=1.2878749370574951\n","training log: 0 epoch, 1510/3076 loss=1.660562515258789\n","training log: 0 epoch, 1520/3076 loss=1.2946271896362305\n","training log: 0 epoch, 1530/3076 loss=1.5677907466888428\n","training log: 0 epoch, 1540/3076 loss=1.3050715923309326\n","training log: 0 epoch, 1550/3076 loss=1.5339136123657227\n","training log: 0 epoch, 1560/3076 loss=1.693460464477539\n","training log: 0 epoch, 1570/3076 loss=1.5999075174331665\n","training log: 0 epoch, 1580/3076 loss=1.2645727396011353\n","training log: 0 epoch, 1590/3076 loss=1.4460984468460083\n","training log: 0 epoch, 1600/3076 loss=1.5237787961959839\n","training log: 0 epoch, 1610/3076 loss=1.188154697418213\n","training log: 0 epoch, 1620/3076 loss=1.076327919960022\n","training log: 0 epoch, 1630/3076 loss=1.6198042631149292\n","training log: 0 epoch, 1640/3076 loss=1.3138271570205688\n","training log: 0 epoch, 1650/3076 loss=1.4095653295516968\n","training log: 0 epoch, 1660/3076 loss=1.1182777881622314\n","training log: 0 epoch, 1670/3076 loss=1.3932796716690063\n","training log: 0 epoch, 1680/3076 loss=1.4780069589614868\n","training log: 0 epoch, 1690/3076 loss=1.3891777992248535\n","training log: 0 epoch, 1700/3076 loss=1.5293943881988525\n","training log: 0 epoch, 1710/3076 loss=1.4911609888076782\n","training log: 0 epoch, 1720/3076 loss=1.5996582508087158\n","training log: 0 epoch, 1730/3076 loss=1.5371257066726685\n","training log: 0 epoch, 1740/3076 loss=1.5569318532943726\n","training log: 0 epoch, 1750/3076 loss=1.7343653440475464\n","training log: 0 epoch, 1760/3076 loss=1.1898797750473022\n","training log: 0 epoch, 1770/3076 loss=1.4867587089538574\n","training log: 0 epoch, 1780/3076 loss=1.2865744829177856\n","training log: 0 epoch, 1790/3076 loss=1.1579630374908447\n","training log: 0 epoch, 1800/3076 loss=1.339611291885376\n","training log: 0 epoch, 1810/3076 loss=1.4254744052886963\n","training log: 0 epoch, 1820/3076 loss=1.2607002258300781\n","training log: 0 epoch, 1830/3076 loss=1.4994794130325317\n","training log: 0 epoch, 1840/3076 loss=1.4748742580413818\n","training log: 0 epoch, 1850/3076 loss=1.6183232069015503\n","training log: 0 epoch, 1860/3076 loss=1.6966190338134766\n","training log: 0 epoch, 1870/3076 loss=1.2654303312301636\n","training log: 0 epoch, 1880/3076 loss=1.4638729095458984\n","training log: 0 epoch, 1890/3076 loss=1.4288877248764038\n","training log: 0 epoch, 1900/3076 loss=1.4812729358673096\n","training log: 0 epoch, 1910/3076 loss=1.392934799194336\n","training log: 0 epoch, 1920/3076 loss=1.4124729633331299\n","training log: 0 epoch, 1930/3076 loss=1.378199815750122\n","training log: 0 epoch, 1940/3076 loss=1.3669451475143433\n","training log: 0 epoch, 1950/3076 loss=1.394010066986084\n","training log: 0 epoch, 1960/3076 loss=1.588151454925537\n","training log: 0 epoch, 1970/3076 loss=1.3815901279449463\n","training log: 0 epoch, 1980/3076 loss=1.3927196264266968\n","training log: 0 epoch, 1990/3076 loss=1.3029649257659912\n","training log: 0 epoch, 2000/3076 loss=1.646141529083252\n","training log: 0 epoch, 2010/3076 loss=1.4454841613769531\n","training log: 0 epoch, 2020/3076 loss=1.8604378700256348\n","training log: 0 epoch, 2030/3076 loss=1.5481507778167725\n","training log: 0 epoch, 2040/3076 loss=1.2918798923492432\n","training log: 0 epoch, 2050/3076 loss=1.394213080406189\n","training log: 0 epoch, 2060/3076 loss=1.44749915599823\n","training log: 0 epoch, 2070/3076 loss=1.145015001296997\n","training log: 0 epoch, 2080/3076 loss=1.5493814945220947\n","training log: 0 epoch, 2090/3076 loss=1.1938226222991943\n","training log: 0 epoch, 2100/3076 loss=1.239730715751648\n","training log: 0 epoch, 2110/3076 loss=1.0451624393463135\n","training log: 0 epoch, 2120/3076 loss=1.3061057329177856\n","training log: 0 epoch, 2130/3076 loss=1.4697339534759521\n","training log: 0 epoch, 2140/3076 loss=1.0237220525741577\n","training log: 0 epoch, 2150/3076 loss=1.6780084371566772\n","training log: 0 epoch, 2160/3076 loss=1.8476152420043945\n","training log: 0 epoch, 2170/3076 loss=1.238629937171936\n","training log: 0 epoch, 2180/3076 loss=1.5874595642089844\n","training log: 0 epoch, 2190/3076 loss=1.126999855041504\n","training log: 0 epoch, 2200/3076 loss=1.2464944124221802\n","training log: 0 epoch, 2210/3076 loss=1.4964642524719238\n","training log: 0 epoch, 2220/3076 loss=1.7303454875946045\n","training log: 0 epoch, 2230/3076 loss=1.3166636228561401\n","training log: 0 epoch, 2240/3076 loss=1.169656753540039\n","training log: 0 epoch, 2250/3076 loss=1.2430925369262695\n","training log: 0 epoch, 2260/3076 loss=1.4395273923873901\n","training log: 0 epoch, 2270/3076 loss=1.3086724281311035\n","training log: 0 epoch, 2280/3076 loss=1.1922173500061035\n","training log: 0 epoch, 2290/3076 loss=1.6302871704101562\n","training log: 0 epoch, 2300/3076 loss=1.434340238571167\n","training log: 0 epoch, 2310/3076 loss=1.2984764575958252\n","training log: 0 epoch, 2320/3076 loss=1.3338205814361572\n","training log: 0 epoch, 2330/3076 loss=1.2555500268936157\n","training log: 0 epoch, 2340/3076 loss=1.382885217666626\n","training log: 0 epoch, 2350/3076 loss=1.173202395439148\n","training log: 0 epoch, 2360/3076 loss=1.4493645429611206\n","training log: 0 epoch, 2370/3076 loss=1.771876335144043\n","training log: 0 epoch, 2380/3076 loss=1.7193725109100342\n","training log: 0 epoch, 2390/3076 loss=1.3445312976837158\n","training log: 0 epoch, 2400/3076 loss=1.0824071168899536\n","training log: 0 epoch, 2410/3076 loss=1.0384057760238647\n","training log: 0 epoch, 2420/3076 loss=1.2147092819213867\n","training log: 0 epoch, 2430/3076 loss=1.289825677871704\n","training log: 0 epoch, 2440/3076 loss=1.0508966445922852\n","training log: 0 epoch, 2450/3076 loss=1.2597756385803223\n","training log: 0 epoch, 2460/3076 loss=1.0387420654296875\n","training log: 0 epoch, 2470/3076 loss=1.2255487442016602\n","training log: 0 epoch, 2480/3076 loss=1.3175926208496094\n","training log: 0 epoch, 2490/3076 loss=1.5741569995880127\n","training log: 0 epoch, 2500/3076 loss=1.3396984338760376\n","training log: 0 epoch, 2510/3076 loss=1.2419582605361938\n","training log: 0 epoch, 2520/3076 loss=1.5540015697479248\n","training log: 0 epoch, 2530/3076 loss=1.2515405416488647\n","training log: 0 epoch, 2540/3076 loss=1.247594952583313\n","training log: 0 epoch, 2550/3076 loss=1.4659889936447144\n","training log: 0 epoch, 2560/3076 loss=1.0647578239440918\n","training log: 0 epoch, 2570/3076 loss=1.685586929321289\n","training log: 0 epoch, 2580/3076 loss=1.5599305629730225\n","training log: 0 epoch, 2590/3076 loss=1.4943726062774658\n","training log: 0 epoch, 2600/3076 loss=1.3613497018814087\n","training log: 0 epoch, 2610/3076 loss=1.6667461395263672\n","training log: 0 epoch, 2620/3076 loss=1.4572027921676636\n","training log: 0 epoch, 2630/3076 loss=1.2497775554656982\n","training log: 0 epoch, 2640/3076 loss=1.1313945055007935\n","training log: 0 epoch, 2650/3076 loss=1.2637906074523926\n","training log: 0 epoch, 2660/3076 loss=1.5186845064163208\n","training log: 0 epoch, 2670/3076 loss=1.0228850841522217\n","training log: 0 epoch, 2680/3076 loss=0.9576622247695923\n","training log: 0 epoch, 2690/3076 loss=1.5666447877883911\n","training log: 0 epoch, 2700/3076 loss=1.2120963335037231\n","training log: 0 epoch, 2710/3076 loss=1.1167773008346558\n","training log: 0 epoch, 2720/3076 loss=1.2680447101593018\n","training log: 0 epoch, 2730/3076 loss=1.229409098625183\n","training log: 0 epoch, 2740/3076 loss=1.1420767307281494\n","training log: 0 epoch, 2750/3076 loss=1.4217939376831055\n","training log: 0 epoch, 2760/3076 loss=1.2768710851669312\n","training log: 0 epoch, 2770/3076 loss=1.236474871635437\n","training log: 0 epoch, 2780/3076 loss=1.2846012115478516\n","training log: 0 epoch, 2790/3076 loss=1.429375171661377\n","training log: 0 epoch, 2800/3076 loss=1.3358241319656372\n","training log: 0 epoch, 2810/3076 loss=1.339163899421692\n","training log: 0 epoch, 2820/3076 loss=1.2935147285461426\n","training log: 0 epoch, 2830/3076 loss=1.1806949377059937\n","training log: 0 epoch, 2840/3076 loss=1.310391902923584\n","training log: 0 epoch, 2850/3076 loss=1.0961005687713623\n","training log: 0 epoch, 2860/3076 loss=1.6397812366485596\n","training log: 0 epoch, 2870/3076 loss=1.4912433624267578\n","training log: 0 epoch, 2880/3076 loss=1.2707829475402832\n","training log: 0 epoch, 2890/3076 loss=1.0693098306655884\n","training log: 0 epoch, 2900/3076 loss=1.2947648763656616\n","training log: 0 epoch, 2910/3076 loss=1.2553244829177856\n","training log: 0 epoch, 2920/3076 loss=1.5256800651550293\n","training log: 0 epoch, 2930/3076 loss=1.3194916248321533\n","training log: 0 epoch, 2940/3076 loss=1.2917625904083252\n","training log: 0 epoch, 2950/3076 loss=1.166849136352539\n","training log: 0 epoch, 2960/3076 loss=1.29823899269104\n","training log: 0 epoch, 2970/3076 loss=1.468350887298584\n","training log: 0 epoch, 2980/3076 loss=1.4260890483856201\n","training log: 0 epoch, 2990/3076 loss=1.6172776222229004\n","training log: 0 epoch, 3000/3076 loss=1.2100058794021606\n","training log: 0 epoch, 3010/3076 loss=1.3811085224151611\n","training log: 0 epoch, 3020/3076 loss=1.078066110610962\n","training log: 0 epoch, 3030/3076 loss=1.417569637298584\n","training log: 0 epoch, 3040/3076 loss=1.3297338485717773\n","training log: 0 epoch, 3050/3076 loss=1.1234022378921509\n","training log: 0 epoch, 3060/3076 loss=1.263526439666748\n","training log: 0 epoch, 3070/3076 loss=1.1713573932647705"]},{"cell_type":"code","source":["training log: 0 epoch, 0/3076 loss=18.631317138671875\n","training log: 0 epoch, 10/3076 loss=11.61350154876709\n","training log: 0 epoch, 20/3076 loss=10.2649507522583\n","training log: 0 epoch, 30/3076 loss=8.926521301269531\n","training log: 0 epoch, 40/3076 loss=7.99122428894043\n","training log: 0 epoch, 50/3076 loss=7.248771667480469\n","training log: 0 epoch, 60/3076 loss=7.375607490539551\n","training log: 0 epoch, 70/3076 loss=6.954869270324707\n","training log: 0 epoch, 80/3076 loss=7.360713005065918\n","training log: 0 epoch, 90/3076 loss=5.9394211769104\n","training log: 0 epoch, 100/3076 loss=7.356283187866211\n","training log: 0 epoch, 110/3076 loss=6.256516456604004\n","training log: 0 epoch, 120/3076 loss=6.693115234375\n","training log: 0 epoch, 130/3076 loss=4.974355697631836\n","training log: 0 epoch, 140/3076 loss=5.533995151519775\n","training log: 0 epoch, 150/3076 loss=5.115541458129883\n","training log: 0 epoch, 160/3076 loss=5.194180965423584\n","training log: 0 epoch, 170/3076 loss=5.22303581237793\n","training log: 0 epoch, 180/3076 loss=6.0245819091796875\n","training log: 0 epoch, 190/3076 loss=5.16840124130249\n","training log: 0 epoch, 200/3076 loss=5.801542282104492\n","training log: 0 epoch, 210/3076 loss=4.52789306640625\n","training log: 0 epoch, 220/3076 loss=4.150794982910156\n","training log: 0 epoch, 230/3076 loss=5.006357192993164\n","training log: 0 epoch, 240/3076 loss=4.544564247131348\n","training log: 0 epoch, 250/3076 loss=4.971286773681641\n","training log: 0 epoch, 260/3076 loss=4.736966133117676\n","training log: 0 epoch, 270/3076 loss=5.014521598815918\n","training log: 0 epoch, 280/3076 loss=4.132544994354248\n","training log: 0 epoch, 290/3076 loss=4.614043235778809\n","training log: 0 epoch, 300/3076 loss=5.1389570236206055\n","training log: 0 epoch, 310/3076 loss=4.4005584716796875\n","training log: 0 epoch, 320/3076 loss=4.4048285484313965\n","training log: 0 epoch, 330/3076 loss=3.98689603805542\n","training log: 0 epoch, 340/3076 loss=3.867811441421509\n","training log: 0 epoch, 350/3076 loss=4.003584384918213\n","training log: 0 epoch, 360/3076 loss=3.6251261234283447\n","training log: 0 epoch, 370/3076 loss=3.9454402923583984\n","training log: 0 epoch, 380/3076 loss=3.6640872955322266\n","training log: 0 epoch, 390/3076 loss=3.572514295578003\n","training log: 0 epoch, 400/3076 loss=3.6906471252441406\n","training log: 0 epoch, 410/3076 loss=4.165279388427734\n","training log: 0 epoch, 420/3076 loss=3.9914116859436035\n","training log: 0 epoch, 430/3076 loss=3.1719651222229004\n","training log: 0 epoch, 440/3076 loss=3.783179998397827\n","training log: 0 epoch, 450/3076 loss=4.211324691772461\n","training log: 0 epoch, 460/3076 loss=3.846748113632202\n","training log: 0 epoch, 470/3076 loss=3.7150306701660156\n","training log: 0 epoch, 480/3076 loss=3.2471907138824463\n","training log: 0 epoch, 490/3076 loss=3.0258476734161377\n","training log: 0 epoch, 500/3076 loss=3.9236106872558594\n","training log: 0 epoch, 510/3076 loss=3.152893543243408\n","training log: 0 epoch, 520/3076 loss=3.4884345531463623\n","training log: 0 epoch, 530/3076 loss=3.86311674118042\n","training log: 0 epoch, 540/3076 loss=2.859797239303589\n","training log: 0 epoch, 550/3076 loss=3.882335662841797\n","training log: 0 epoch, 560/3076 loss=3.608929395675659\n","training log: 0 epoch, 570/3076 loss=3.110743999481201\n","training log: 0 epoch, 580/3076 loss=3.3882813453674316\n","training log: 0 epoch, 590/3076 loss=3.5470521450042725\n","training log: 0 epoch, 600/3076 loss=3.0869202613830566\n","training log: 0 epoch, 610/3076 loss=3.3449463844299316\n","training log: 0 epoch, 620/3076 loss=2.8918943405151367\n","training log: 0 epoch, 630/3076 loss=3.2104809284210205\n","training log: 0 epoch, 640/3076 loss=3.618100881576538\n","training log: 0 epoch, 650/3076 loss=3.5320565700531006\n","training log: 0 epoch, 660/3076 loss=3.3256804943084717\n","training log: 0 epoch, 670/3076 loss=3.062116861343384\n","training log: 0 epoch, 680/3076 loss=3.0935847759246826\n","training log: 0 epoch, 690/3076 loss=3.029815673828125\n","training log: 0 epoch, 700/3076 loss=3.4618489742279053\n","training log: 0 epoch, 710/3076 loss=3.04278564453125\n","training log: 0 epoch, 720/3076 loss=3.2199506759643555\n","training log: 0 epoch, 730/3076 loss=3.576434373855591\n","training log: 0 epoch, 740/3076 loss=3.383559226989746\n","training log: 0 epoch, 750/3076 loss=3.1280925273895264\n","training log: 0 epoch, 760/3076 loss=4.1927924156188965\n","training log: 0 epoch, 770/3076 loss=2.955925941467285\n","training log: 0 epoch, 780/3076 loss=3.39963960647583\n","training log: 0 epoch, 790/3076 loss=3.2096469402313232\n","training log: 0 epoch, 800/3076 loss=2.830965280532837\n","training log: 0 epoch, 810/3076 loss=3.7224693298339844\n","training log: 0 epoch, 820/3076 loss=2.9962563514709473\n","training log: 0 epoch, 830/3076 loss=3.144347667694092\n","training log: 0 epoch, 840/3076 loss=2.9936728477478027\n","training log: 0 epoch, 850/3076 loss=3.4840426445007324\n","training log: 0 epoch, 860/3076 loss=3.5015339851379395\n","training log: 0 epoch, 870/3076 loss=3.70815372467041\n","training log: 0 epoch, 880/3076 loss=3.295330762863159\n","training log: 0 epoch, 890/3076 loss=3.191878080368042\n","training log: 0 epoch, 900/3076 loss=3.113919734954834\n","training log: 0 epoch, 910/3076 loss=3.0972952842712402\n","training log: 0 epoch, 920/3076 loss=2.762779474258423\n","training log: 0 epoch, 930/3076 loss=3.295499801635742\n","training log: 0 epoch, 940/3076 loss=2.9889655113220215\n","training log: 0 epoch, 950/3076 loss=3.3222413063049316\n","training log: 0 epoch, 960/3076 loss=2.8689019680023193\n","training log: 0 epoch, 970/3076 loss=2.7535321712493896\n","training log: 0 epoch, 980/3076 loss=2.7632787227630615\n","training log: 0 epoch, 990/3076 loss=3.307183027267456\n","training log: 0 epoch, 1000/3076 loss=2.9741342067718506\n","training log: 0 epoch, 1010/3076 loss=3.053895950317383\n","training log: 0 epoch, 1020/3076 loss=3.098280191421509\n","training log: 0 epoch, 1030/3076 loss=2.691862106323242\n","training log: 0 epoch, 1040/3076 loss=2.705533742904663\n","training log: 0 epoch, 1050/3076 loss=2.564206600189209\n","training log: 0 epoch, 1060/3076 loss=3.2988638877868652\n","training log: 0 epoch, 1070/3076 loss=2.5759451389312744\n","training log: 0 epoch, 1080/3076 loss=2.6918797492980957\n","training log: 0 epoch, 1090/3076 loss=3.005479335784912\n","training log: 0 epoch, 1100/3076 loss=2.7214581966400146\n","training log: 0 epoch, 1110/3076 loss=3.062544345855713\n","training log: 0 epoch, 1120/3076 loss=3.412898302078247\n","training log: 0 epoch, 1130/3076 loss=2.971100330352783\n","training log: 0 epoch, 1140/3076 loss=3.1070642471313477\n","training log: 0 epoch, 1150/3076 loss=2.483006238937378\n","training log: 0 epoch, 1160/3076 loss=3.3305468559265137\n","training log: 0 epoch, 1170/3076 loss=3.0268971920013428\n","training log: 0 epoch, 1180/3076 loss=2.7636356353759766\n","training log: 0 epoch, 1190/3076 loss=2.682352304458618\n","training log: 0 epoch, 1200/3076 loss=2.7478411197662354\n","training log: 0 epoch, 1210/3076 loss=3.2326056957244873\n","training log: 0 epoch, 1220/3076 loss=2.793438673019409\n","training log: 0 epoch, 1230/3076 loss=2.7576279640197754\n","training log: 0 epoch, 1240/3076 loss=3.297926187515259\n","training log: 0 epoch, 1250/3076 loss=2.7371020317077637\n","training log: 0 epoch, 1260/3076 loss=2.8806440830230713\n","training log: 0 epoch, 1270/3076 loss=2.7219014167785645\n","training log: 0 epoch, 1280/3076 loss=2.8848953247070312\n","training log: 0 epoch, 1290/3076 loss=2.668107271194458\n","training log: 0 epoch, 1300/3076 loss=2.8944225311279297\n","training log: 0 epoch, 1310/3076 loss=2.8927056789398193\n","training log: 0 epoch, 1320/3076 loss=2.626521110534668\n","training log: 0 epoch, 1330/3076 loss=2.651348114013672\n","training log: 0 epoch, 1340/3076 loss=2.909348964691162\n","training log: 0 epoch, 1350/3076 loss=2.6740951538085938\n","training log: 0 epoch, 1360/3076 loss=2.849395513534546\n","training log: 0 epoch, 1370/3076 loss=2.5442590713500977\n","training log: 0 epoch, 1380/3076 loss=2.8419992923736572\n","training log: 0 epoch, 1390/3076 loss=2.873138666152954\n","training log: 0 epoch, 1400/3076 loss=2.766057014465332\n","training log: 0 epoch, 1410/3076 loss=2.665351390838623\n","training log: 0 epoch, 1420/3076 loss=2.5992836952209473\n","training log: 0 epoch, 1430/3076 loss=2.578052043914795\n","training log: 0 epoch, 1440/3076 loss=2.6918563842773438\n","training log: 0 epoch, 1450/3076 loss=2.503202438354492\n","training log: 0 epoch, 1460/3076 loss=3.4823076725006104\n","training log: 0 epoch, 1470/3076 loss=2.8049280643463135\n","training log: 0 epoch, 1480/3076 loss=3.351067304611206\n","training log: 0 epoch, 1490/3076 loss=2.994169235229492\n","training log: 0 epoch, 1500/3076 loss=2.6919729709625244\n","training log: 0 epoch, 1510/3076 loss=2.2154338359832764\n","training log: 0 epoch, 1520/3076 loss=3.088168144226074\n","training log: 0 epoch, 1530/3076 loss=2.4762842655181885\n","training log: 0 epoch, 1540/3076 loss=2.9825024604797363\n","training log: 0 epoch, 1550/3076 loss=2.658299446105957\n","training log: 0 epoch, 1560/3076 loss=2.8031766414642334\n","training log: 0 epoch, 1570/3076 loss=2.68898868560791\n","training log: 0 epoch, 1580/3076 loss=2.7482874393463135\n","training log: 0 epoch, 1590/3076 loss=2.7816238403320312\n","training log: 0 epoch, 1600/3076 loss=2.524653196334839\n","training log: 0 epoch, 1610/3076 loss=2.691943883895874\n","training log: 0 epoch, 1620/3076 loss=3.0859687328338623\n","training log: 0 epoch, 1630/3076 loss=3.0925841331481934\n","training log: 0 epoch, 1640/3076 loss=2.785303831100464\n","training log: 0 epoch, 1650/3076 loss=3.162116527557373\n","training log: 0 epoch, 1660/3076 loss=3.065321683883667\n","training log: 0 epoch, 1670/3076 loss=2.520820140838623\n","training log: 0 epoch, 1680/3076 loss=2.731889247894287\n","training log: 0 epoch, 1690/3076 loss=2.958505868911743\n","training log: 0 epoch, 1700/3076 loss=2.973196268081665\n","training log: 0 epoch, 1710/3076 loss=2.774852991104126\n","training log: 0 epoch, 1720/3076 loss=2.8387341499328613\n","training log: 0 epoch, 1730/3076 loss=2.7681658267974854\n","training log: 0 epoch, 1740/3076 loss=2.7312309741973877\n","training log: 0 epoch, 1750/3076 loss=2.5029211044311523\n","training log: 0 epoch, 1760/3076 loss=2.3611533641815186\n","training log: 0 epoch, 1770/3076 loss=2.351728916168213\n","training log: 0 epoch, 1780/3076 loss=2.781827688217163\n","training log: 0 epoch, 1790/3076 loss=2.936420202255249\n","training log: 0 epoch, 1800/3076 loss=2.701838970184326\n","training log: 0 epoch, 1810/3076 loss=2.2520065307617188\n","training log: 0 epoch, 1820/3076 loss=3.002368927001953\n","training log: 0 epoch, 1830/3076 loss=2.6979563236236572\n","training log: 0 epoch, 1840/3076 loss=2.578545331954956\n","training log: 0 epoch, 1850/3076 loss=2.3861801624298096\n","training log: 0 epoch, 1860/3076 loss=2.7526049613952637\n","training log: 0 epoch, 1870/3076 loss=2.465733528137207\n","training log: 0 epoch, 1880/3076 loss=2.894193172454834\n","training log: 0 epoch, 1890/3076 loss=2.1502134799957275\n","training log: 0 epoch, 1900/3076 loss=2.2568295001983643\n","training log: 0 epoch, 1910/3076 loss=2.7351722717285156\n","training log: 0 epoch, 1920/3076 loss=2.38472318649292\n","training log: 0 epoch, 1930/3076 loss=2.8463356494903564\n","training log: 0 epoch, 1940/3076 loss=2.8041062355041504\n","training log: 0 epoch, 1950/3076 loss=2.558621883392334\n","training log: 0 epoch, 1960/3076 loss=2.312673568725586\n","training log: 0 epoch, 1970/3076 loss=2.7635648250579834\n","training log: 0 epoch, 1980/3076 loss=2.9210634231567383\n","training log: 0 epoch, 1990/3076 loss=2.852141857147217\n","training log: 0 epoch, 2000/3076 loss=2.6728992462158203\n","training log: 0 epoch, 2010/3076 loss=2.591586112976074\n","training log: 0 epoch, 2020/3076 loss=2.6372427940368652\n","training log: 0 epoch, 2030/3076 loss=2.427854299545288\n","training log: 0 epoch, 2040/3076 loss=2.8457388877868652\n","training log: 0 epoch, 2050/3076 loss=2.6277642250061035\n","training log: 0 epoch, 2060/3076 loss=2.243375539779663\n","training log: 0 epoch, 2070/3076 loss=2.344027519226074\n","training log: 0 epoch, 2080/3076 loss=2.6336450576782227\n","training log: 0 epoch, 2090/3076 loss=2.7050554752349854\n","training log: 0 epoch, 2100/3076 loss=2.667311906814575\n","training log: 0 epoch, 2110/3076 loss=2.129185676574707\n","training log: 0 epoch, 2120/3076 loss=2.648242235183716\n","training log: 0 epoch, 2130/3076 loss=2.4310595989227295\n","training log: 0 epoch, 2140/3076 loss=2.870819330215454\n","training log: 0 epoch, 2150/3076 loss=2.4406559467315674\n","training log: 0 epoch, 2160/3076 loss=2.1233232021331787\n","training log: 0 epoch, 2170/3076 loss=2.2009377479553223\n","training log: 0 epoch, 2180/3076 loss=2.521465301513672\n","training log: 0 epoch, 2190/3076 loss=2.711350202560425\n","training log: 0 epoch, 2200/3076 loss=2.19853138923645\n","training log: 0 epoch, 2210/3076 loss=1.8311798572540283\n","training log: 0 epoch, 2220/3076 loss=2.3410465717315674\n","training log: 0 epoch, 2230/3076 loss=2.264772415161133\n","training log: 0 epoch, 2240/3076 loss=2.4161593914031982\n","training log: 0 epoch, 2250/3076 loss=2.522688865661621\n","training log: 0 epoch, 2260/3076 loss=2.179048776626587\n","training log: 0 epoch, 2270/3076 loss=2.4037861824035645\n","training log: 0 epoch, 2280/3076 loss=2.6863646507263184\n","training log: 0 epoch, 2290/3076 loss=2.2633113861083984\n","training log: 0 epoch, 2300/3076 loss=2.392080307006836\n","training log: 0 epoch, 2310/3076 loss=1.6924952268600464\n","training log: 0 epoch, 2320/3076 loss=2.711355686187744\n","training log: 0 epoch, 2330/3076 loss=2.186338424682617\n","training log: 0 epoch, 2340/3076 loss=2.8495211601257324\n","training log: 0 epoch, 2350/3076 loss=2.2934107780456543\n","training log: 0 epoch, 2360/3076 loss=2.559164524078369\n","training log: 0 epoch, 2370/3076 loss=2.062978506088257\n","training log: 0 epoch, 2380/3076 loss=2.5775113105773926\n","training log: 0 epoch, 2390/3076 loss=2.5488219261169434\n","training log: 0 epoch, 2400/3076 loss=2.1515209674835205\n","training log: 0 epoch, 2410/3076 loss=2.549410820007324\n","training log: 0 epoch, 2420/3076 loss=2.796093702316284\n","training log: 0 epoch, 2430/3076 loss=2.125836133956909\n","training log: 0 epoch, 2440/3076 loss=2.519648790359497\n","training log: 0 epoch, 2450/3076 loss=1.9068583250045776\n","training log: 0 epoch, 2460/3076 loss=2.2414934635162354\n","training log: 0 epoch, 2470/3076 loss=2.637831687927246\n","training log: 0 epoch, 2480/3076 loss=1.9222567081451416\n","training log: 0 epoch, 2490/3076 loss=2.489401340484619\n","training log: 0 epoch, 2500/3076 loss=2.213078260421753\n","training log: 0 epoch, 2510/3076 loss=2.001268148422241\n","training log: 0 epoch, 2520/3076 loss=1.9682378768920898\n","training log: 0 epoch, 2530/3076 loss=2.4105045795440674\n","training log: 0 epoch, 2540/3076 loss=2.3572278022766113\n","training log: 0 epoch, 2550/3076 loss=2.243565320968628\n","training log: 0 epoch, 2560/3076 loss=2.348299026489258\n","training log: 0 epoch, 2570/3076 loss=2.184830665588379\n","training log: 0 epoch, 2580/3076 loss=2.056722640991211\n","training log: 0 epoch, 2590/3076 loss=2.3954739570617676\n","training log: 0 epoch, 2600/3076 loss=2.3880133628845215\n","training log: 0 epoch, 2610/3076 loss=2.2102415561676025\n","training log: 0 epoch, 2620/3076 loss=2.23551869392395\n","training log: 0 epoch, 2630/3076 loss=2.5700995922088623\n","training log: 0 epoch, 2640/3076 loss=2.41522479057312\n","training log: 0 epoch, 2650/3076 loss=2.7933685779571533\n","training log: 0 epoch, 2660/3076 loss=2.3886919021606445\n","training log: 0 epoch, 2670/3076 loss=2.178402900695801\n","training log: 0 epoch, 2680/3076 loss=1.9875856637954712\n","training log: 0 epoch, 2690/3076 loss=2.430011510848999\n","training log: 0 epoch, 2700/3076 loss=2.1611294746398926\n","training log: 0 epoch, 2710/3076 loss=3.193410634994507\n","training log: 0 epoch, 2720/3076 loss=2.3589115142822266\n","training log: 0 epoch, 2730/3076 loss=2.4696528911590576\n","training log: 0 epoch, 2740/3076 loss=2.563023567199707\n","training log: 0 epoch, 2750/3076 loss=2.306819200515747\n","training log: 0 epoch, 2760/3076 loss=2.4559249877929688\n","training log: 0 epoch, 2770/3076 loss=2.1847541332244873\n","training log: 0 epoch, 2780/3076 loss=2.471203565597534\n","training log: 0 epoch, 2790/3076 loss=2.6405718326568604\n","training log: 0 epoch, 2800/3076 loss=2.5954012870788574\n","training log: 0 epoch, 2810/3076 loss=1.9674091339111328\n","training log: 0 epoch, 2820/3076 loss=2.307049512863159\n","training log: 0 epoch, 2830/3076 loss=2.450000762939453\n","training log: 0 epoch, 2840/3076 loss=2.1116316318511963\n","training log: 0 epoch, 2850/3076 loss=2.134247064590454\n","training log: 0 epoch, 2860/3076 loss=2.3031165599823\n","training log: 0 epoch, 2870/3076 loss=2.0993552207946777\n","training log: 0 epoch, 2880/3076 loss=2.0821661949157715\n","training log: 0 epoch, 2890/3076 loss=2.095163345336914\n","training log: 0 epoch, 2900/3076 loss=2.7819888591766357\n","training log: 0 epoch, 2910/3076 loss=2.293067455291748\n","training log: 0 epoch, 2920/3076 loss=2.596061944961548\n","training log: 0 epoch, 2930/3076 loss=2.556335687637329\n","training log: 0 epoch, 2940/3076 loss=2.4529905319213867\n","training log: 0 epoch, 2950/3076 loss=1.9770022630691528\n","training log: 0 epoch, 2960/3076 loss=1.9333609342575073\n","training log: 0 epoch, 2970/3076 loss=2.275407314300537\n","training log: 0 epoch, 2980/3076 loss=2.25219464302063\n","training log: 0 epoch, 2990/3076 loss=2.3901026248931885\n","training log: 0 epoch, 3000/3076 loss=2.1306140422821045\n","training log: 0 epoch, 3010/3076 loss=2.4180052280426025\n","training log: 0 epoch, 3020/3076 loss=2.054279327392578\n","training log: 0 epoch, 3030/3076 loss=2.4228880405426025\n","training log: 0 epoch, 3040/3076 loss=2.403083324432373\n","training log: 0 epoch, 3050/3076 loss=2.1179957389831543\n","training log: 0 epoch, 3060/3076 loss=2.504387617111206\n","training log: 0 epoch, 3070/3076 loss=2.4775421619415283\n","training log: 1 epoch, 0/3076 loss=2.649858236312866\n","training log: 1 epoch, 10/3076 loss=2.0398969650268555\n","training log: 1 epoch, 20/3076 loss=1.852761149406433\n","training log: 1 epoch, 30/3076 loss=1.9422670602798462\n","training log: 1 epoch, 40/3076 loss=2.1659469604492188\n","training log: 1 epoch, 50/3076 loss=2.5787789821624756\n","training log: 1 epoch, 60/3076 loss=2.0122501850128174\n","training log: 1 epoch, 70/3076 loss=2.2442259788513184\n","training log: 1 epoch, 80/3076 loss=2.0500996112823486\n","training log: 1 epoch, 90/3076 loss=2.14385724067688\n","training log: 1 epoch, 100/3076 loss=2.2485570907592773\n","training log: 1 epoch, 110/3076 loss=2.219026565551758\n","training log: 1 epoch, 120/3076 loss=2.4759678840637207\n","training log: 1 epoch, 130/3076 loss=2.01899790763855\n","training log: 1 epoch, 140/3076 loss=2.0730252265930176\n","training log: 1 epoch, 150/3076 loss=2.181464195251465\n","training log: 1 epoch, 160/3076 loss=2.263639450073242\n","training log: 1 epoch, 170/3076 loss=2.156669855117798\n","training log: 1 epoch, 180/3076 loss=1.8918505907058716\n","training log: 1 epoch, 190/3076 loss=1.8108127117156982\n","training log: 1 epoch, 200/3076 loss=2.1832168102264404\n","training log: 1 epoch, 210/3076 loss=2.289241075515747\n","training log: 1 epoch, 220/3076 loss=2.212083339691162\n","training log: 1 epoch, 230/3076 loss=2.2336325645446777\n","training log: 1 epoch, 240/3076 loss=1.8655999898910522\n","training log: 1 epoch, 250/3076 loss=2.3917386531829834\n","training log: 1 epoch, 260/3076 loss=2.387896776199341\n","training log: 1 epoch, 270/3076 loss=1.6834943294525146\n","training log: 1 epoch, 280/3076 loss=2.4507343769073486\n","training log: 1 epoch, 290/3076 loss=2.25252103805542\n","training log: 1 epoch, 300/3076 loss=2.200971841812134\n","training log: 1 epoch, 310/3076 loss=2.3746140003204346\n","training log: 1 epoch, 320/3076 loss=1.954698085784912\n","training log: 1 epoch, 330/3076 loss=2.045255422592163\n","training log: 1 epoch, 340/3076 loss=2.4071061611175537\n","training log: 1 epoch, 350/3076 loss=2.119410276412964\n","training log: 1 epoch, 360/3076 loss=2.1102304458618164\n","training log: 1 epoch, 370/3076 loss=2.1270477771759033\n","training log: 1 epoch, 380/3076 loss=1.7238521575927734\n","training log: 1 epoch, 390/3076 loss=2.5062220096588135\n","training log: 1 epoch, 400/3076 loss=2.6271181106567383\n","training log: 1 epoch, 410/3076 loss=2.2267587184906006\n","training log: 1 epoch, 420/3076 loss=2.031285047531128\n","training log: 1 epoch, 430/3076 loss=2.2304489612579346\n","training log: 1 epoch, 440/3076 loss=2.3279788494110107\n","training log: 1 epoch, 450/3076 loss=2.660487651824951\n","training log: 1 epoch, 460/3076 loss=2.258876085281372\n","training log: 1 epoch, 470/3076 loss=2.084972858428955\n","training log: 1 epoch, 480/3076 loss=1.896381139755249\n","training log: 1 epoch, 490/3076 loss=2.2427291870117188\n","training log: 1 epoch, 500/3076 loss=2.255547285079956\n","training log: 1 epoch, 510/3076 loss=2.7331714630126953\n","training log: 1 epoch, 520/3076 loss=2.3309924602508545\n","training log: 1 epoch, 530/3076 loss=2.0216095447540283\n","training log: 1 epoch, 540/3076 loss=2.691438674926758\n","training log: 1 epoch, 550/3076 loss=2.0983498096466064\n","training log: 1 epoch, 560/3076 loss=1.987513542175293\n","training log: 1 epoch, 570/3076 loss=2.3268229961395264\n","training log: 1 epoch, 580/3076 loss=1.8468008041381836\n","training log: 1 epoch, 590/3076 loss=1.8299446105957031\n","training log: 1 epoch, 600/3076 loss=1.9700543880462646\n","training log: 1 epoch, 610/3076 loss=2.0169286727905273\n","training log: 1 epoch, 620/3076 loss=1.7463029623031616\n","training log: 1 epoch, 630/3076 loss=2.6886658668518066\n","training log: 1 epoch, 640/3076 loss=2.002349376678467\n","training log: 1 epoch, 650/3076 loss=2.836426019668579\n","training log: 1 epoch, 660/3076 loss=2.215653896331787\n","training log: 1 epoch, 670/3076 loss=1.759749412536621\n","training log: 1 epoch, 680/3076 loss=2.2462480068206787\n","training log: 1 epoch, 690/3076 loss=2.3722152709960938\n","training log: 1 epoch, 700/3076 loss=2.3666486740112305\n","training log: 1 epoch, 710/3076 loss=2.378020763397217\n","training log: 1 epoch, 720/3076 loss=1.86732017993927\n","training log: 1 epoch, 730/3076 loss=1.9543453454971313\n","training log: 1 epoch, 740/3076 loss=2.00223970413208\n","training log: 1 epoch, 750/3076 loss=2.4266202449798584\n","training log: 1 epoch, 760/3076 loss=2.053647756576538\n","training log: 1 epoch, 770/3076 loss=2.2475154399871826\n","training log: 1 epoch, 780/3076 loss=2.0161068439483643\n","training log: 1 epoch, 790/3076 loss=2.038562774658203\n","training log: 1 epoch, 800/3076 loss=2.046671152114868\n","training log: 1 epoch, 810/3076 loss=1.8976542949676514\n","training log: 1 epoch, 820/3076 loss=2.3014798164367676\n","training log: 1 epoch, 830/3076 loss=2.6288113594055176\n","training log: 1 epoch, 840/3076 loss=2.0703961849212646\n","training log: 1 epoch, 850/3076 loss=1.9628556966781616\n","training log: 1 epoch, 860/3076 loss=1.8767685890197754\n","training log: 1 epoch, 870/3076 loss=2.24902081489563\n","training log: 1 epoch, 880/3076 loss=2.1108343601226807\n","training log: 1 epoch, 890/3076 loss=1.933682918548584\n","training log: 1 epoch, 900/3076 loss=1.8525404930114746\n","training log: 1 epoch, 910/3076 loss=2.1188111305236816\n","training log: 1 epoch, 920/3076 loss=2.4079205989837646\n","training log: 1 epoch, 930/3076 loss=1.8697491884231567\n","training log: 1 epoch, 940/3076 loss=1.902410626411438\n","training log: 1 epoch, 950/3076 loss=2.2143683433532715\n","training log: 1 epoch, 960/3076 loss=2.250404119491577\n","training log: 1 epoch, 970/3076 loss=2.583366870880127\n","training log: 1 epoch, 980/3076 loss=1.909641981124878\n","training log: 1 epoch, 990/3076 loss=1.719569206237793\n","training log: 1 epoch, 1000/3076 loss=2.2727670669555664\n","training log: 1 epoch, 1010/3076 loss=2.4792728424072266\n","training log: 1 epoch, 1020/3076 loss=2.354018211364746\n","training log: 1 epoch, 1030/3076 loss=2.0903992652893066\n","training log: 1 epoch, 1040/3076 loss=2.141474723815918\n","training log: 1 epoch, 1050/3076 loss=2.0798416137695312\n","training log: 1 epoch, 1060/3076 loss=1.783476710319519\n","training log: 1 epoch, 1070/3076 loss=2.4307119846343994\n","training log: 1 epoch, 1080/3076 loss=2.265122413635254\n","training log: 1 epoch, 1090/3076 loss=2.412142515182495\n","training log: 1 epoch, 1100/3076 loss=1.8732820749282837\n","training log: 1 epoch, 1110/3076 loss=2.164069414138794\n","training log: 1 epoch, 1120/3076 loss=1.812462329864502\n","training log: 1 epoch, 1130/3076 loss=2.402315139770508\n","training log: 1 epoch, 1140/3076 loss=1.9948076009750366\n","training log: 1 epoch, 1150/3076 loss=2.0621700286865234\n","training log: 1 epoch, 1160/3076 loss=1.812887191772461\n","training log: 1 epoch, 1170/3076 loss=2.1764354705810547\n","training log: 1 epoch, 1180/3076 loss=1.9075335264205933\n","training log: 1 epoch, 1190/3076 loss=2.33127760887146\n","training log: 1 epoch, 1200/3076 loss=2.1023123264312744\n","training log: 1 epoch, 1210/3076 loss=2.095154047012329\n","training log: 1 epoch, 1220/3076 loss=2.1297807693481445\n","training log: 1 epoch, 1230/3076 loss=2.434072971343994\n","training log: 1 epoch, 1240/3076 loss=2.0339725017547607\n","training log: 1 epoch, 1250/3076 loss=1.9952119588851929\n","training log: 1 epoch, 1260/3076 loss=2.244309186935425\n","training log: 1 epoch, 1270/3076 loss=1.697061538696289\n","training log: 1 epoch, 1280/3076 loss=2.0640347003936768\n","training log: 1 epoch, 1290/3076 loss=2.36724853515625\n","training log: 1 epoch, 1300/3076 loss=2.1325297355651855\n","training log: 1 epoch, 1310/3076 loss=2.166266679763794\n","training log: 1 epoch, 1320/3076 loss=2.067317008972168\n","training log: 1 epoch, 1330/3076 loss=2.230409860610962\n","training log: 1 epoch, 1340/3076 loss=2.0693142414093018\n","training log: 1 epoch, 1350/3076 loss=2.0986366271972656\n","training log: 1 epoch, 1360/3076 loss=2.13096284866333\n","training log: 1 epoch, 1370/3076 loss=2.0358669757843018\n","training log: 1 epoch, 1380/3076 loss=2.378718376159668\n","training log: 1 epoch, 1390/3076 loss=2.01955509185791\n","training log: 1 epoch, 1400/3076 loss=2.445221424102783\n","training log: 1 epoch, 1410/3076 loss=1.8314534425735474\n","training log: 1 epoch, 1420/3076 loss=2.088789463043213\n","training log: 1 epoch, 1430/3076 loss=2.2046661376953125\n","training log: 1 epoch, 1440/3076 loss=1.6845097541809082\n","training log: 1 epoch, 1450/3076 loss=2.2403032779693604\n","training log: 1 epoch, 1460/3076 loss=1.8550480604171753\n","training log: 1 epoch, 1470/3076 loss=2.0793378353118896\n","training log: 1 epoch, 1480/3076 loss=2.220019817352295\n","training log: 1 epoch, 1490/3076 loss=2.0437698364257812\n","training log: 1 epoch, 1500/3076 loss=1.995517611503601\n","training log: 1 epoch, 1510/3076 loss=2.127866744995117\n","training log: 1 epoch, 1520/3076 loss=1.8982762098312378\n","training log: 1 epoch, 1530/3076 loss=2.0774741172790527\n","training log: 1 epoch, 1540/3076 loss=1.9066082239151\n","training log: 1 epoch, 1550/3076 loss=1.8245905637741089\n","training log: 1 epoch, 1560/3076 loss=1.9887149333953857\n","training log: 1 epoch, 1570/3076 loss=2.2277960777282715\n","training log: 1 epoch, 1580/3076 loss=2.079782009124756\n","training log: 1 epoch, 1590/3076 loss=1.980839490890503\n","training log: 1 epoch, 1600/3076 loss=2.1966965198516846\n","training log: 1 epoch, 1610/3076 loss=1.9679656028747559\n","training log: 1 epoch, 1620/3076 loss=2.1522610187530518\n","training log: 1 epoch, 1630/3076 loss=1.9255945682525635\n","training log: 1 epoch, 1640/3076 loss=1.7296299934387207\n","training log: 1 epoch, 1650/3076 loss=1.8689721822738647\n","training log: 1 epoch, 1660/3076 loss=1.868844985961914\n","training log: 1 epoch, 1670/3076 loss=2.0275306701660156\n","training log: 1 epoch, 1680/3076 loss=1.852512240409851\n","training log: 1 epoch, 1690/3076 loss=2.2223939895629883\n","training log: 1 epoch, 1700/3076 loss=2.0810892581939697\n","training log: 1 epoch, 1710/3076 loss=1.6592860221862793\n","training log: 1 epoch, 1720/3076 loss=1.8588371276855469\n","training log: 1 epoch, 1730/3076 loss=1.8793022632598877\n","training log: 1 epoch, 1740/3076 loss=2.0083837509155273\n","training log: 1 epoch, 1750/3076 loss=2.1419942378997803\n","training log: 1 epoch, 1760/3076 loss=1.782540202140808\n","training log: 1 epoch, 1770/3076 loss=2.031721591949463\n","training log: 1 epoch, 1780/3076 loss=2.1149561405181885\n","training log: 1 epoch, 1790/3076 loss=2.819675922393799\n","training log: 1 epoch, 1800/3076 loss=1.8663225173950195\n","training log: 1 epoch, 1810/3076 loss=1.7477073669433594\n","training log: 1 epoch, 1820/3076 loss=1.648837924003601\n","training log: 1 epoch, 1830/3076 loss=1.9606781005859375\n","training log: 1 epoch, 1840/3076 loss=1.5267713069915771\n","training log: 1 epoch, 1850/3076 loss=1.9217565059661865\n","training log: 1 epoch, 1860/3076 loss=2.007519245147705\n","training log: 1 epoch, 1870/3076 loss=1.819130301475525\n","training log: 1 epoch, 1880/3076 loss=2.0863895416259766\n","training log: 1 epoch, 1890/3076 loss=2.0996620655059814\n","training log: 1 epoch, 1900/3076 loss=1.7742412090301514\n","training log: 1 epoch, 1910/3076 loss=2.076976776123047\n","training log: 1 epoch, 1920/3076 loss=2.094895839691162\n","training log: 1 epoch, 1930/3076 loss=1.8470054864883423\n","training log: 1 epoch, 1940/3076 loss=1.638865351676941\n","training log: 1 epoch, 1950/3076 loss=2.0099735260009766\n","training log: 1 epoch, 1960/3076 loss=2.2888455390930176\n","training log: 1 epoch, 1970/3076 loss=1.7061774730682373\n","training log: 1 epoch, 1980/3076 loss=1.6564593315124512\n","training log: 1 epoch, 1990/3076 loss=1.8741981983184814\n","training log: 1 epoch, 2000/3076 loss=2.1558303833007812\n","training log: 1 epoch, 2010/3076 loss=2.218744993209839\n","training log: 1 epoch, 2020/3076 loss=1.8331716060638428\n","training log: 1 epoch, 2030/3076 loss=2.1570937633514404\n","training log: 1 epoch, 2040/3076 loss=1.4360849857330322\n","training log: 1 epoch, 2050/3076 loss=1.7174935340881348\n","training log: 1 epoch, 2060/3076 loss=2.1574034690856934\n","training log: 1 epoch, 2070/3076 loss=2.359262704849243\n","training log: 1 epoch, 2080/3076 loss=1.7753925323486328\n","training log: 1 epoch, 2090/3076 loss=1.8909984827041626\n","training log: 1 epoch, 2100/3076 loss=1.5971453189849854\n","training log: 1 epoch, 2110/3076 loss=2.0273544788360596\n","training log: 1 epoch, 2120/3076 loss=2.6046242713928223\n","training log: 1 epoch, 2130/3076 loss=2.096083164215088\n","training log: 1 epoch, 2140/3076 loss=2.102860450744629\n","training log: 1 epoch, 2150/3076 loss=1.9738974571228027\n","training log: 1 epoch, 2160/3076 loss=1.826403021812439\n","training log: 1 epoch, 2170/3076 loss=2.1741302013397217\n","training log: 1 epoch, 2180/3076 loss=2.0846822261810303\n","training log: 1 epoch, 2190/3076 loss=2.0522804260253906\n","training log: 1 epoch, 2200/3076 loss=2.007237672805786\n","training log: 1 epoch, 2210/3076 loss=1.8566418886184692\n","training log: 1 epoch, 2220/3076 loss=1.9812674522399902\n","training log: 1 epoch, 2230/3076 loss=2.1415090560913086\n","training log: 1 epoch, 2240/3076 loss=2.1319265365600586\n","training log: 1 epoch, 2250/3076 loss=1.8296266794204712\n","training log: 1 epoch, 2260/3076 loss=1.821007251739502\n","training log: 1 epoch, 2270/3076 loss=1.6314483880996704\n","training log: 1 epoch, 2280/3076 loss=1.9312400817871094\n","training log: 1 epoch, 2290/3076 loss=2.112046003341675\n","training log: 1 epoch, 2300/3076 loss=1.982805609703064\n","training log: 1 epoch, 2310/3076 loss=2.407996892929077\n","training log: 1 epoch, 2320/3076 loss=1.7327228784561157\n","training log: 1 epoch, 2330/3076 loss=1.7817336320877075\n","training log: 1 epoch, 2340/3076 loss=2.3570187091827393\n","training log: 1 epoch, 2350/3076 loss=2.3255186080932617\n","training log: 1 epoch, 2360/3076 loss=2.0614521503448486\n","training log: 1 epoch, 2370/3076 loss=1.9712989330291748\n","training log: 1 epoch, 2380/3076 loss=2.0701208114624023\n","training log: 1 epoch, 2390/3076 loss=1.8632413148880005\n","training log: 1 epoch, 2400/3076 loss=1.6728354692459106\n","training log: 1 epoch, 2410/3076 loss=1.9740599393844604\n","training log: 1 epoch, 2420/3076 loss=1.7484685182571411\n","training log: 1 epoch, 2430/3076 loss=2.306603193283081\n","training log: 1 epoch, 2440/3076 loss=1.6680454015731812\n","training log: 1 epoch, 2450/3076 loss=1.654589295387268\n","training log: 1 epoch, 2460/3076 loss=1.7784878015518188\n","training log: 1 epoch, 2470/3076 loss=1.8662323951721191\n","training log: 1 epoch, 2480/3076 loss=1.863662838935852\n","training log: 1 epoch, 2490/3076 loss=2.332496404647827\n","training log: 1 epoch, 2500/3076 loss=1.8843261003494263\n","training log: 1 epoch, 2510/3076 loss=2.0479323863983154\n","training log: 1 epoch, 2520/3076 loss=1.95787513256073\n","training log: 1 epoch, 2530/3076 loss=1.6830939054489136\n","training log: 1 epoch, 2540/3076 loss=1.801347255706787\n","training log: 1 epoch, 2550/3076 loss=1.7514318227767944\n","training log: 1 epoch, 2560/3076 loss=1.810538649559021\n","training log: 1 epoch, 2570/3076 loss=1.5667258501052856\n","training log: 1 epoch, 2580/3076 loss=2.205063581466675\n","training log: 1 epoch, 2590/3076 loss=2.3262879848480225\n","training log: 1 epoch, 2600/3076 loss=2.005566358566284\n","training log: 1 epoch, 2610/3076 loss=1.9915119409561157\n","training log: 1 epoch, 2620/3076 loss=1.6014397144317627\n","training log: 1 epoch, 2630/3076 loss=1.4343136548995972\n","training log: 1 epoch, 2640/3076 loss=1.6455094814300537\n","training log: 1 epoch, 2650/3076 loss=2.1251800060272217\n","training log: 1 epoch, 2660/3076 loss=2.03584361076355\n","training log: 1 epoch, 2670/3076 loss=1.626950979232788\n","training log: 1 epoch, 2680/3076 loss=1.7884999513626099\n","training log: 1 epoch, 2690/3076 loss=1.5674749612808228\n","training log: 1 epoch, 2700/3076 loss=1.9543133974075317\n","training log: 1 epoch, 2710/3076 loss=1.853598713874817\n","training log: 1 epoch, 2720/3076 loss=2.0311834812164307\n","training log: 1 epoch, 2730/3076 loss=1.9205683469772339\n","training log: 1 epoch, 2740/3076 loss=1.7583812475204468\n","training log: 1 epoch, 2750/3076 loss=1.9233729839324951\n","training log: 1 epoch, 2760/3076 loss=1.673035740852356\n","training log: 1 epoch, 2770/3076 loss=1.899361252784729\n","training log: 1 epoch, 2780/3076 loss=1.6575607061386108\n","training log: 1 epoch, 2790/3076 loss=1.6934096813201904\n","training log: 1 epoch, 2800/3076 loss=1.887115716934204\n","training log: 1 epoch, 2810/3076 loss=1.5745505094528198\n","training log: 1 epoch, 2820/3076 loss=1.5162348747253418\n","training log: 1 epoch, 2830/3076 loss=1.5746949911117554\n","training log: 1 epoch, 2840/3076 loss=1.504516839981079\n","training log: 1 epoch, 2850/3076 loss=1.9815282821655273\n","training log: 1 epoch, 2860/3076 loss=1.7058154344558716\n","training log: 1 epoch, 2870/3076 loss=1.8495832681655884\n","training log: 1 epoch, 2880/3076 loss=1.4409162998199463\n","training log: 1 epoch, 2890/3076 loss=1.4277220964431763\n","training log: 1 epoch, 2900/3076 loss=2.205700635910034\n","training log: 1 epoch, 2910/3076 loss=1.5981942415237427\n","training log: 1 epoch, 2920/3076 loss=2.2698397636413574\n","training log: 1 epoch, 2930/3076 loss=1.9861820936203003\n","training log: 1 epoch, 2940/3076 loss=1.5474704504013062\n","training log: 1 epoch, 2950/3076 loss=1.424481987953186\n","training log: 1 epoch, 2960/3076 loss=1.9427931308746338\n","training log: 1 epoch, 2970/3076 loss=1.7649110555648804\n","training log: 1 epoch, 2980/3076 loss=1.8330942392349243\n","training log: 1 epoch, 2990/3076 loss=1.737334966659546\n","training log: 1 epoch, 3000/3076 loss=1.9433112144470215\n","training log: 1 epoch, 3010/3076 loss=1.8053295612335205\n","training log: 1 epoch, 3020/3076 loss=2.0792009830474854\n","training log: 1 epoch, 3030/3076 loss=2.060393810272217\n","training log: 1 epoch, 3040/3076 loss=1.884380578994751\n","training log: 1 epoch, 3050/3076 loss=1.821703553199768\n","training log: 1 epoch, 3060/3076 loss=1.9891164302825928\n","training log: 1 epoch, 3070/3076 loss=2.015561580657959"],"metadata":{"id":"s-e9QFSu01-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"NVYRE8JnoqEx","executionInfo":{"status":"ok","timestamp":1648660588550,"user_tz":-540,"elapsed":2954,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["#torch.save(net.state_dict(), \"/content/drive/MyDrive/lab/2021/MyTabCNN/model/model_para.pth\")\n","\n","# 保存したモデルを読み込む。\n","net: MyVGG = MyVGG()\n","net= torch.load('/content/drive/MyDrive/lab/2021/MyTabCNN/model/model_vgg_bekku.pth')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"OihZBTm0Z2PM","executionInfo":{"status":"ok","timestamp":1648660595739,"user_tz":-540,"elapsed":493,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[],"source":["def tab2pitch(tab):\n","    pitch_vector = np.zeros(44)\n","    string_pitches = [40, 45, 50, 55, 59, 64]\n","    for string_num in range(len(tab)):\n","        fret_class = tab[string_num]\n","        # 0 means that the string is closed \n","        if fret_class > 0:\n","            pitch_num = fret_class + string_pitches[string_num] - 41\n","            pitch_vector[pitch_num] = 1\n","    return pitch_vector\n","\n","def pitch_precision(pred, gt):\n","    pitch_pred = np.array(list(map(tab2pitch,pred)))\n","    pitch_gt = np.array(list(map(tab2pitch,gt)))\n","    numerator = np.sum(np.multiply(pitch_pred, pitch_gt).flatten())\n","    denominator = np.sum(pitch_pred.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def pitch_recall(pred, gt):\n","    pitch_pred = np.array(list(map(tab2pitch,pred)))\n","    pitch_gt = np.array(list(map(tab2pitch,gt)))\n","    numerator = np.sum(np.multiply(pitch_pred, pitch_gt).flatten())\n","    denominator = np.sum(pitch_gt.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def pitch_f_measure(pred, gt):\n","    p = pitch_precision(pred, gt)\n","    r = pitch_recall(pred, gt)\n","    f = (2 * p * r) / (p + r)\n","    return f\n","\n","def tab2bin(tab):\n","    tab_arr = np.zeros((6,20))\n","    for string_num in range(len(tab)):\n","        fret_class = tab[string_num]\n","        # 0 means that the string is closed \n","        if fret_class > 0:\n","            fret_num = fret_class - 1\n","            tab_arr[string_num][fret_num] = 1\n","    return tab_arr\n","\n","def tab_precision(pred, gt):\n","    # get rid of \"closed\" class, as we only want to count positives\n","    tab_pred = np.array(list(map(tab2bin,pred)))\n","    tab_gt = np.array(list(map(tab2bin,gt)))\n","    numerator = np.sum(np.multiply(tab_pred, tab_gt).flatten())\n","    denominator = np.sum(tab_pred.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def tab_recall(pred, gt):\n","    # get rid of \"closed\" class, as we only want to count positives\n","    tab_pred = np.array(list(map(tab2bin,pred)))\n","    tab_gt = np.array(list(map(tab2bin,gt)))\n","    numerator = np.sum(np.multiply(tab_pred, tab_gt).flatten())\n","    denominator = np.sum(tab_gt.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def tab_f_measure(pred, gt):\n","    p = tab_precision(pred, gt)\n","    r = tab_recall(pred, gt)\n","    f = (2 * p * r) / (p + r)\n","    return f\n","\n","def tab_disamb(pred, gt):\n","    tp = tab_precision(pred, gt)\n","    pp = pitch_precision(pred, gt)\n","    return tp / pp"]},{"cell_type":"code","source":["training_generator, validation_generator = partition_data(0)"],"metadata":{"id":"Eb9jY7JPOEJf","executionInfo":{"status":"ok","timestamp":1648660601014,"user_tz":-540,"elapsed":331,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":4253421,"status":"error","timestamp":1648632795151,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"UjpkAGh2g3L1","outputId":"4d8ae6d7-5c0e-409f-e4da-e532e77c183e"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-48b8a743f1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mdenominator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-e04606fcac02>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#---pitch-test---\n","from tqdm import tqdm\n","\n","net: MyVGG = MyVGG()\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","net= torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/model_vgg_bekku.pth\")\n","history = {\n","    'train_loss': [],\n","    'train_acc': [],\n","    'test_acc': []\n","}\n","\n","predictions_dir_path = \"/content/drive/MyDrive/lab/2021/MyTabCNN/model/predictions\"\n","#os.mkdir(predictions_dir_path)\n","\n","net.eval()\n","denominator = 0\n","training_generator, validation_generator = partition_data(0)\n","results = {}\n","results[\"precision\"] = []\n","results[\"recall\"] = []\n","results[\"f-measure\"] = []\n","for i, (images, labels) in enumerate(validation_generator):\n","  images = torch.Tensor(np.transpose(images, (0,3,1,2)))\n","  labels = torch.Tensor(labels)\n","  outputs = net(images)\n","  denominator += 1\n","  _, predicted = torch.max(outputs.data, 2)\n","  gt = np.argmax(labels, 2)\n","  pred = pitch_precision(predicted, gt)\n","  recall = pitch_recall(predicted, gt)\n","  f_measure = pitch_f_measure(predicted, gt)\n","  results[\"precision\"].append(pred)\n","  results[\"recall\"].append(recall)\n","  results[\"f-measure\"].append(f_measure)"]},{"cell_type":"code","source":["precision_mean = sum(results[\"precision\"])/len(results[\"precision\"])\n","recall_mean = sum(results[\"recall\"])/len(results[\"recall\"])\n","Fmeasure_mean = sum(results[\"f-measure\"])/len(results[\"f-measure\"])\n","print(precision_mean, recall_mean, Fmeasure_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tK_n6XMlLB7i","executionInfo":{"status":"ok","timestamp":1648633240986,"user_tz":-540,"elapsed":3,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"f737f71f-62cf-44db-935e-5fe044f1ebd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7977688217672034 0.5660336704207104 0.6471972026398908\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DIPFQ4LhqD7r","outputId":"e95ae37a-8299-4ec1-cd3c-206020c99979","executionInfo":{"status":"error","timestamp":1648665080388,"user_tz":-540,"elapsed":4330580,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n"]},{"output_type":"stream","name":"stdout","text":["308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","640\n","641\n","642\n","643\n","644\n","645\n","646\n","647\n","648\n","649\n","650\n","651\n","652\n","653\n","654\n","655\n","656\n","657\n","658\n","659\n","660\n","661\n","662\n","663\n","664\n","665\n","666\n","667\n","668\n","669\n","670\n","671\n","672\n","673\n","674\n","675\n","676\n","677\n","678\n","679\n","680\n","681\n","682\n","683\n","684\n","685\n","686\n","687\n","688\n","689\n","690\n","691\n","692\n","693\n","694\n","695\n","696\n","697\n","698\n","699\n","700\n","701\n","702\n","703\n","704\n","705\n","706\n","707\n","708\n","709\n","710\n","711\n","712\n","713\n","714\n","715\n","716\n","717\n","718\n","719\n","720\n","721\n","722\n","723\n","724\n","725\n","726\n","727\n","728\n","729\n","730\n","731\n","732\n","733\n","734\n","735\n","736\n","737\n","738\n","739\n","740\n","741\n","742\n","743\n","744\n","745\n","746\n","747\n","748\n","749\n","750\n","751\n","752\n","753\n","754\n","755\n","756\n","757\n","758\n","759\n","760\n","761\n","762\n","763\n","764\n","765\n","766\n","767\n","768\n","769\n","770\n","771\n","772\n","773\n","774\n","775\n","776\n","777\n","778\n","779\n","780\n","781\n","782\n","783\n","784\n","785\n","786\n","787\n","788\n","789\n","790\n","791\n","792\n","793\n","794\n","795\n","796\n","797\n","798\n","799\n","800\n","801\n","802\n","803\n","804\n","805\n","806\n","807\n","808\n","809\n","810\n","811\n","812\n","813\n","814\n","815\n","816\n","817\n","818\n","819\n","820\n","821\n","822\n","823\n","824\n","825\n","826\n","827\n","828\n","829\n","830\n","831\n","832\n","833\n","834\n","835\n","836\n","837\n","838\n","839\n","840\n","841\n","842\n","843\n","844\n","845\n","846\n","847\n","848\n","849\n","850\n","851\n","852\n","853\n","854\n","855\n","856\n","857\n","858\n","859\n","860\n","861\n","862\n","863\n","864\n","865\n","866\n","867\n","868\n","869\n","870\n","871\n","872\n","873\n","874\n","875\n","876\n","877\n","878\n","879\n","880\n","881\n","882\n","883\n","884\n","885\n","886\n","887\n","888\n","889\n","890\n","891\n","892\n","893\n","894\n","895\n","896\n","897\n","898\n","899\n","900\n","901\n","902\n","903\n","904\n","905\n","906\n","907\n","908\n","909\n","910\n","911\n","912\n","913\n","914\n","915\n","916\n","917\n","918\n","919\n","920\n","921\n","922\n","923\n","924\n","925\n","926\n","927\n","928\n","929\n","930\n","931\n","932\n","933\n","934\n","935\n","936\n","937\n","938\n","939\n","940\n","941\n","942\n","943\n","944\n","945\n","946\n","947\n","948\n","949\n","950\n","951\n","952\n","953\n","954\n","955\n","956\n","957\n","958\n","959\n","960\n","961\n","962\n","963\n","964\n","965\n","966\n","967\n","968\n","969\n","970\n","971\n","972\n","973\n","974\n","975\n","976\n","977\n","978\n","979\n","980\n","981\n","982\n","983\n","984\n","985\n","986\n","987\n","988\n","989\n","990\n","991\n","992\n","993\n","994\n","995\n","996\n","997\n","998\n","999\n","1000\n","1001\n","1002\n","1003\n","1004\n","1005\n","1006\n","1007\n","1008\n","1009\n","1010\n","1011\n","1012\n","1013\n","1014\n","1015\n","1016\n","1017\n","1018\n","1019\n","1020\n","1021\n","1022\n","1023\n","1024\n","1025\n","1026\n","1027\n","1028\n","1029\n","1030\n","1031\n","1032\n","1033\n","1034\n","1035\n","1036\n","1037\n","1038\n","1039\n","1040\n","1041\n","1042\n","1043\n","1044\n","1045\n","1046\n","1047\n","1048\n","1049\n","1050\n","1051\n","1052\n","1053\n","1054\n","1055\n","1056\n","1057\n","1058\n","1059\n","1060\n","1061\n","1062\n","1063\n","1064\n","1065\n","1066\n","1067\n","1068\n","1069\n","1070\n","1071\n","1072\n","1073\n","1074\n","1075\n","1076\n","1077\n","1078\n","1079\n","1080\n","1081\n","1082\n","1083\n","1084\n","1085\n","1086\n","1087\n","1088\n","1089\n","1090\n","1091\n","1092\n","1093\n","1094\n","1095\n","1096\n","1097\n","1098\n","1099\n","1100\n","1101\n","1102\n","1103\n","1104\n","1105\n","1106\n","1107\n","1108\n","1109\n","1110\n","1111\n","1112\n","1113\n","1114\n","1115\n","1116\n","1117\n","1118\n","1119\n","1120\n","1121\n","1122\n","1123\n","1124\n","1125\n","1126\n","1127\n","1128\n","1129\n","1130\n","1131\n","1132\n","1133\n","1134\n","1135\n","1136\n","1137\n","1138\n","1139\n","1140\n","1141\n","1142\n","1143\n","1144\n","1145\n","1146\n","1147\n","1148\n","1149\n","1150\n","1151\n","1152\n","1153\n","1154\n","1155\n","1156\n","1157\n","1158\n","1159\n","1160\n","1161\n","1162\n","1163\n","1164\n","1165\n","1166\n","1167\n","1168\n","1169\n","1170\n","1171\n","1172\n","1173\n","1174\n","1175\n","1176\n","1177\n","1178\n","1179\n","1180\n","1181\n","1182\n","1183\n","1184\n","1185\n","1186\n","1187\n","1188\n","1189\n","1190\n","1191\n","1192\n","1193\n","1194\n","1195\n","1196\n","1197\n","1198\n","1199\n","1200\n","1201\n","1202\n","1203\n","1204\n","1205\n","1206\n","1207\n","1208\n","1209\n","1210\n","1211\n","1212\n","1213\n","1214\n","1215\n","1216\n","1217\n","1218\n","1219\n","1220\n","1221\n","1222\n","1223\n","1224\n","1225\n","1226\n","1227\n","1228\n","1229\n","1230\n","1231\n","1232\n","1233\n","1234\n","1235\n","1236\n","1237\n","1238\n","1239\n","1240\n","1241\n","1242\n","1243\n","1244\n","1245\n","1246\n","1247\n","1248\n","1249\n","1250\n","1251\n","1252\n","1253\n","1254\n","1255\n","1256\n","1257\n","1258\n","1259\n","1260\n","1261\n","1262\n","1263\n","1264\n","1265\n","1266\n","1267\n","1268\n","1269\n","1270\n","1271\n","1272\n","1273\n","1274\n","1275\n","1276\n","1277\n","1278\n","1279\n","1280\n","1281\n","1282\n","1283\n","1284\n","1285\n","1286\n","1287\n","1288\n","1289\n","1290\n","1291\n","1292\n","1293\n","1294\n","1295\n","1296\n","1297\n","1298\n","1299\n","1300\n","1301\n","1302\n","1303\n","1304\n","1305\n","1306\n","1307\n","1308\n","1309\n","1310\n","1311\n","1312\n","1313\n","1314\n","1315\n","1316\n","1317\n","1318\n","1319\n","1320\n","1321\n","1322\n","1323\n","1324\n","1325\n","1326\n","1327\n","1328\n","1329\n","1330\n","1331\n","1332\n","1333\n","1334\n","1335\n","1336\n","1337\n","1338\n","1339\n","1340\n","1341\n","1342\n","1343\n","1344\n","1345\n","1346\n","1347\n","1348\n","1349\n","1350\n","1351\n","1352\n","1353\n","1354\n","1355\n","1356\n","1357\n","1358\n","1359\n","1360\n","1361\n","1362\n","1363\n","1364\n","1365\n","1366\n","1367\n","1368\n","1369\n","1370\n","1371\n","1372\n","1373\n","1374\n","1375\n","1376\n","1377\n","1378\n","1379\n","1380\n","1381\n","1382\n","1383\n","1384\n","1385\n","1386\n","1387\n","1388\n","1389\n","1390\n","1391\n","1392\n","1393\n","1394\n","1395\n","1396\n","1397\n","1398\n","1399\n","1400\n","1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n","1440\n","1441\n","1442\n","1443\n","1444\n","1445\n","1446\n","1447\n","1448\n","1449\n","1450\n","1451\n","1452\n","1453\n","1454\n","1455\n","1456\n","1457\n","1458\n","1459\n","1460\n","1461\n","1462\n","1463\n","1464\n","1465\n","1466\n","1467\n","1468\n","1469\n","1470\n","1471\n","1472\n","1473\n","1474\n","1475\n","1476\n","1477\n","1478\n","1479\n","1480\n","1481\n","1482\n","1483\n","1484\n","1485\n","1486\n","1487\n","1488\n","1489\n","1490\n","1491\n","1492\n","1493\n","1494\n","1495\n","1496\n","1497\n","1498\n","1499\n","1500\n","1501\n","1502\n","1503\n","1504\n","1505\n","1506\n","1507\n","1508\n","1509\n","1510\n","1511\n","1512\n","1513\n","1514\n","1515\n","1516\n","1517\n","1518\n","1519\n","1520\n","1521\n","1522\n","1523\n","1524\n","1525\n","1526\n","1527\n","1528\n","1529\n","1530\n","1531\n","1532\n","1533\n","1534\n","1535\n","1536\n","1537\n","1538\n","1539\n","1540\n","1541\n","1542\n","1543\n","1544\n","1545\n","1546\n","1547\n","1548\n","1549\n","1550\n","1551\n","1552\n","1553\n","1554\n","1555\n","1556\n","1557\n","1558\n","1559\n","1560\n","1561\n","1562\n","1563\n","1564\n","1565\n","1566\n","1567\n","1568\n","1569\n","1570\n","1571\n","1572\n","1573\n","1574\n","1575\n","1576\n","1577\n","1578\n","1579\n","1580\n","1581\n","1582\n","1583\n","1584\n","1585\n","1586\n","1587\n","1588\n","1589\n","1590\n","1591\n","1592\n","1593\n","1594\n","1595\n","1596\n","1597\n","1598\n","1599\n","1600\n","1601\n","1602\n","1603\n","1604\n","1605\n","1606\n","1607\n","1608\n","1609\n","1610\n","1611\n","1612\n","1613\n","1614\n","1615\n","1616\n","1617\n","1618\n","1619\n","1620\n","1621\n","1622\n","1623\n","1624\n","1625\n","1626\n","1627\n","1628\n","1629\n","1630\n","1631\n","1632\n","1633\n","1634\n","1635\n","1636\n","1637\n","1638\n","1639\n","1640\n","1641\n","1642\n","1643\n","1644\n","1645\n","1646\n","1647\n","1648\n","1649\n","1650\n","1651\n","1652\n","1653\n","1654\n","1655\n","1656\n","1657\n","1658\n","1659\n","1660\n","1661\n","1662\n","1663\n","1664\n","1665\n","1666\n","1667\n","1668\n","1669\n","1670\n","1671\n","1672\n","1673\n","1674\n","1675\n","1676\n","1677\n","1678\n","1679\n","1680\n","1681\n","1682\n","1683\n","1684\n","1685\n","1686\n","1687\n","1688\n","1689\n","1690\n","1691\n","1692\n","1693\n","1694\n","1695\n","1696\n","1697\n","1698\n","1699\n","1700\n","1701\n","1702\n","1703\n","1704\n","1705\n","1706\n","1707\n","1708\n","1709\n","1710\n","1711\n","1712\n","1713\n","1714\n","1715\n","1716\n","1717\n","1718\n","1719\n","1720\n","1721\n","1722\n","1723\n","1724\n","1725\n","1726\n","1727\n","1728\n","1729\n","1730\n","1731\n","1732\n","1733\n","1734\n","1735\n","1736\n","1737\n","1738\n","1739\n","1740\n","1741\n","1742\n","1743\n","1744\n","1745\n","1746\n","1747\n","1748\n","1749\n","1750\n","1751\n","1752\n","1753\n","1754\n","1755\n","1756\n","1757\n","1758\n","1759\n","1760\n","1761\n","1762\n","1763\n","1764\n","1765\n","1766\n","1767\n","1768\n","1769\n","1770\n","1771\n","1772\n","1773\n","1774\n","1775\n","1776\n","1777\n","1778\n","1779\n","1780\n","1781\n","1782\n","1783\n","1784\n","1785\n","1786\n","1787\n","1788\n","1789\n","1790\n","1791\n","1792\n","1793\n","1794\n","1795\n","1796\n","1797\n","1798\n","1799\n","1800\n","1801\n","1802\n","1803\n","1804\n","1805\n","1806\n","1807\n","1808\n","1809\n","1810\n","1811\n","1812\n","1813\n","1814\n","1815\n","1816\n","1817\n","1818\n","1819\n","1820\n","1821\n","1822\n","1823\n","1824\n","1825\n","1826\n","1827\n","1828\n","1829\n","1830\n","1831\n","1832\n","1833\n","1834\n","1835\n","1836\n","1837\n","1838\n","1839\n","1840\n","1841\n","1842\n","1843\n","1844\n","1845\n","1846\n","1847\n","1848\n","1849\n","1850\n","1851\n","1852\n","1853\n","1854\n","1855\n","1856\n","1857\n","1858\n","1859\n","1860\n","1861\n","1862\n","1863\n","1864\n","1865\n","1866\n","1867\n","1868\n","1869\n","1870\n","1871\n","1872\n","1873\n","1874\n","1875\n","1876\n","1877\n","1878\n","1879\n","1880\n","1881\n","1882\n","1883\n","1884\n","1885\n","1886\n","1887\n","1888\n","1889\n","1890\n","1891\n","1892\n","1893\n","1894\n","1895\n","1896\n","1897\n","1898\n","1899\n","1900\n","1901\n","1902\n","1903\n","1904\n","1905\n","1906\n","1907\n","1908\n","1909\n","1910\n","1911\n","1912\n","1913\n","1914\n","1915\n","1916\n","1917\n","1918\n","1919\n","1920\n","1921\n","1922\n","1923\n","1924\n","1925\n","1926\n","1927\n","1928\n","1929\n","1930\n","1931\n","1932\n","1933\n","1934\n","1935\n","1936\n","1937\n","1938\n","1939\n","1940\n","1941\n","1942\n","1943\n","1944\n","1945\n","1946\n","1947\n","1948\n","1949\n","1950\n","1951\n","1952\n","1953\n","1954\n","1955\n","1956\n","1957\n","1958\n","1959\n","1960\n","1961\n","1962\n","1963\n","1964\n","1965\n","1966\n","1967\n","1968\n","1969\n","1970\n","1971\n","1972\n","1973\n","1974\n","1975\n","1976\n","1977\n","1978\n","1979\n","1980\n","1981\n","1982\n","1983\n","1984\n","1985\n","1986\n","1987\n","1988\n","1989\n","1990\n","1991\n","1992\n","1993\n","1994\n","1995\n","1996\n","1997\n","1998\n","1999\n","2000\n","2001\n","2002\n","2003\n","2004\n","2005\n","2006\n","2007\n","2008\n","2009\n","2010\n","2011\n","2012\n","2013\n","2014\n","2015\n","2016\n","2017\n","2018\n","2019\n","2020\n","2021\n","2022\n","2023\n","2024\n","2025\n","2026\n","2027\n","2028\n","2029\n","2030\n","2031\n","2032\n","2033\n","2034\n","2035\n","2036\n","2037\n","2038\n","2039\n","2040\n","2041\n","2042\n","2043\n","2044\n","2045\n","2046\n","2047\n","2048\n","2049\n","2050\n","2051\n","2052\n","2053\n","2054\n","2055\n","2056\n","2057\n","2058\n","2059\n","2060\n","2061\n","2062\n","2063\n","2064\n","2065\n","2066\n","2067\n","2068\n","2069\n","2070\n","2071\n","2072\n","2073\n","2074\n","2075\n","2076\n","2077\n","2078\n","2079\n","2080\n","2081\n","2082\n","2083\n","2084\n","2085\n","2086\n","2087\n","2088\n","2089\n","2090\n","2091\n","2092\n","2093\n","2094\n","2095\n","2096\n","2097\n","2098\n","2099\n","2100\n","2101\n","2102\n","2103\n","2104\n","2105\n","2106\n","2107\n","2108\n","2109\n","2110\n","2111\n","2112\n","2113\n","2114\n","2115\n","2116\n","2117\n","2118\n","2119\n","2120\n","2121\n","2122\n","2123\n","2124\n","2125\n","2126\n","2127\n","2128\n","2129\n","2130\n","2131\n","2132\n","2133\n","2134\n","2135\n","2136\n","2137\n","2138\n","2139\n","2140\n","2141\n","2142\n","2143\n","2144\n","2145\n","2146\n","2147\n","2148\n","2149\n","2150\n","2151\n","2152\n","2153\n","2154\n","2155\n","2156\n","2157\n","2158\n","2159\n","2160\n","2161\n","2162\n","2163\n","2164\n","2165\n","2166\n","2167\n","2168\n","2169\n","2170\n","2171\n","2172\n","2173\n","2174\n","2175\n","2176\n","2177\n","2178\n","2179\n","2180\n","2181\n","2182\n","2183\n","2184\n","2185\n","2186\n","2187\n","2188\n","2189\n","2190\n","2191\n","2192\n","2193\n","2194\n","2195\n","2196\n","2197\n","2198\n","2199\n","2200\n","2201\n","2202\n","2203\n","2204\n","2205\n","2206\n","2207\n","2208\n","2209\n","2210\n","2211\n","2212\n","2213\n","2214\n","2215\n","2216\n","2217\n","2218\n","2219\n","2220\n","2221\n","2222\n","2223\n","2224\n","2225\n","2226\n","2227\n","2228\n","2229\n","2230\n","2231\n","2232\n","2233\n","2234\n","2235\n","2236\n","2237\n","2238\n","2239\n","2240\n","2241\n","2242\n","2243\n","2244\n","2245\n","2246\n","2247\n","2248\n","2249\n","2250\n","2251\n","2252\n","2253\n","2254\n","2255\n","2256\n","2257\n","2258\n","2259\n","2260\n","2261\n","2262\n","2263\n","2264\n","2265\n","2266\n","2267\n","2268\n","2269\n","2270\n","2271\n","2272\n","2273\n","2274\n","2275\n","2276\n","2277\n","2278\n","2279\n","2280\n","2281\n","2282\n","2283\n","2284\n","2285\n","2286\n","2287\n","2288\n","2289\n","2290\n","2291\n","2292\n","2293\n","2294\n","2295\n","2296\n","2297\n","2298\n","2299\n","2300\n","2301\n","2302\n","2303\n","2304\n","2305\n","2306\n","2307\n","2308\n","2309\n","2310\n","2311\n","2312\n","2313\n","2314\n","2315\n","2316\n","2317\n","2318\n","2319\n","2320\n","2321\n","2322\n","2323\n","2324\n","2325\n","2326\n","2327\n","2328\n","2329\n","2330\n","2331\n","2332\n","2333\n","2334\n","2335\n","2336\n","2337\n","2338\n","2339\n","2340\n","2341\n","2342\n","2343\n","2344\n","2345\n","2346\n","2347\n","2348\n","2349\n","2350\n","2351\n","2352\n","2353\n","2354\n","2355\n","2356\n","2357\n","2358\n","2359\n","2360\n","2361\n","2362\n","2363\n","2364\n","2365\n","2366\n","2367\n","2368\n","2369\n","2370\n","2371\n","2372\n","2373\n","2374\n","2375\n","2376\n","2377\n","2378\n","2379\n","2380\n","2381\n","2382\n","2383\n","2384\n","2385\n","2386\n","2387\n","2388\n","2389\n","2390\n","2391\n","2392\n","2393\n","2394\n","2395\n","2396\n","2397\n","2398\n","2399\n","2400\n","2401\n","2402\n","2403\n","2404\n","2405\n","2406\n","2407\n","2408\n","2409\n","2410\n","2411\n","2412\n","2413\n","2414\n","2415\n","2416\n","2417\n","2418\n","2419\n","2420\n","2421\n","2422\n","2423\n","2424\n","2425\n","2426\n","2427\n","2428\n","2429\n","2430\n","2431\n","2432\n","2433\n","2434\n","2435\n","2436\n","2437\n","2438\n","2439\n","2440\n","2441\n","2442\n","2443\n","2444\n","2445\n","2446\n","2447\n","2448\n","2449\n","2450\n","2451\n","2452\n","2453\n","2454\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in double_scalars\n"]},{"output_type":"stream","name":"stdout","text":["2455\n","2456\n","2457\n","2458\n","2459\n","2460\n","2461\n","2462\n","2463\n","2464\n","2465\n","2466\n","2467\n","2468\n","2469\n","2470\n","2471\n","2472\n","2473\n","2474\n","2475\n","2476\n","2477\n","2478\n","2479\n","2480\n","2481\n","2482\n","2483\n","2484\n","2485\n","2486\n","2487\n","2488\n","2489\n","2490\n","2491\n","2492\n","2493\n","2494\n","2495\n","2496\n","2497\n","2498\n","2499\n","2500\n","2501\n","2502\n","2503\n","2504\n","2505\n","2506\n","2507\n","2508\n","2509\n","2510\n","2511\n","2512\n","2513\n","2514\n","2515\n","2516\n","2517\n","2518\n","2519\n","2520\n","2521\n","2522\n","2523\n","2524\n","2525\n","2526\n","2527\n","2528\n","2529\n","2530\n","2531\n","2532\n","2533\n","2534\n","2535\n","2536\n","2537\n","2538\n","2539\n","2540\n","2541\n","2542\n","2543\n","2544\n","2545\n","2546\n","2547\n","2548\n","2549\n","2550\n","2551\n","2552\n","2553\n","2554\n","2555\n","2556\n","2557\n","2558\n","2559\n","2560\n","2561\n","2562\n","2563\n","2564\n","2565\n","2566\n","2567\n","2568\n","2569\n","2570\n","2571\n","2572\n","2573\n","2574\n","2575\n","2576\n","2577\n","2578\n","2579\n","2580\n","2581\n","2582\n","2583\n","2584\n","2585\n","2586\n","2587\n","2588\n","2589\n","2590\n","2591\n","2592\n","2593\n","2594\n","2595\n","2596\n","2597\n","2598\n","2599\n","2600\n","2601\n","2602\n","2603\n","2604\n","2605\n","2606\n","2607\n","2608\n","2609\n","2610\n","2611\n","2612\n","2613\n","2614\n","2615\n","2616\n","2617\n","2618\n","2619\n","2620\n","2621\n","2622\n","2623\n","2624\n","2625\n","2626\n","2627\n","2628\n","2629\n","2630\n","2631\n","2632\n","2633\n","2634\n","2635\n","2636\n","2637\n","2638\n","2639\n","2640\n","2641\n","2642\n","2643\n","2644\n","2645\n","2646\n","2647\n","2648\n","2649\n","2650\n","2651\n","2652\n","2653\n","2654\n","2655\n","2656\n","2657\n","2658\n","2659\n","2660\n","2661\n","2662\n","2663\n","2664\n","2665\n","2666\n","2667\n","2668\n","2669\n","2670\n","2671\n","2672\n","2673\n","2674\n","2675\n","2676\n","2677\n","2678\n","2679\n","2680\n","2681\n","2682\n","2683\n","2684\n","2685\n","2686\n","2687\n","2688\n","2689\n","2690\n","2691\n","2692\n","2693\n","2694\n","2695\n","2696\n","2697\n","2698\n","2699\n","2700\n","2701\n","2702\n","2703\n","2704\n","2705\n","2706\n","2707\n","2708\n","2709\n","2710\n","2711\n","2712\n","2713\n","2714\n","2715\n","2716\n","2717\n","2718\n","2719\n","2720\n","2721\n","2722\n","2723\n","2724\n","2725\n","2726\n","2727\n","2728\n","2729\n","2730\n","2731\n","2732\n","2733\n","2734\n","2735\n","2736\n","2737\n","2738\n","2739\n","2740\n","2741\n","2742\n","2743\n","2744\n","2745\n","2746\n","2747\n","2748\n","2749\n","2750\n","2751\n","2752\n","2753\n","2754\n","2755\n","2756\n","2757\n","2758\n","2759\n","2760\n","2761\n","2762\n","2763\n","2764\n","2765\n","2766\n","2767\n","2768\n","2769\n","2770\n","2771\n","2772\n","2773\n","2774\n","2775\n","2776\n","2777\n","2778\n","2779\n","2780\n","2781\n","2782\n","2783\n","2784\n","2785\n","2786\n","2787\n","2788\n","2789\n","2790\n","2791\n","2792\n","2793\n","2794\n","2795\n","2796\n","2797\n","2798\n","2799\n","2800\n","2801\n","2802\n","2803\n","2804\n","2805\n","2806\n","2807\n","2808\n","2809\n","2810\n","2811\n","2812\n","2813\n","2814\n","2815\n","2816\n","2817\n","2818\n","2819\n","2820\n","2821\n","2822\n","2823\n","2824\n","2825\n","2826\n","2827\n","2828\n","2829\n","2830\n","2831\n","2832\n","2833\n","2834\n","2835\n","2836\n","2837\n","2838\n","2839\n","2840\n","2841\n","2842\n","2843\n","2844\n","2845\n","2846\n","2847\n","2848\n","2849\n","2850\n","2851\n","2852\n","2853\n","2854\n","2855\n","2856\n","2857\n","2858\n","2859\n","2860\n","2861\n","2862\n","2863\n","2864\n","2865\n","2866\n","2867\n","2868\n","2869\n","2870\n","2871\n","2872\n","2873\n","2874\n","2875\n","2876\n","2877\n","2878\n","2879\n","2880\n","2881\n","2882\n","2883\n","2884\n","2885\n","2886\n","2887\n","2888\n","2889\n","2890\n","2891\n","2892\n","2893\n","2894\n","2895\n","2896\n","2897\n","2898\n","2899\n","2900\n","2901\n","2902\n","2903\n","2904\n","2905\n","2906\n","2907\n","2908\n","2909\n","2910\n","2911\n","2912\n","2913\n","2914\n","2915\n","2916\n","2917\n","2918\n","2919\n","2920\n","2921\n","2922\n","2923\n","2924\n","2925\n","2926\n","2927\n","2928\n","2929\n","2930\n","2931\n","2932\n","2933\n","2934\n","2935\n","2936\n","2937\n","2938\n","2939\n","2940\n","2941\n","2942\n","2943\n","2944\n","2945\n","2946\n","2947\n","2948\n","2949\n","2950\n","2951\n","2952\n","2953\n","2954\n","2955\n","2956\n","2957\n","2958\n","2959\n","2960\n","2961\n","2962\n","2963\n","2964\n","2965\n","2966\n","2967\n","2968\n","2969\n","2970\n","2971\n","2972\n","2973\n","2974\n","2975\n","2976\n","2977\n","2978\n","2979\n","2980\n","2981\n","2982\n","2983\n","2984\n","2985\n","2986\n","2987\n","2988\n","2989\n","2990\n","2991\n","2992\n","2993\n","2994\n","2995\n","2996\n","2997\n","2998\n","2999\n","3000\n","3001\n","3002\n","3003\n","3004\n","3005\n","3006\n","3007\n","3008\n","3009\n","3010\n","3011\n","3012\n","3013\n","3014\n","3015\n","3016\n","3017\n","3018\n","3019\n","3020\n","3021\n","3022\n","3023\n","3024\n","3025\n","3026\n","3027\n","3028\n","3029\n","3030\n","3031\n","3032\n","3033\n","3034\n","3035\n","3036\n","3037\n","3038\n","3039\n","3040\n","3041\n","3042\n","3043\n","3044\n","3045\n","3046\n","3047\n","3048\n","3049\n","3050\n","3051\n","3052\n","3053\n","3054\n","3055\n","3056\n","3057\n","3058\n","3059\n","3060\n","3061\n","3062\n","3063\n","3064\n","3065\n","3066\n","3067\n","3068\n","3069\n","3070\n","3071\n","3072\n","3073\n","3074\n","3075\n","3076\n","3077\n","3078\n","3079\n","3080\n","3081\n","3082\n","3083\n","3084\n","3085\n","3086\n","3087\n","3088\n","3089\n","3090\n","3091\n","3092\n","3093\n","3094\n","3095\n","3096\n","3097\n","3098\n","3099\n","3100\n","3101\n","3102\n","3103\n","3104\n","3105\n","3106\n","3107\n","3108\n","3109\n","3110\n","3111\n","3112\n","3113\n","3114\n","3115\n","3116\n","3117\n","3118\n","3119\n","3120\n","3121\n","3122\n","3123\n","3124\n","3125\n","3126\n","3127\n","3128\n","3129\n","3130\n","3131\n","3132\n","3133\n","3134\n","3135\n","3136\n","3137\n","3138\n","3139\n","3140\n","3141\n","3142\n","3143\n","3144\n","3145\n","3146\n","3147\n","3148\n","3149\n","3150\n","3151\n","3152\n","3153\n","3154\n","3155\n","3156\n","3157\n","3158\n","3159\n","3160\n","3161\n","3162\n","3163\n","3164\n","3165\n","3166\n","3167\n","3168\n","3169\n","3170\n","3171\n","3172\n","3173\n","3174\n","3175\n","3176\n","3177\n","3178\n","3179\n","3180\n","3181\n","3182\n","3183\n","3184\n","3185\n","3186\n","3187\n","3188\n","3189\n","3190\n","3191\n","3192\n","3193\n","3194\n","3195\n","3196\n","3197\n","3198\n","3199\n","3200\n","3201\n","3202\n","3203\n","3204\n","3205\n","3206\n","3207\n","3208\n","3209\n","3210\n","3211\n","3212\n","3213\n","3214\n","3215\n","3216\n","3217\n","3218\n","3219\n","3220\n","3221\n","3222\n","3223\n","3224\n","3225\n","3226\n","3227\n","3228\n","3229\n","3230\n","3231\n","3232\n","3233\n","3234\n","3235\n","3236\n","3237\n","3238\n","3239\n","3240\n","3241\n","3242\n","3243\n","3244\n","3245\n","3246\n","3247\n","3248\n","3249\n","3250\n","3251\n","3252\n","3253\n","3254\n","3255\n","3256\n","3257\n","3258\n","3259\n","3260\n","3261\n","3262\n","3263\n","3264\n","3265\n","3266\n","3267\n","3268\n","3269\n","3270\n","3271\n","3272\n","3273\n","3274\n","3275\n","3276\n","3277\n","3278\n","3279\n","3280\n","3281\n","3282\n","3283\n","3284\n","3285\n","3286\n","3287\n","3288\n","3289\n","3290\n","3291\n","3292\n","3293\n","3294\n","3295\n","3296\n","3297\n","3298\n","3299\n","3300\n","3301\n","3302\n","3303\n","3304\n","3305\n","3306\n","3307\n","3308\n","3309\n","3310\n","3311\n","3312\n","3313\n","3314\n","3315\n","3316\n","3317\n","3318\n","3319\n","3320\n","3321\n","3322\n","3323\n","3324\n","3325\n","3326\n","3327\n","3328\n","3329\n","3330\n","3331\n","3332\n","3333\n","3334\n","3335\n","3336\n","3337\n","3338\n","3339\n","3340\n","3341\n","3342\n","3343\n","3344\n","3345\n","3346\n","3347\n","3348\n","3349\n","3350\n","3351\n","3352\n","3353\n","3354\n","3355\n","3356\n","3357\n","3358\n","3359\n","3360\n","3361\n","3362\n","3363\n","3364\n","3365\n","3366\n","3367\n","3368\n","3369\n","3370\n","3371\n","3372\n","3373\n","3374\n","3375\n","3376\n","3377\n","3378\n","3379\n","3380\n","3381\n","3382\n","3383\n","3384\n","3385\n","3386\n","3387\n","3388\n","3389\n","3390\n","3391\n","3392\n","3393\n","3394\n","3395\n","3396\n","3397\n","3398\n","3399\n","3400\n","3401\n","3402\n","3403\n","3404\n","3405\n","3406\n","3407\n","3408\n","3409\n","3410\n","3411\n","3412\n","3413\n","3414\n","3415\n","3416\n","3417\n","3418\n","3419\n","3420\n","3421\n","3422\n","3423\n","3424\n","3425\n","3426\n","3427\n","3428\n","3429\n","3430\n","3431\n","3432\n","3433\n","3434\n","3435\n","3436\n","3437\n","3438\n","3439\n","3440\n","3441\n","3442\n","3443\n","3444\n","3445\n","3446\n","3447\n","3448\n","3449\n","3450\n","3451\n","3452\n","3453\n","3454\n","3455\n","3456\n","3457\n","3458\n","3459\n","3460\n","3461\n","3462\n","3463\n","3464\n","3465\n","3466\n","3467\n","3468\n","3469\n","3470\n","3471\n","3472\n","3473\n","3474\n","3475\n","3476\n","3477\n","3478\n","3479\n","3480\n","3481\n","3482\n","3483\n","3484\n","3485\n","3486\n","3487\n","3488\n","3489\n","3490\n","3491\n","3492\n","3493\n","3494\n","3495\n","3496\n","3497\n","3498\n","3499\n","3500\n","3501\n","3502\n","3503\n","3504\n","3505\n","3506\n","3507\n","3508\n","3509\n","3510\n","3511\n","3512\n","3513\n","3514\n","3515\n","3516\n","3517\n","3518\n","3519\n","3520\n","3521\n","3522\n","3523\n","3524\n","3525\n","3526\n","3527\n","3528\n","3529\n","3530\n","3531\n","3532\n","3533\n","3534\n","3535\n","3536\n","3537\n","3538\n","3539\n","3540\n","3541\n","3542\n","3543\n","3544\n","3545\n","3546\n","3547\n","3548\n","3549\n","3550\n","3551\n","3552\n","3553\n","3554\n","3555\n","3556\n","3557\n","3558\n","3559\n","3560\n","3561\n","3562\n","3563\n","3564\n","3565\n","3566\n","3567\n","3568\n","3569\n","3570\n","3571\n","3572\n","3573\n","3574\n","3575\n","3576\n","3577\n","3578\n","3579\n","3580\n","3581\n","3582\n","3583\n","3584\n","3585\n","3586\n","3587\n","3588\n","3589\n","3590\n","3591\n","3592\n","3593\n","3594\n","3595\n","3596\n","3597\n","3598\n","3599\n","3600\n","3601\n","3602\n","3603\n","3604\n","3605\n","3606\n","3607\n","3608\n","3609\n","3610\n","3611\n","3612\n","3613\n","3614\n","3615\n","3616\n","3617\n","3618\n","3619\n","3620\n","3621\n","3622\n","3623\n","3624\n","3625\n","3626\n","3627\n","3628\n","3629\n","3630\n","3631\n","3632\n","3633\n","3634\n","3635\n","3636\n","3637\n","3638\n","3639\n","3640\n","3641\n","3642\n","3643\n","3644\n","3645\n","3646\n","3647\n","3648\n","3649\n","3650\n","3651\n","3652\n","3653\n","3654\n","3655\n","3656\n","3657\n","3658\n","3659\n","3660\n","3661\n","3662\n","3663\n","3664\n","3665\n","3666\n","3667\n","3668\n","3669\n","3670\n","3671\n","3672\n","3673\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c1d549b8641e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtab_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtab_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mf_measure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtab_f_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-38b2e9198ddd>\u001b[0m in \u001b[0;36mtab_precision\u001b[0;34m(pred, gt)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtab_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# get rid of \"closed\" class, as we only want to count positives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtab_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab2bin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mtab_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab2bin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-38b2e9198ddd>\u001b[0m in \u001b[0;36mtab2bin\u001b[0;34m(tab)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mfret_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# 0 means that the string is closed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfret_class\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mfret_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfret_class\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtab_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfret_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#---tab-test---\n","net: MyVGG = MyVGG()\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","net= torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/model_vgg_bekku.pth\")\n","net.to(\"cuda:0\")\n","tab_results = {}\n","tab_results[\"precision\"] = []\n","tab_results[\"recall\"] = []\n","tab_results[\"f-measure\"] = []\n","for i, (images, labels) in enumerate(validation_generator):\n","  print(i)\n","  input_data = validation_generator[i]\n","  images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2))).to(\"cuda:0\")\n","  labels = torch.Tensor(input_data[1])\n","  outputs = net(images)\n","  _, predicted = torch.max(outputs.data, 2)\n","  gt = np.argmax(labels, 2)\n","  pred = tab_precision(predicted, gt)\n","  recall = tab_recall(predicted, gt)\n","  f_measure = tab_f_measure(predicted, gt)\n","  tab_results[\"precision\"].append(pred)\n","  tab_results[\"recall\"].append(recall)\n","  tab_results[\"f-measure\"].append(f_measure)"]},{"cell_type":"code","source":["print(len(tab_results[\"precision\"][:615]), len(tab_results[\"recall\"][:615]), len(tab_results[\"f-measure\"][:615]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JzDsM7yKBa0","executionInfo":{"status":"ok","timestamp":1648666119901,"user_tz":-540,"elapsed":716,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"f960c2b0-7e3d-466b-f737-85579e762ad1"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["615 615 615\n"]}]},{"cell_type":"code","source":["precision_mean = sum(tab_results[\"precision\"][:615])/len(tab_results[\"precision\"][:615])\n","recall_mean = sum(tab_results[\"recall\"][:615])/len(tab_results[\"recall\"][:615])\n","Fmeasure_mean = sum(tab_results[\"f-measure\"][:615])/len(tab_results[\"f-measure\"][:615])\n","print(precision_mean, recall_mean, Fmeasure_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiwVFPtH7AA-","executionInfo":{"status":"ok","timestamp":1648666061372,"user_tz":-540,"elapsed":558,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"84426ef6-e614-4cad-aca9-89181d3abcf9"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6011888260230286 0.49913360384929273 nan\n"]}]},{"cell_type":"markdown","source":["↓tabcnn 2ep"],"metadata":{"id":"B5sE9wAaKlX5"}},{"cell_type":"code","source":["class MyCNN(torch.nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","        self.conv1 = torch.nn.Conv2d(1, 32, 3)\n","        self.conv2 = torch.nn.Conv2d(32, 64, 3)\n","        self.conv3 = torch.nn.Conv2d(64, 64, 3)\n"," \n","        self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\n","\n","        self.drop1 = torch.nn.Dropout2d(0.25)\n","        self.drop2 = torch.nn.Dropout(0.5)\n","        self.flatten = torch.nn.Flatten()\n","\n","        self.fc1 = torch.nn.Linear(5952,128)\n","        self.fc2 = torch.nn.Linear(128,126)\n","        \n"," \n","    def forward(self, x):\n","        # print(x.size())\n","        x = f.relu(self.conv1(x))\n","        # print(x.size())\n","        x = f.relu(self.conv2(x))\n","        #print(x.size())\n","        x = f.relu(self.conv3(x))\n","        #print(x.size())\n","        x = self.pool(x)\n","        #print(x.size())\n","        x = self.drop1(x)\n","        #print(x.size())\n","        x = self.flatten(x)\n","        #print(x.size())\n","        x = f.relu(self.fc1(x))\n","        #print(x.size())\n","        x = self.fc2(x)\n","        #print(x.size())\n","        x = torch.reshape(x, (128, 6, 21)) \n","        #m = nn.Softmax(dim=2)\n","        x_out = x\n","        #print(x_out.shape)\n","        return x_out"],"metadata":{"id":"KE2r_MILLZIM","executionInfo":{"status":"ok","timestamp":1648666451745,"user_tz":-540,"elapsed":334,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["#---tab-test---\n","net: MyCNN = MyCNN()\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","net= torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/model2.pth\")\n","net.to(\"cuda:0\")\n","tab_results2 = {}\n","tab_results2[\"precision\"] = []\n","tab_results2[\"recall\"] = []\n","tab_results2[\"f-measure\"] = []\n","for i, (images, labels) in enumerate(validation_generator):\n","  print(i)\n","  input_data = validation_generator[i]\n","  images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2))).to(\"cuda:0\")\n","  labels = torch.Tensor(input_data[1])\n","  outputs = net(images)\n","  _, predicted = torch.max(outputs.data, 2)\n","  gt = np.argmax(labels, 2)\n","  pred = tab_precision(predicted, gt)\n","  recall = tab_recall(predicted, gt)\n","  f_measure = tab_f_measure(predicted, gt)\n","  tab_results2[\"precision\"].append(pred)\n","  tab_results2[\"recall\"].append(recall)\n","  tab_results2[\"f-measure\"].append(f_measure)\n","  if i==616:\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1l6ta4coKkLl","executionInfo":{"status":"ok","timestamp":1648668401061,"user_tz":-540,"elapsed":1934398,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"c958ac19-eb5a-494e-88d3-b9008de57633"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n"]},{"output_type":"stream","name":"stdout","text":["344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n"]}]},{"cell_type":"code","source":["precision_mean = sum(tab_results2[\"precision\"][:615])/len(tab_results2[\"precision\"][:615])\n","recall_mean = sum(tab_results2[\"recall\"][:615])/len(tab_results2[\"recall\"][:615])\n","Fmeasure_mean = sum(tab_results2[\"f-measure\"][:615])/len(tab_results2[\"f-measure\"][:615])\n","print(precision_mean, recall_mean, Fmeasure_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oh08Y8fyLGJb","executionInfo":{"status":"ok","timestamp":1648668481962,"user_tz":-540,"elapsed":407,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"78db32db-1e59-4c4b-c97d-dbce2197aead"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7063941072929059 0.5800507627690599 nan\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"HaSG-gKvLG5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sfqljGV4tus6"},"outputs":[],"source":["training_generator, validation_generator = partition_data(0)\n","input_data = validation_generator[65]\n","images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2)))\n","labels = torch.Tensor(input_data[1])\n","outputs = net(images)\n","_, predicted = torch.max(outputs.data, 2)\n","gt = np.argmax(labels, 2)\n","\n","ans = tab2bin(predicted[0])\n","lab = tab2bin(gt[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1642436190280,"user":{"displayName":"五頭健太郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10164916516000345785"},"user_tz":-540},"id":"LN0lib3kyCCp","outputId":"334edf84-0861-4673-e3f8-e787051c4fc3"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","from matplotlib import animation, rc\n","from IPython.display import HTML\n","plt.imshow(lab, cmap=plt.cm.Blues, interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1642436191808,"user":{"displayName":"五頭健太郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10164916516000345785"},"user_tz":-540},"id":"WLmVWD45rCz_","outputId":"3aded366-3d7e-480e-935e-a3e7abae74ff"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWoAAACDCAYAAACk5FEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAJaUlEQVR4nO3dfahkdR3H8fenVQtKdO0uZa7takhkf5RytQcrpMLUQisiNnqwB5CoBYUijCCi/yqKqKQwk54kpbSSMNLSiAQ3r+tq6lZuspay6m6KFv1R1rc/5lwbrzP3zuKcmZ/6fsFwz8z5zcyH35793DPnzMxNVSFJatcz5h1AkrQ6i1qSGmdRS1LjLGpJapxFLUmNO6CPB11YWKhNmzb38dATu2nnX57wYxz3khdOIYkkre2uu3azb9++jFrXS1Fv2rSZ67Yt9fHQE1t/wtYn/BjXbfvaFJJI0tpOesXi2HUe+pCkxlnUktQ4i1qSGmdRS1LjJirqJKcm+WOSXUnO6zuUJOn/1izqJOuA84HTgGOBdyU5tu9gkqSBSfaoTwR2VdWdVfUv4BLgzH5jSZKWTVLURwB/Hbp+d3fbYyQ5O8lSkqW9+/ZOK58kPe1N7WRiVV1QVYtVtbhhYcO0HlaSnvYmKep7gCOHrm/sbpMkzcAkRX0DcEySo5IcBGwBrug3liRp2Zrf9VFVjyTZCvwCWAdcVFW39Z5MkgRM+KVMVXUlcGXPWSRJI/jJRElqnEUtSY3r5fuoW/DgDX6XtKSnBveoJalxFrUkNc6ilqTGWdSS1DiLWpIaZ1FLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNe8r+4YD1J2x9wo/hHx+Q1AL3qCWpcRa1JDXOopakxlnUktS4NYs6yZFJrk1ye5Lbkpwzi2CSpIFJ3vXxCPCxqtqe5GDgxiRXV9XtPWeTJDHBHnVV7amq7d3y34GdwBF9B5MkDezXMeokm4HjgG0j1p2dZCnJ0t59e6eTTpI0eVEneQ5wGXBuVT28cn1VXVBVi1W1uGFhwzQzStLT2kRFneRABiV9cVVd3m8kSdKwSd71EeBbwM6q+lL/kSRJwybZoz4JeC/w+iQ7usvpPeeSJHXWfHteVf0WyAyySJJG8JOJktQ4i1qSGveU/T7qaXyXtN9pLakF7lFLUuMsaklqnEUtSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhr3lP3DAdPgl/5LaoF71JLUOItakhpnUUtS4yxqSWqcRS1JjZu4qJOsS3JTkp/1GUiS9Fj7s0d9DrCzryCSpNEmKuokG4E3Axf2G0eStNKke9RfBj4B/HfcgCRnJ1lKsrR3396phJMkTVDUSd4C3F9VN642rqouqKrFqlrcsLBhagEl6elukj3qk4AzkuwGLgFen+T7vaaSJD1qzaKuqk9W1caq2gxsAa6pqvf0nkySBPg+aklq3n59e15V/Rr4dS9JJEkjuUctSY2zqCWpcRa1JDXOopakxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXEWtSQ1zqKWpMZZ1JLUOItakhpnUUtS4yxqSWqcRS1JjbOoJalxFrUkNS5VNf0HTfYCd60yZAHYN/Unnj5zTs+TISOYc9rMOblNVbVh1IpeinotSZaqanHmT7yfzDk9T4aMYM5pM+d0eOhDkhpnUUtS4+ZV1BfM6Xn3lzmn58mQEcw5beacgrkco5YkTc5DH5LUOItakhrXa1EnOTXJH5PsSnLeiPXPTHJpt35bks195hmT8cgk1ya5PcltSc4ZMebkJA8l2dFdPj3rnF2O3Ul+32VYGrE+Sb7SzectSY6fcb4XD83RjiQPJzl3xZi5zGWSi5Lcn+TWodsOS3J1kju6n+vH3PesbswdSc6aQ84vJPlD92/64ySHjrnvqtvHDHJ+Jsk9Q/+2p4+576q9MIOclw5l3J1kx5j7zmw+11RVvVyAdcCfgaOBg4CbgWNXjPkI8I1ueQtwaV95Vsl5OHB8t3ww8KcROU8GfjbrbCOy7gYWVll/OvBzIMArgW1zzLoOuJfBm/jnPpfA64DjgVuHbvs8cF63fB7wuRH3Owy4s/u5vlteP+OcpwAHdMufG5Vzku1jBjk/A3x8gu1i1V7oO+eK9V8EPj3v+Vzr0uce9YnArqq6s6r+BVwCnLlizJnAd7rlHwFvSJIeMz1OVe2pqu3d8t+BncARs8wwRWcC362B64FDkxw+pyxvAP5cVat9QnVmquo3wAMrbh7e/r4DvHXEXd8EXF1VD1TVg8DVwKmzzFlVV1XVI93V64GNfT3/pMbM5yQm6YWpWS1n1zXvBH7Q1/NPS59FfQTw16Hrd/P4Anx0TLchPgQ8t8dMq+oOvRwHbBux+lVJbk7y8yQvnWmw/yvgqiQ3Jjl7xPpJ5nxWtjD+P0ALcwnwvKra0y3fCzxvxJiW5hTggwxeNY2y1vYxC1u7QzQXjTmU1NJ8vha4r6ruGLO+hfkEPJn4qCTPAS4Dzq2qh1es3s7gJfzLgK8CP5l1vs5rqup44DTgo0leN6ccq0pyEHAG8MMRq1uZy8eowWvdpt+rmuRTwCPAxWOGzHv7+DrwIuDlwB4GhxVa9i5W35ue93w+qs+ivgc4cuj6xu62kWOSHAAcAvytx0wjJTmQQUlfXFWXr1xfVQ9X1T+65SuBA5MszDgmVXVP9/N+4McMXkYOm2TOZ+E0YHtV3bdyRStz2blv+dBQ9/P+EWOamNMk7wfeAry7+6XyOBNsH72qqvuq6j9V9V/gm2Oev5X5PAB4O3DpuDHzns9hfRb1DcAxSY7q9rC2AFesGHMFsHwW/R3ANeM2wr50x6m+Beysqi+NGfP85WPnSU5kMG8z/YWS5NlJDl5eZnCC6dYVw64A3te9++OVwENDL+1naeyeSgtzOWR4+zsL+OmIMb8ATkmyvnspf0p328wkORX4BHBGVf1zzJhJto9erTgf8rYxzz9JL8zCG4E/VNXdo1a2MJ+P0eeZSgbvQvgTg7O8n+pu+yyDDQ7gWQxeHu8CfgccPeuzqcBrGLzkvQXY0V1OBz4MfLgbsxW4jcEZ6uuBV88h59Hd89/cZVmez+GcAc7v5vv3wOIccj6bQfEeMnTb3OeSwS+OPcC/GRwX/RCD8yG/Au4Afgkc1o1dBC4cuu8Hu210F/CBOeTcxeC47vL2ufxOqRcAV662fcw45/e67e4WBuV7+Mqc3fXH9cIsc3a3f3t5mxwaO7f5XOviR8glqXGeTJSkxlnUktQ4i1qSGmdRS1LjLGpJapxFLUmNs6glqXH/AzVzKEq0kU1NAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.imshow(ans, cmap=plt.cm.Blues, interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"elapsed":2945,"status":"ok","timestamp":1642482817442,"user":{"displayName":"五頭健太郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10164916516000345785"},"user_tz":-540},"id":"8VF_dXelgy8P","outputId":"85a03d6a-388e-4835-a0ba-4e2e9490c73f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\", line 196, in process\n","    func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/animation.py\", line 1467, in _stop\n","    self.event_source.remove_callback(self._loop_delay)\n","AttributeError: 'NoneType' object has no attribute 'remove_callback'\n"]},{"data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div id='1a92edeb-9e62-4165-b6da-8bb4a441ab0f'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%matplotlib nbagg\n","\n","import matplotlib.pyplot as plt \n","import matplotlib.animation as animation\n","\n","fig = plt.figure()\n","ims = []\n","\n","training_generator, validation_generator = partition_data(0)\n","input_data = validation_generator[0]\n","images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2)))\n","labels = torch.Tensor(input_data[1])\n","outputs = net(images)\n","_, predicted = torch.max(outputs.data, 2)\n","gt = np.argmax(labels, 2)\n","\n","for i in range(128):\n","  ans = tab2bin(predicted[i])\n","  lab = tab2bin(gt[i])\n","  im = plt.imshow(lab, cmap=plt.cm.Blues, interpolation='nearest', animated=True)\n","  ims.append([im])\n","\n","ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"elapsed":16156,"status":"error","timestamp":1642482359318,"user":{"displayName":"五頭健太郎","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10164916516000345785"},"user_tz":-540},"id":"X6l-Sus3b6_A","outputId":"f45fded3-63f0-462a-c86f-2408025adc41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: Cannot change to a different GUI toolkit: notebook. Using nbagg instead.\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\", line 196, in process\n","    func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/animation.py\", line 1467, in _stop\n","    self.event_source.remove_callback(self._loop_delay)\n","AttributeError: 'NoneType' object has no attribute 'remove_callback'\n"]},{"data":{"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div id='21df23eb-e1c5-4314-bf4e-f606a21d890e'></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-46189e7ff3e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-12c2d82f0014>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-12c2d82f0014>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# load a context window centered around the frame index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mfull_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"repr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalfwin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalfwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0msample_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_idx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcon_win_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    254\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[1;32m    765\u001b[0m                                                              count=read_count)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mZIP_STORED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_read2\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    752\u001b[0m                         \"Close the writing handle before trying to read.\")\n\u001b[1;32m    753\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%matplotlib notebook\n","import matplotlib.pyplot as plt \n","\n","ims = []\n","for i, (images, labels) in enumerate(validation_generator):\n","  input_data = validation_generator[i]\n","  images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2)))\n","  labels = torch.Tensor(input_data[1])\n","  outputs = net(images)\n","  _, predicted = torch.max(outputs.data, 2)\n","  gt = np.argmax(labels, 2)\n","  ans = tab2bin(predicted[0])\n","  lab = tab2bin(gt[0])\n","  im = plt.imshow(lab, cmap=plt.cm.Blues, interpolation='nearest')\n","  ims.append(im)\n","\n","ani = animation.ArtistAnimation(ims)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DataGenerator4.ipynb","provenance":[]},"interpreter":{"hash":"ee2652462c3ef076369cbdf09a6715f1a7d8c5fa11cbe58a9308975a5bb1304d"},"kernelspec":{"display_name":"Python 3.9.9 64-bit (windows store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}