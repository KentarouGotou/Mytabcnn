{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2024,"status":"ok","timestamp":1656960752181,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"},"user_tz":-540},"id":"mE1PVbn3rLEQ","outputId":"1e1d38b6-13a0-4470-c07c-694b333cbbae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qroPP7dJ5-Cb","executionInfo":{"status":"ok","timestamp":1656960752535,"user_tz":-540,"elapsed":8,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"579f0663-5220-4c99-e70b-0d17d5652190"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jul  4 18:52:32 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    45W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPq7xplyrCz0"},"outputs":[],"source":["import numpy as np\n","from torch.utils.data import Dataset\n","import os\n","\n","class MyDataGenerator(Dataset):\n","    \n","    def __init__(self, list_IDs, data_path=\"/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr\", batch_size=128, shuffle=True, label_dim = (6,21), spec_repr=\"c\", con_win_size=9):\n","        \n","        self.list_IDs = list_IDs\n","        self.data_path = data_path\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.label_dim = label_dim\n","        self.spec_repr = spec_repr\n","        self.con_win_size = con_win_size\n","        self.halfwin = con_win_size // 2\n","        \n","        if self.spec_repr == \"c\":\n","            self.X_dim = (self.batch_size, 192, self.con_win_size)\n","        elif self.spec_repr == \"m\":\n","            self.X_dim = (self.batch_size, 128, self.con_win_size)\n","        elif self.spec_repr == \"cm\":\n","            self.X_dim = (self.batch_size, 320, self.con_win_size)\n","        elif self.spec_repr == \"s\":\n","            self.X_dim = (self.batch_size, 1025, self.con_win_size)\n","            \n","        self.y_dim = (self.batch_size, self.label_dim[0], self.label_dim[1])\n","        \n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # number of batches per epoch\n","        return int(np.floor(float(len(self.list_IDs)) / self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        # generate indices of the batch(バッチごとのインデクス)\n","        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n","        \n","        # find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # generate data\n","        X, y, tempo = self.__data_generation(list_IDs_temp)\n","        \n","        return X, y, tempo\n","    \n","    def on_epoch_end(self):\n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self, list_IDs_temp):\n","        #Generates data containing batch_size samples\n","        # X : (n_samples, *dim, n_channels)\n","        \n","        # Initialization\n","        X = np.empty(self.X_dim)\n","        y = np.empty(self.y_dim)\n","        tempo = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            # determine filename\n","            data_dir = self.data_path + self.spec_repr + \"/\"\n","            filename = \"_\".join(ID.split(\"_\")[:-1]) + \".npz\"\n","            tempo.append(int(ID.split(\"-\")[1]))\n","            frame_idx = int(ID.split(\"_\")[-1])\n","            \n","            # load a context window centered around the frame index\n","            loaded = np.load(data_dir + filename)\n","            full_x = np.pad(loaded[\"repr\"], [(self.halfwin,self.halfwin), (0,0)], mode='constant')\n","            sample_x = full_x[frame_idx : frame_idx + self.con_win_size]\n","            #X[i,] = np.expand_dims(np.swapaxes(sample_x, 0, 1), -1)\n","            X[i,] = np.swapaxes(sample_x, 0, 1)\n","\n","            # Store label\n","            y[i,] = loaded[\"labels\"][frame_idx]\n","\n","        return X, y, tempo"]},{"cell_type":"code","source":["class MyDataGenerator2(Dataset):\n","    \n","    def __init__(self, list_IDs, data_path=\"/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr\", batch_size=128, label_dim = (6,21), spec_repr=\"c\", window_size = 50):\n","        \n","        self.list_IDs = list_IDs\n","        self.data_path = data_path\n","        self.batch_size = batch_size\n","        self.label_dim = label_dim\n","        self.spec_repr = spec_repr\n","        self.window_size = window_size\n","        \n","        if self.spec_repr == \"c\":\n","            self.X_dim = (self.batch_size, 192, 2000, 1)\n","        elif self.spec_repr == \"m\":\n","            self.X_dim = (self.batch_size, 128, 2000, 1)\n","        elif self.spec_repr == \"cm\":\n","            self.X_dim = (self.batch_size, 320, 2000, 1)\n","        elif self.spec_repr == \"s\":\n","            self.X_dim = (self.batch_size, 1025, 2000, 1)\n","            \n","        self.y_dim = (self.batch_size, 2000, self.label_dim[0], self.label_dim[1])\n","        \n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # number of batches per epoch\n","        return int(np.floor(float(len(self.list_IDs)) / self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        # generate indices of the batch(バッチごとのインデクス)\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        \n","        # find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # generate data\n","        X, y, ID = self.__data_generation(list_IDs_temp)\n","        \n","        return X, y, ID\n","    \n","    def on_epoch_end(self):\n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.list_IDs))\n","            \n","    def __data_generation(self, list_IDs_temp):\n","        #Generates data containing batch_size samples\n","        # X : (n_samples, *dim, n_channels)\n","        \n","        # Initialization\n","        X = np.empty(self.X_dim)\n","        y = np.empty(self.y_dim)\n","        X = []\n","        files = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            # determine filename\n","            data_dir = self.data_path + self.spec_repr + \"/\"\n","            filename = ID + \".npz\"\n","            files.append(filename)\n","            \n","            # load a context window centered around the frame index\n","            loaded = np.load(data_dir + filename)\n","\n","            slice_num = len(loaded[\"repr\"])//self.window_size + 1\n","            all_length = slice_num * self.window_size\n","            pad_span = all_length - len(loaded[\"repr\"]) - 4\n","            full_x = np.pad(loaded[\"repr\"], [(4,pad_span), (0,0)], mode=\"constant\")\n","            sample_x = full_x\n","            for j in range(slice_num):\n","              X.append(np.expand_dims(np.swapaxes(sample_x, 0, 1), -1))\n","\n","            pad_span = 1996 - len(loaded[\"repr\"])\n","            full_x = np.pad(loaded[\"repr\"], [(4,pad_span), (0,0)], mode='constant')\n","            sample_x = full_x\n","            X[i,] = np.expand_dims(np.swapaxes(sample_x, 0, 1), -1)\n","\n","            # Store label\n","            y[i,][:len(loaded[\"repr\"])] = loaded[\"labels\"]\n","            for j in range(len(loaded[\"labels\"]),2000):\n","                for k in range(6):\n","                    y[i,][j][k][0] = 1\n","\n","        return X, y, files"],"metadata":{"id":"ogTV9F0vcf2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataGenerator3(Dataset):\n","    \n","    def __init__(self, list_IDs, data_path=\"/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr\", batch_size=128, shuffle=True, label_dim = (6,21), spec_repr=\"c\", con_win_size=9):\n","        \n","        self.list_IDs = list_IDs\n","        self.data_path = data_path\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.label_dim = label_dim\n","        self.spec_repr = spec_repr\n","        self.con_win_size = con_win_size\n","        self.halfwin = con_win_size // 2\n","        \n","        if self.spec_repr == \"c\":\n","            self.X_dim = (self.batch_size, 192, self.con_win_size)\n","        elif self.spec_repr == \"m\":\n","            self.X_dim = (self.batch_size, 128, self.con_win_size)\n","        elif self.spec_repr == \"cm\":\n","            self.X_dim = (self.batch_size, 320, self.con_win_size)\n","        elif self.spec_repr == \"s\":\n","            self.X_dim = (self.batch_size, 1025, self.con_win_size)\n","            \n","        self.y_dim = (self.batch_size, self.label_dim[0], self.label_dim[1])\n","        \n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # number of batches per epoch\n","        return int(np.floor(float(len(self.list_IDs)) / self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        # generate indices of the batch(バッチごとのインデクス)\n","        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n","        \n","        # find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # generate data\n","        X, y, tempo = self.__data_generation(list_IDs_temp)\n","        \n","        return X, y, tempo\n","    \n","    def on_epoch_end(self):\n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self, list_IDs_temp):\n","        #Generates data containing batch_size samples\n","        # X : (n_samples, *dim, n_channels)\n","        \n","        # Initialization\n","        X = np.empty(self.X_dim)\n","        y = np.empty(self.y_dim)\n","        tempo = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            # determine filename\n","            data_dir = self.data_path + self.spec_repr + \"/\"\n","            filename = \"_\".join(ID.split(\"_\")[:-1]) + \".npz\"\n","            tempo.append(int(ID.split(\"-\")[1]))\n","            frame_idx = int(ID.split(\"_\")[-1])\n","            \n","            # load a context window centered around the frame index\n","            loaded = np.load(data_dir + filename)\n","            full_x = np.pad(loaded[\"repr\"], [(self.halfwin,self.halfwin), (0,0)], mode='constant')\n","            sample_x = full_x[frame_idx : frame_idx + self.con_win_size]\n","            X[i,] = np.swapaxes(sample_x, 0, 1)\n","\n","            # Store label\n","            y[i,] = loaded[\"labels\"][frame_idx]\n","\n","        return X, y, tempo"],"metadata":{"id":"53cmqE9nXkUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataGenerator4(Dataset):\n","    \n","    def __init__(self, list_IDs, data_path=\"/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr\", batch_size=128, shuffle=True, label_dim = (6,21), spec_repr=\"c\", con_win_size=9):\n","        \n","        self.list_IDs = list_IDs\n","        self.data_path = data_path\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.label_dim = label_dim\n","        self.spec_repr = spec_repr\n","        self.con_win_size = con_win_size\n","        self.halfwin = con_win_size // 2\n","        \n","        if self.spec_repr == \"c\":\n","            self.X_dim = (self.batch_size, 192, self.con_win_size, 1)\n","        elif self.spec_repr == \"m\":\n","            self.X_dim = (self.batch_size, 128, self.con_win_size, 1)\n","        elif self.spec_repr == \"cm\":\n","            self.X_dim = (self.batch_size, 320, self.con_win_size, 1)\n","        elif self.spec_repr == \"s\":\n","            self.X_dim = (self.batch_size, 1025, self.con_win_size, 1)\n","            \n","        self.y_dim = (self.batch_size, self.label_dim[0], self.label_dim[1])\n","        \n","        self.on_epoch_end()\n","    \n","    def __len__(self):\n","        # number of batches per epoch\n","        return len(self.list_IDs)*2048\n","    \n","    def __getitem__(self, index):\n","        # generate indices of the batch(バッチごとのインデクス)\n","        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n","        \n","        # find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # generate data\n","        X, y, tempo = self.__data_generation(list_IDs_temp)\n","        \n","        return X, y, tempo\n","    \n","    def on_epoch_end(self):\n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self, list_IDs_temp):\n","        #Generates data containing batch_size samples\n","        # X : (n_samples, *dim, n_channels)\n","        \n","        # Initialization\n","        X = np.empty(self.X_dim)\n","        y = np.empty(self.y_dim)\n","        tempo = []\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            # determine filename\n","            data_dir = self.data_path + self.spec_repr + \"/\"\n","            filename = \"_\".join(ID.split(\"_\")[:-1]) + \".npz\"\n","            tempo.append(int(ID.split(\"-\")[1]))\n","            frame_idx = int(ID.split(\"_\")[-1])\n","            \n","            # load a context window centered around the frame index\n","            loaded = np.load(data_dir + filename)\n","            full_x = np.pad(loaded[\"repr\"], [(self.halfwin,self.halfwin), (0,0)], mode='constant')\n","            sample_x = full_x[frame_idx : frame_idx + self.con_win_size]\n","            X[i,] = np.expand_dims(np.swapaxes(sample_x, 0, 1), -1)\n","\n","            # Store label\n","            y[i,] = loaded[\"labels\"][frame_idx]\n","\n","        return X, y, tempo"],"metadata":{"id":"JTjNarv2NL58"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bs5q5PYOrCz7"},"outputs":[],"source":["import datetime\n","import pandas as pd\n","\n","batch_size=128\n","epochs=8\n","con_win_size = 9\n","spec_repr=\"c\"\n","data_path=\"/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr/\"\n","# data_path2=\"/content/drive/MyDrive/lab/2021/MyTabCNN/data/GuitarSet/annotation\"\n","# data_path3=\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/\"\n","id_file=\"id.csv\"\n","id3_file=\"id3.npy\"\n","\n","csv_file = data_path + id_file\n","#jams_file = os.listdir(data_path2)\n","list_IDs = list(pd.read_csv(csv_file, header=None)[0])\n","list_IDs2 = []\n","# for i in jams_file:\n","#   if i[0] != \".\":\n","#     list_IDs2.append(i[:-5])\n","\n","def partition_data(data_split):\n","    data_split = data_split\n","    partition = {}\n","    partition[\"training\"] = []\n","    partition[\"validation\"] = []\n","    for ID in list_IDs:\n","        guitarist = int(ID.split(\"_\")[0])\n","        if guitarist == data_split:\n","            partition[\"validation\"].append(ID)\n","        else:\n","            partition[\"training\"].append(ID)\n","    training_generator = MyDataGenerator(partition['training'], \n","                                            data_path=data_path, \n","                                            batch_size=batch_size, \n","                                            shuffle=False,\n","                                            spec_repr=spec_repr, \n","                                            con_win_size=con_win_size)\n","    \n","    validation_generator = MyDataGenerator(partition['validation'], \n","                                            data_path=data_path, \n","                                            batch_size=batch_size, \n","                                            shuffle=False,\n","                                            spec_repr=spec_repr, \n","                                            con_win_size=con_win_size)\n","    return training_generator, validation_generator\n","\n","# def partition_data2(data_split):\n","#     data_split = data_split\n","#     partition = {}\n","#     partition[\"training\"] = []\n","#     partition[\"validation\"] = []\n","#     for ID2 in list_IDs2:\n","#       guitarist = int(ID2.split(\"_\")[0])\n","#       if guitarist == data_split:\n","#           partition[\"validation\"].append(ID2)\n","#       else:\n","#           partition[\"training\"].append(ID2)\n","#     training_generator = MyDataGenerator2(partition['training'], \n","#                                             data_path=data_path, \n","#                                             batch_size=batch_size,\n","#                                             spec_repr=spec_repr)\n","    \n","#     validation_generator = MyDataGenerator2(partition['validation'], \n","#                                             data_path=data_path, \n","#                                             batch_size=batch_size,\n","#                                             spec_repr=spec_repr)\n","#     return training_generator, validation_generator\n","\n","# def partition_data3(data_split):\n","#     data_split = data_split\n","#     partition = {}\n","#     partition[\"training\"] = []\n","#     partition[\"validation\"] = []\n","#     for ID in list_IDs3:\n","#         guitarist = int(ID.split(\"_\")[0])\n","#         if guitarist == data_split:\n","#             partition[\"validation\"].append(ID)\n","#         else:\n","#             partition[\"training\"].append(ID)\n","#     training_generator = MyDataGenerator3(partition['training'], \n","#                                             data_path=data_path, \n","#                                             batch_size=batch_size, \n","#                                             shuffle=False,\n","#                                             spec_repr=spec_repr, \n","#                                             con_win_size=con_win_size)\n","    \n","#     validation_generator = MyDataGenerator3(partition['validation'], \n","#                                             data_path=data_path, \n","#                                             batch_size=batch_size, \n","#                                             shuffle=False,\n","#                                             spec_repr=spec_repr, \n","#                                             con_win_size=con_win_size)\n","#     return training_generator, validation_generator\n","  \n","# def partition_data4(data_split):\n","#     data_split = data_split\n","#     partition = {}\n","#     partition[\"training\"] = []\n","#     partition[\"validation\"] = []\n","#     for ID in list_IDs:\n","#         guitarist = int(ID.split(\"_\")[0])\n","#         if guitarist == data_split:\n","#             partition[\"validation\"].append(ID)\n","#         else:\n","#             partition[\"training\"].append(ID)\n","#     training_generator = MyDataGenerator4(partition['training'], \n","#                                             data_path=data_path,\n","#                                             batch_size=batch_size, \n","#                                             shuffle=False,\n","#                                             spec_repr=spec_repr, \n","#                                             con_win_size=con_win_size)\n","    \n","#     validation_generator = MyDataGenerator4(partition['validation'], \n","#                                             data_path=data_path,\n","#                                             batch_size=batch_size, \n","#                                             shuffle=False,\n","#                                             spec_repr=spec_repr, \n","#                                             con_win_size=con_win_size)\n","#     return training_generator, validation_generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3jFaBryLrCz8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.onnx as onnx\n","import torchvision.models as models\n","import torch.nn.functional as f\n","class MyCNN(torch.nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","        self.conv1 = torch.nn.Conv2d(1, 32, 3)\n","        self.conv2 = torch.nn.Conv2d(32, 64, 3)\n","        self.conv3 = torch.nn.Conv2d(64, 64, 3)\n"," \n","        self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\n","\n","        self.drop1 = torch.nn.Dropout2d(0.25)\n","        self.drop2 = torch.nn.Dropout(0.5)\n","        self.flatten = torch.nn.Flatten()\n","\n","        self.fc1 = torch.nn.Linear(5952,128)\n","        self.fc2 = torch.nn.Linear(128,126)\n","        self.softmax = nn.Softmax(dim=2)\n","        \n"," \n","    def forward(self, x):\n","        # print(x.size())\n","        x = f.relu(self.conv1(x))\n","        # print(x.size())\n","        x = f.relu(self.conv2(x))\n","        #print(x.size())\n","        x = f.relu(self.conv3(x))\n","        #print(x.size())\n","        x = self.pool(x)\n","        #print(x.size())\n","        x = self.drop1(x)\n","        #print(x.size())\n","        x = self.flatten(x)\n","        #print(x.size())\n","        x = f.relu(self.fc1(x))\n","        #print(x.size())\n","        x = self.fc2(x)\n","        #print(x.size())\n","        x = torch.reshape(x, (128, 6, 21))\n","        #m = nn.Softmax(dim=2)\n","        x_out = x\n","        #print(x_out.shape)\n","        return x_out"]},{"cell_type":"code","source":["class MyCNN2(torch.nn.Module):\n","    def __init__(self):\n","        super(MyCNN2, self).__init__()\n","        self.conv1 = torch.nn.Conv2d(1, 32, 3)\n","        self.conv2 = torch.nn.Conv2d(32, 64, 3)\n","        self.conv3 = torch.nn.Conv2d(64, 64, 3)\n"," \n","        self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\n","\n","        self.drop1 = torch.nn.Dropout2d(0.25)\n","        self.drop2 = torch.nn.Dropout(0.5)\n","        self.flatten = torch.nn.Flatten()\n","\n","        self.fc1 = torch.nn.Linear(190464,512)\n","        self.fc2 = torch.nn.Linear(512,126)\n","        \n"," \n","    def forward(self, x):\n","        # print(x.size())\n","        x = f.relu(self.conv1(x))\n","        # print(x.size())\n","        x = f.relu(self.conv2(x))\n","        #print(x.size())\n","        x = f.relu(self.conv3(x))\n","        #print(x.size())\n","        x = self.pool(x)\n","        #print(x.size())\n","        x = self.drop1(x)\n","        #print(x.size())\n","        x = self.flatten(x)\n","        #print(x.size())\n","        x = f.relu(self.fc1(x))\n","        x = self.drop2(x)\n","        #print(x.size())\n","        x = self.fc2(x)\n","        #print(x.size())\n","        x = torch.reshape(x, (128, 6, 21)) \n","        #m = nn.Softmax(dim=2)\n","        x_out = x\n","        #print(x_out.shape)\n","        return x_out"],"metadata":{"id":"fNPVoq3_u-Aw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyVGG(torch.nn.Module):\n","  def __init__(self):\n","    super(MyVGG, self).__init__()\n","    self.conv1 = torch.nn.Conv2d(1, 32, 3)\n","    self.bn1 = nn.BatchNorm2d(32)\n","    self.conv2 = torch.nn.Conv2d(32, 32, 3, padding=1)\n","    self.bn2 = nn.BatchNorm2d(32)\n","    self.conv3 = torch.nn.Conv2d(32, 64, 3)\n","    self.bn3 = nn.BatchNorm2d(64)\n","    self.conv4 = torch.nn.Conv2d(64, 64, 3, padding=1)\n","    self.bn4 = nn.BatchNorm2d(64)\n","    self.conv5 = torch.nn.Conv2d(64, 128, 3)\n","    self.bn5 = nn.BatchNorm2d(128)\n","    self.conv6 = torch.nn.Conv2d(128, 256, 3, padding=1)\n","    self.bn6 = nn.BatchNorm2d(256)\n","    self.conv7 = torch.nn.Conv2d(256, 256, 3, padding=1)\n","    self.bn7 = nn.BatchNorm2d(256)\n","    self.conv8 = torch.nn.Conv2d(256, 512, 3, padding=1)\n","    self.bn8 = nn.BatchNorm2d(512)\n","    self.conv9 = torch.nn.Conv2d(512, 512, 3, padding=1)\n","    self.bn9 = nn.BatchNorm2d(512)\n","    self.relu = nn.ReLU(inplace=True)\n","\n","    self.pool = torch.nn.MaxPool2d(2, 2)\n","\n","    self.drop1 = torch.nn.Dropout2d(0.25)\n","    self.drop2 = torch.nn.Dropout(0.5)\n","    self.flatten = torch.nn.Flatten()\n","\n","    self.fc1 = torch.nn.Linear(47616,128)\n","    self.fc2 = torch.nn.Linear(128,126)\n","\n","  def forward(self, x):\n","    #print(x.size())\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv3(out)\n","    out = self.bn3(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv4(out)\n","    out = self.bn4(out)\n","    out = self.relu(out)\n","    #print(out.size())\n","    out = self.conv5(out)\n","    out = self.bn5(out)\n","    out = self.relu(out)\n","    out = self.conv6(out)\n","    out = self.bn6(out)\n","    out = self.relu(out)\n","    out = self.conv7(out)\n","    out = self.bn7(out)\n","    out = self.relu(out)\n","    out = self.conv8(out)\n","    out = self.bn8(out)\n","    out = self.relu(out)\n","    out = self.conv9(out)\n","    out = self.bn9(out)\n","    out = self.relu(out)\n","\n","    out = self.pool(out)\n","    out = self.drop1(out)\n","    #print(out.size())\n","    out = self.flatten(out)\n","    #print(out.size())\n","    out = self.fc1(out)\n","    out = self.relu(out)\n","    out = self.drop2(out)\n","    out = self.fc2(out)\n","    out = torch.reshape(out, (batch_size, 6, 21))\n","\n","    return out"],"metadata":{"id":"9ZEHCQ0utO8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlHs4dFcNty_","executionInfo":{"status":"ok","timestamp":1656960772664,"user_tz":-540,"elapsed":2583,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"9fb7591b-547c-483e-bd4f-2fe98ad1a391"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"]}]},{"cell_type":"code","source":["from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","# helpers\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","# classes\n","\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x):\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n","        super().__init__()\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n","                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n","            ]))\n","    def forward(self, x):\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","        return x\n","\n","class tab_transformer(nn.Module):\n","    def __init__(self, *, input_size, input_hight, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.input_liniear = nn.Linear(input_size, dim)\n","        self.pos_embedding = nn.Parameter(torch.randn(1, input_hight + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","        self.flatten = nn.Flatten(1, -1)\n","        # self.mlp_head = nn.Sequential(\n","        #     nn.LayerNorm(193*dim),\n","        #     nn.Linear(193*dim, input_size*6*21)\n","        # )\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, 6*21)\n","        )\n","\n","\n","    def forward(self, x):\n","      #\n","        x = self.input_liniear(x)\n","        print(x)\n","        b, n, _ = x.shape\n","        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","        x = self.transformer(x)\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","        x = self.to_latent(x)\n","        x = self.mlp_head(x)\n","        x = torch.reshape(x, (-1, 6, 21))\n","        return x"],"metadata":{"id":"BHI7OX-OMnsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OihZBTm0Z2PM"},"outputs":[],"source":["def tab2pitch(tab):\n","    pitch_vector = np.zeros(44)\n","    string_pitches = [40, 45, 50, 55, 59, 64]\n","    for string_num in range(len(tab)):\n","        fret_class = tab[string_num]\n","        # 0 means that the string is closed \n","        if fret_class > 0:\n","            pitch_num = fret_class + string_pitches[string_num] - 41\n","            pitch_vector[pitch_num] = 1\n","    return pitch_vector\n","\n","def pitch_precision(pred, gt):\n","    pitch_pred = np.array(list(map(tab2pitch,pred)))\n","    pitch_gt = np.array(list(map(tab2pitch,gt)))\n","    numerator = np.sum(np.multiply(pitch_pred, pitch_gt).flatten())\n","    denominator = np.sum(pitch_pred.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def pitch_recall(pred, gt):\n","    pitch_pred = np.array(list(map(tab2pitch,pred)))\n","    pitch_gt = np.array(list(map(tab2pitch,gt)))\n","    numerator = np.sum(np.multiply(pitch_pred, pitch_gt).flatten())\n","    denominator = np.sum(pitch_gt.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def pitch_f_measure(pred, gt):\n","    p = pitch_precision(pred, gt)\n","    r = pitch_recall(pred, gt)\n","    f = (2 * p * r) / (p + r)\n","    return f\n","\n","def tab2bin(tab):\n","    tab_arr = np.zeros((6,20))\n","    for string_num in range(len(tab)):\n","        fret_class = tab[string_num]\n","        # 0 means that the string is closed \n","        if fret_class > 0:\n","            fret_num = fret_class - 1\n","            tab_arr[string_num][fret_num] = 1\n","    return tab_arr\n","\n","def tab_precision(pred, gt):\n","    # get rid of \"closed\" class, as we only want to count positives\n","    tab_pred = np.array(list(map(tab2bin,pred)))\n","    tab_gt = np.array(list(map(tab2bin,gt)))\n","    numerator = np.sum(np.multiply(tab_pred, tab_gt).flatten())\n","    denominator = np.sum(tab_pred.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def tab_recall(pred, gt):\n","    # get rid of \"closed\" class, as we only want to count positives\n","    tab_pred = np.array(list(map(tab2bin,pred)))\n","    tab_gt = np.array(list(map(tab2bin,gt)))\n","    numerator = np.sum(np.multiply(tab_pred, tab_gt).flatten())\n","    denominator = np.sum(tab_gt.flatten())\n","    return (1.0 * numerator) / denominator\n","\n","def tab_f_measure(pred, gt):\n","    p = tab_precision(pred, gt)\n","    r = tab_recall(pred, gt)\n","    f = (2 * p * r) / (p + r)\n","    return f"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDjV4w-ftTHe","executionInfo":{"status":"error","timestamp":1656903711005,"user_tz":-540,"elapsed":13090,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"colab":{"base_uri":"https://localhost:8080/","height":402},"outputId":"ab933db4-6f38-4817-d80b-9865329ca260"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-54baff4bb3a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#net = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\",map_location='cuda:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn2-model.path\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnetvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/myvgg-model.path\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         loaded_storages[key] = torch.storage._TypedStorage(\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m             dtype=dtype)\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_string_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import scipy.stats as stats\n","\n","net = MyCNN()\n","net2 = MyCNN2()\n","vgg = MyVGG()\n","#net = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\",map_location='cuda:0')\n","net = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\",map_location=\"cuda:0\")\n","# net2 = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn2-model.path\",map_location=\"cuda:0\")\n","# netvgg = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/myvgg-model.path\",map_location=\"cuda:0\")\n","net.eval()\n","acc = {}\n","acc[\"pp\"] = []\n","acc[\"pr\"] = []\n","acc[\"pf\"] = []\n","acc[\"tp\"] = []\n","acc[\"tr\"] = []\n","acc[\"tf\"] = []\n","acc[\"tdr\"] = []\n","acc2 = {}\n","acc2[\"pp\"] = []\n","acc2[\"pr\"] = []\n","acc2[\"pf\"] = []\n","acc2[\"tp\"] = []\n","acc2[\"tr\"] = []\n","acc2[\"tf\"] = []\n","acc2[\"tdr\"] = []\n","accvgg = {}\n","accvgg[\"pp\"] = []\n","accvgg[\"pr\"] = []\n","accvgg[\"pf\"] = []\n","accvgg[\"tp\"] = []\n","accvgg[\"tr\"] = []\n","accvgg[\"tf\"] = []\n","accvgg[\"tdr\"] = []\n","training_generator, validation_generator = partition_data(0)\n","for i in range(615):\n","  input_data1, input_data2, tempo = validation_generator[i]\n","  images = input_data1.astype(np.float32)\n","  labels = input_data2.astype(np.float32)\n","  images = torch.tensor(np.transpose(images, (0,3,1,2)), device = \"cuda:0\")\n","  labels = torch.tensor(labels)\n","  output = net(images)\n","  _, pre = torch.max(output.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","  pred = np.zeros((128, 6), dtype=np.int16)\n","\n","  note16 = 2580/4/tempo\n","  for j in range(int(batch_size//note16)):\n","    out = pre[int(j * note16):int((j+1) * note16)]\n","    mode_val, mode_num = stats.mode(out, axis=0)\n","    for k in range(len(out)):\n","      for l, fret in enumerate(mode_val[0]):\n","        pred[int(j * note16)+k][l] = fret\n","\n","  label = labels.to('cpu').detach().numpy().copy()\n","  gt = np.argmax(label, 2)\n","  acc[\"pp\"].append(pitch_precision(pred, gt))\n","  acc[\"pr\"].append(pitch_recall(pred, gt))\n","  acc[\"pf\"].append(pitch_f_measure(pred, gt))\n","  acc[\"tp\"].append(tab_precision(pred, gt))\n","  acc[\"tr\"].append(tab_recall(pred, gt))\n","  acc[\"tf\"].append(tab_f_measure(pred, gt))\n","for i in range(615):\n","  input_data1, input_data2, tempo = validation_generator[i]\n","  images = input_data1.astype(np.float32)\n","  labels = input_data2.astype(np.float32)\n","  images = torch.tensor(np.transpose(images, (0,3,1,2)), device = \"cuda:0\")\n","  labels = torch.tensor(labels)\n","  output = net(images)\n","  _, pre = torch.max(output.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  label = labels.to('cpu').detach().numpy().copy()\n","  gt = np.argmax(label, 2)\n","  acc2[\"pp\"].append(pitch_precision(pre, gt))\n","  acc2[\"pr\"].append(pitch_recall(pre, gt))\n","  acc2[\"pf\"].append(pitch_f_measure(pre, gt))\n","  acc2[\"tp\"].append(tab_precision(pre, gt))\n","  acc2[\"tr\"].append(tab_recall(pre, gt))\n","  acc2[\"tf\"].append(tab_f_measure(pre, gt))\n","for i in range(615):\n","  input_data1, input_data2, tempo = validation_generator[i]\n","  images = input_data1.astype(np.float32)\n","  labels = input_data2.astype(np.float32)\n","  images = torch.tensor(np.transpose(images, (0,3,1,2)), device = \"cuda:0\")\n","  labels = torch.tensor(labels)\n","  output = netvgg(images)\n","  _, pre = torch.max(output.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  label = labels.to('cpu').detach().numpy().copy()\n","  gt = np.argmax(label, 2)\n","  accvgg[\"pp\"].append(pitch_precision(pre, gt))\n","  accvgg[\"pr\"].append(pitch_recall(pre, gt))\n","  accvgg[\"pf\"].append(pitch_f_measure(pre, gt))\n","  accvgg[\"tp\"].append(tab_precision(pre, gt))\n","  accvgg[\"tr\"].append(tab_recall(pre, gt))\n","  accvgg[\"tf\"].append(tab_f_measure(pre, gt))"]},{"cell_type":"code","source":["netvgg.eval()\n","acc = {}\n","acc[\"pp\"] = []\n","acc[\"pr\"] = []\n","acc[\"tp\"] = []\n","acc[\"tr\"] = []\n","training_generator, validation_generator = partition_data(0)\n","for i in range(615):\n","  input_data1, input_data2, tempo = validation_generator[i]\n","  images = input_data1.astype(np.float32)\n","  labels = input_data2.astype(np.float32)\n","  images = torch.tensor(np.transpose(images, (0,3,1,2)), device = \"cuda:0\")\n","  labels = torch.tensor(labels)\n","  output = netvgg(images)\n","  _, pre = torch.max(output.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  label = labels.to('cpu').detach().numpy().copy()\n","  gt = np.argmax(label, 2)\n","  acc[\"pp\"].append(pitch_precision(pre, gt))\n","  acc[\"pr\"].append(pitch_recall(pre, gt))\n","  acc[\"tp\"].append(tab_precision(pre, gt))\n","  acc[\"tr\"].append(tab_recall(pre, gt))\n","#np.savez(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved/acc.npz\", acc)"],"metadata":{"id":"AP8K9dSOv_yZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656576412803,"user_tz":-540,"elapsed":871448,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"9b6b7cca-e92a-48e0-dea4-5ea0a56cd4d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in double_scalars\n"]}]},{"cell_type":"code","source":["from librosa.core.spectrum import perceptual_weighting\n","import scipy.stats as stats\n","\n","net = MyCNN()\n","net = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/c_2022-05-13_16-33-31/path/mytabcnn-model.path\",map_location='cuda:0')\n","net.eval()\n","acc3 = {}\n","acc3[\"pp\"] = []\n","acc3[\"pr\"] = []\n","acc3[\"pf\"] = []\n","acc3[\"tp\"] = []\n","acc3[\"tr\"] = []\n","acc3[\"tf\"] = []\n","acc3[\"tdr\"] = []\n","\n","windowsize = 2\n","\n","training_generator, validation_generator = partition_data(0)\n","for i in range(615):\n","  input_data1, input_data2, tempo = validation_generator[i]\n","  images = input_data1.astype(np.float32)\n","  labels = input_data2.astype(np.float32)\n","  images = torch.tensor(np.transpose(images, (0,3,1,2)), device = \"cuda:0\")\n","  labels = torch.tensor(labels)\n","  output = net(images)\n","  _, pre = torch.max(output.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  pret = pre.T\n","  for j, string in enumerate(pret):\n","    index = np.arange(len(string)-(2*windowsize))\n","    np.random.shuffle(index)\n","    for k in index:\n","      window = pret[j][k:k+(2*windowsize)+1]\n","      mode_val, mode_num = stats.mode(window, axis = 0)\n","      pret[j][k] = mode_val[0]\n","  pred = pret.T\n","\n","  label = labels.to('cpu').detach().numpy().copy()\n","  gt = np.argmax(label, 2)\n","  acc3[\"pp\"].append(pitch_precision(pred, gt))\n","  acc3[\"pr\"].append(pitch_recall(pred, gt))\n","  acc3[\"pf\"].append(pitch_f_measure(pred, gt))\n","  acc3[\"tp\"].append(tab_precision(pred, gt))\n","  acc3[\"tr\"].append(tab_recall(pred, gt))\n","  acc3[\"tf\"].append(tab_f_measure(pred, gt))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1zLcdurQ28c","executionInfo":{"status":"ok","timestamp":1656675973944,"user_tz":-540,"elapsed":995071,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"03f90df1-87eb-48af-c8ba-b69813c8487b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n"]}]},{"cell_type":"code","source":["type(acc3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"Kc7WRpRQlwG1","executionInfo":{"status":"error","timestamp":1656678594653,"user_tz":-540,"elapsed":13,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"ca0e463e-0e14-4126-882e-d451352b6cb3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-039fdb75d9eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'acc3' is not defined"]}]},{"cell_type":"code","source":["pp = np.average(acc[\"pp\"])\n","pr = np.average(acc[\"pr\"])\n","tp = np.average(acc[\"tp\"])\n","tr = np.average(acc[\"tr\"])\n","pp2 = np.average(acc2[\"pp\"])\n","pr2 = np.average(acc2[\"pr\"])\n","tp2 = np.average(acc2[\"tp\"])\n","tr2 = np.average(acc2[\"tr\"])\n","\n","print(\"pp:\" + str(pp) + \" \" + str(pp2))\n","print(\"pr:\" + str(pr) + \" \" + str(pr2))\n","print(\"tp:\" + str(tp) + \" \" + str(tp2))\n","print(\"tr:\" + str(tr) + \" \" + str(tr2))\n","print(\"pf:\" + str((2 * pp * pr)/(pp + pr)) + \" \" + str((2 * pp2 * pr2)/(pp2 + pr2)))\n","print(\"pf:\" + str((2 * tp * tr)/(tp + tr)) + \" \" + str((2 * tp2 * tr2)/(tp2 + tr2)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHNQCtaG-Z_k","executionInfo":{"status":"ok","timestamp":1656334994503,"user_tz":-540,"elapsed":238,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"caaf4b8a-2ada-42da-eeac-381ce88eed85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pp:0.8165048115130572 0.8329365695013382\n","pr:0.6724472672836339 0.6281856500520757\n","tp:0.6520357358297051 0.6720381347889317\n","tr:0.5673035914100911 0.5338326420650186\n","pf:0.7375071864900022 0.7162149659516778\n","pf:0.6067256364169871 0.5950154858197935\n"]}]},{"cell_type":"code","source":["loaded = np.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved/acc.npz\", allow_pickle=True)\n","acc = loaded[\"arr_0\"]\n","acc = acc.item()\n","print(sum(acc[\"tp\"])/len(acc[\"tp\"]), np.average(acc[\"tr\"]))\n","# for i, out in enumerate(acc[\"tf\"]):\n","#   if np.isnan(out):\n","#     print(i)\n","#     print(out)\n","input_data1, input_data2, tempo = validation_generator[610]\n","images = input_data1.astype(np.float32)\n","labels = input_data2.astype(np.float32)\n","images = torch.tensor(np.transpose(images, (0,3,1,2)), device = \"cuda:0\")\n","labels = torch.tensor(labels)\n","output = net(images)\n","_, pre = torch.max(output.data, 2)\n","label = labels.to('cpu').detach().numpy().copy()\n","gt = np.argmax(label, 2)\n","# print(tab2bin(pre[0]))\n","# print(tab2bin(gt[0]))\n","# print(tab_precision(pre, gt))\n","# print(tab_recall(pre, gt))\n","tab_f_measure(pre, gt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"ssLlWOxlimiw","executionInfo":{"status":"error","timestamp":1656081260126,"user_tz":-540,"elapsed":850,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"110f36c8-a656-445b-e761-bce8896d584a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7186167916471766 0.5910489966052926\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-788c2fb191b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minput_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m610\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'validation_generator' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2647,"status":"ok","timestamp":1656960786832,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"},"user_tz":-540},"id":"aV8d3jtlJy4Y","outputId":"8561a958-234f-4a69-8b21-0aa62779c65c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"]}],"source":["!pip install pydub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZO2o3yt6eat"},"outputs":[],"source":["from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","from matplotlib import animation, rc\n","import numpy as np\n","from pydub import AudioSegment\n","from pydub.playback import play\n","import IPython.display"]},{"cell_type":"code","source":["annos_path = \"/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr/c/\"\n","anno_list = os.listdir(annos_path)"],"metadata":{"id":"TefKN8u0k9mT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["$$\n","Loss = -1/N\\sum_{j=1}^6\\sum_{i=1}^Nlogp[z_{ij}\\in C_{z_{ij}}] + \\beta(\\sum_{i=1}^N1/6\\sum_{j=1}^6(x_{ij}-\\overline{x_i})^2)\n","$$"],"metadata":{"id":"ZA11xlvS0H8z"}},{"cell_type":"markdown","source":["$$\n","(\\beta = 0.1,lr)\n","$$"],"metadata":{"id":"n8tGn7Of5IBQ"}},{"cell_type":"markdown","source":["$$\n","Loss = -1/N\\sum_{j=1}^6\\sum_{i=1}^Nlogp[z_{ij}\\in C_{z_{ij}}] + \\beta(\\sum_{i=1}^N1/5\\sum_{j=i-2}^{i+2}(\\overline{x}_j-\\overline{\\overline{x}})^2)\n","$$"],"metadata":{"id":"sZVTfUlK7gY-"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":689,"output_embedded_package_id":"1EHGUdHsxJN8lbjXwDlWD6o1fvQeaWbSS"},"executionInfo":{"elapsed":162027,"status":"ok","timestamp":1656962748195,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"},"user_tz":-540},"id":"7VVzMVluXl7v","outputId":"1a4b2e81-8885-46ae-b044-28715f056fad"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#%matplotlib nbagg\n","plt.rcParams['figure.figsize'] = (16.0, 6.0)\n","\n","import scipy.stats as stats\n","\n","net = MyCNN()\n","net = torch.load(\"/content/drive/MyDrive/gozu/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\",map_location=\"cuda:0\")\n","\n","file_name = anno_list[24]\n","anno = annos_path + file_name\n","load = np.load(anno)\n","print(anno)\n","tempo = int(file_name.split(\"-\")[1])\n","print(tempo)\n","label = load[\"labels\"]\n","repr = load[\"repr\"]\n","\n","fig = plt.figure()\n","\n","ims = []\n","\n","labels = label[:len(label)//128*128]\n","repr = np.pad(repr, [(4,4), (0,0)], mode = \"constant\")\n","input_data = []\n","for i in range(len(repr)-8):\n","  input_data.append(repr[i:i+9])\n","repr = np.transpose(np.expand_dims(np.swapaxes(input_data, 0, 1), -1), (1,3,2,0))\n","input = []\n","for i in range(len(repr)//128):\n","  input.append(repr[i*128:(i+1)*128])\n","input_data = np.array(input)\n","reprs = np.zeros(((len(repr)//128*128, 6, 21)))\n","reprs2 = np.zeros(((len(repr)//128*128, 6, 21)))\n","\n","results = {}\n","results[\"pp\"] = []\n","results[\"pr\"] = []\n","results[\"tp\"] = []\n","results[\"tr\"] = []\n","results2 = {}\n","results2[\"pp\"] = []\n","results2[\"pr\"] = []\n","results2[\"tp\"] = []\n","results2[\"tr\"] = []\n","\n","for i in range(len(repr)//128):\n","  images = torch.tensor(input_data[i], dtype=torch.float32, device=\"cuda\")\n","  outputs = net(images)\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","  pred = np.zeros((128, 6), dtype=np.int16)\n","\n","  note16 = 2580/4/tempo\n","  for j in range(int(batch_size//note16)):\n","    out = pre[int(j * note16):int((j+1) * note16)]\n","    mode_val, mode_num = stats.mode(out, axis=0)\n","    for k in range(len(out)):\n","      for l, fret in enumerate(mode_val[0]):\n","        pred[int(j * note16)+k][l] = fret\n","\n","  label = labels[i*128:(i+1)*128]\n","  gt = np.argmax(label, 2)\n","  results[\"pp\"].append(pitch_precision(pred,gt))\n","  results[\"pr\"].append(pitch_recall(pred,gt))\n","  results[\"tp\"].append(tab_precision(pred,gt))\n","  results[\"tr\"].append(tab_recall(pred,gt))\n","  results2[\"pp\"].append(pitch_precision(pre,gt))\n","  results2[\"pr\"].append(pitch_recall(pre,gt))\n","  results2[\"tp\"].append(tab_precision(pre,gt))\n","  results2[\"tr\"].append(tab_recall(pre,gt))\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  note16 = 2580/4/tempo\n","  for j in range(int(batch_size//note16)):\n","    out = pre[int(j * note16):int((j+1) * note16)]\n","    mode_val, mode_num = stats.mode(out, axis=0)\n","    for k in range(len(out)):\n","      for l, fret in enumerate(mode_val[0]):\n","        pred[int(j * note16)+k][l] = fret\n","\n","  for j, strings in enumerate(pred):\n","    for k, fret in enumerate(strings):\n","      reprs[i*128+j][k][fret] = 1\n","  for j, strings in enumerate(pre):\n","    for k, fret in enumerate(strings):\n","      reprs2[i*128+j][k][fret] = 1\n","reprs = np.array(reprs)\n","reprs2 = np.array(reprs2)\n","\n","print(reprs.shape, labels.shape)\n","for i in results:\n","  print(i + str(np.average(results[i])) + \" \" + str(np.average(results2[i])))\n","\n","for i, (rp, rp2, lb) in enumerate(zip(reprs, reprs2, labels)):\n","  im = Image.new('RGB', (1000, 350), (255, 255, 255))\n","  draw = ImageDraw.Draw(im)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for j in range(6):\n","    draw.line(((523, (j+1) * 50), (980, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line(((500 + (j+1) * 23, 50), (500 + (j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          # if k_lb == 1:\n","          #   if k_pr == k_lb:\n","          #     draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","          #   else:\n","          #     draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp2, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          # if k_pr == 1:\n","          #   draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","            # if k_pr == k_lb:\n","            #   draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            # else:\n","            #   draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  im = plt.imshow(np.array(im))\n","  \n","  ims.append([im])\n","  # if i == 10:\n","  #   break\n","\n","ani = animation.ArtistAnimation(fig, ims, interval=23)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"]},{"cell_type":"code","source":["#%matplotlib nbagg\n","plt.rcParams['figure.figsize'] = (16.0, 6.0)\n","\n","import scipy.stats as stats\n","\n","\n","net = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\",map_location=\"cuda:0\")\n","vec1 = torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/saved2/new/tabvec2-model.path\",map_location=\"cuda:0\")\n","\n","file_name = anno_list[0]\n","anno = annos_path + file_name\n","load = np.load(anno)\n","print(anno)\n","tempo = int(file_name.split(\"-\")[1])\n","print(tempo)\n","label = load[\"labels\"]\n","repr = load[\"repr\"]\n","\n","fig = plt.figure()\n","\n","ims = []\n","\n","labels = label[:len(label)//128*128]\n","repr = np.pad(repr, [(4,4), (0,0)], mode = \"constant\")\n","input_data = []\n","for i in range(len(repr)-8):\n","  input_data.append(repr[i:i+9])\n","repr = np.transpose(np.expand_dims(np.swapaxes(input_data, 0, 1), -1), (1,3,2,0))\n","input = []\n","for i in range(len(repr)//128):\n","  input.append(repr[i*128:(i+1)*128])\n","input_data = np.array(input)\n","reprs = np.zeros(((len(repr)//128*128, 6, 21)))\n","reprsvec = np.zeros(((len(repr)//128*128, 6, 21)))\n","\n","results = {}\n","results[\"pp\"] = []\n","results[\"pr\"] = []\n","results[\"tp\"] = []\n","results[\"tr\"] = []\n","resultsvec = {}\n","resultsvec[\"pp\"] = []\n","resultsvec[\"pr\"] = []\n","resultsvec[\"tp\"] = []\n","resultsvec[\"tr\"] = []\n","\n","for i in range(len(repr)//128):\n","  images = torch.tensor(input_data[i], dtype=torch.float32, device=\"cuda\")\n","  outputs = net(images)\n","  outputsvec = vec1(images)\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","  _, prevec = torch.max(outputsvec.data, 2)\n","  prevec = prevec.to('cpu').detach().numpy().copy()\n","\n","  label = labels[i*128:(i+1)*128]\n","  gt = np.argmax(label, 2)\n","  results[\"pp\"].append(pitch_precision(pre,gt))\n","  results[\"pr\"].append(pitch_recall(pre,gt))\n","  results[\"tp\"].append(tab_precision(pre,gt))\n","  results[\"tr\"].append(tab_recall(pre,gt))\n","  resultsvec[\"pp\"].append(pitch_precision(prevec,gt))\n","  resultsvec[\"pr\"].append(pitch_recall(prevec,gt))\n","  resultsvec[\"tp\"].append(tab_precision(prevec,gt))\n","  resultsvec[\"tr\"].append(tab_recall(prevec,gt))\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","  _, prevec = torch.max(outputsvec.data, 2)\n","  prevec = prevec.to('cpu').detach().numpy().copy()\n","\n","  for j, strings in enumerate(pre):\n","    for k, fret in enumerate(strings):\n","      reprs[i*128+j][k][fret] = 1\n","  for j, strings in enumerate(prevec):\n","    for k, fret in enumerate(strings):\n","      reprsvec[i*128+j][k][fret] = 1\n","reprs = np.array(reprs)\n","reprsvec = np.array(reprsvec)\n","\n","print(reprs.shape, labels.shape)\n","for i in results:\n","  print(i + str(np.average(results[i])) + \" \" + str(np.average(resultsvec[i])))\n","\n","for i, (rp, rp2, lb) in enumerate(zip(reprs, reprsvec, labels)):\n","  im = Image.new('RGB', (1000, 350), (255, 255, 255))\n","  draw = ImageDraw.Draw(im)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for j in range(6):\n","    draw.line(((523, (j+1) * 50), (980, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line(((500 + (j+1) * 23, 50), (500 + (j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            if k_pr == k_lb:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            else:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp2, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            if k_pr == k_lb:\n","              draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            else:\n","              draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  im = plt.imshow(np.array(im))\n","  \n","  ims.append([im])\n","  # if i == 10:\n","  #   break\n","\n","ani = animation.ArtistAnimation(fig, ims, interval=23)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":700,"output_embedded_package_id":"1U0dDEK-34lO18lQMoqoIn-PXOQZ50NZ-"},"id":"9_VQnzxMu4Fz","executionInfo":{"status":"ok","timestamp":1656905246857,"user_tz":-540,"elapsed":156902,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"7e2cb300-a8b8-4ded-923a-2e45e15d9bde"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#%matplotlib nbagg\n","plt.rcParams['figure.figsize'] = (16.0, 6.0)\n","\n","import scipy.stats as stats\n","\n","net = MyCNN()\n","trnsfrmr = tab_transformer(\n","        input_size = 9,\n","        input_hight = 192, \n","        dim = 1024,\n","        depth = 6,\n","        heads = 16,\n","        mlp_dim = 2048,\n","        dropout = 0.1,\n","        emb_dropout = 0.1\n","        )\n","net = torch.load(\"/content/drive/MyDrive/gozu/2021/MyTabCNN/model/saved2/new/mytabcnn-model.path\",map_location=\"cuda:0\")\n","trnsfrmr = torch.load(\"/content/drive/MyDrive/gozu/2021/MyTabCNN/model/saved2/new/mytransformer-model.path\",map_location=\"cuda:0\")\n","\n","file_name = anno_list[0]\n","anno = annos_path + file_name\n","load = np.load(anno)\n","print(anno)\n","tempo = int(file_name.split(\"-\")[1])\n","print(tempo)\n","label = load[\"labels\"]\n","repr = load[\"repr\"]\n","\n","fig = plt.figure()\n","\n","ims = []\n","\n","labels = label[:len(label)//128*128]\n","repr = np.pad(repr, [(4,4), (0,0)], mode = \"constant\")\n","input_data = []\n","for i in range(len(repr)-8):\n","  input_data.append(repr[i:i+9])\n","repr = np.transpose(np.expand_dims(np.swapaxes(input_data, 0, 1), -1), (1,3,2,0))\n","input = []\n","for i in range(len(repr)//128):\n","  input.append(repr[i*128:(i+1)*128])\n","input_data = np.array(input)\n","reprs = np.zeros(((len(repr)//128*128, 6, 21)))\n","reprsvec = np.zeros(((len(repr)//128*128, 6, 21)))\n","\n","results = {}\n","results[\"pp\"] = []\n","results[\"pr\"] = []\n","results[\"tp\"] = []\n","results[\"tr\"] = []\n","resultsvec = {}\n","resultsvec[\"pp\"] = []\n","resultsvec[\"pr\"] = []\n","resultsvec[\"tp\"] = []\n","resultsvec[\"tr\"] = []\n","\n","for i in range(len(repr)//128):\n","  images = torch.tensor(input_data[i], dtype=torch.float32, device=\"cuda\")\n","  outputs = net(images)\n","  outputsvec = trnsfrmr(images)\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","  _, prevec = torch.max(outputsvec.data, 2)\n","  prevec = prevec.to('cpu').detach().numpy().copy()\n","\n","  label = labels[i*128:(i+1)*128]\n","  gt = np.argmax(label, 2)\n","  results[\"pp\"].append(pitch_precision(pre,gt))\n","  results[\"pr\"].append(pitch_recall(pre,gt))\n","  results[\"tp\"].append(tab_precision(pre,gt))\n","  results[\"tr\"].append(tab_recall(pre,gt))\n","  resultsvec[\"pp\"].append(pitch_precision(prevec,gt))\n","  resultsvec[\"pr\"].append(pitch_recall(prevec,gt))\n","  resultsvec[\"tp\"].append(tab_precision(prevec,gt))\n","  resultsvec[\"tr\"].append(tab_recall(prevec,gt))\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","  _, prevec = torch.max(outputsvec.data, 2)\n","  prevec = prevec.to('cpu').detach().numpy().copy()\n","\n","  for j, strings in enumerate(pre):\n","    for k, fret in enumerate(strings):\n","      reprs[i*128+j][k][fret] = 1\n","  for j, strings in enumerate(prevec):\n","    for k, fret in enumerate(strings):\n","      reprsvec[i*128+j][k][fret] = 1\n","reprs = np.array(reprs)\n","reprsvec = np.array(reprsvec)\n","\n","print(reprs.shape, labels.shape)\n","for i in results:\n","  print(i + str(np.average(results[i])) + \" \" + str(np.average(resultsvec[i])))\n","\n","for i, (rp, rp2, lb) in enumerate(zip(reprs, reprsvec, labels)):\n","  im = Image.new('RGB', (1000, 350), (255, 255, 255))\n","  draw = ImageDraw.Draw(im)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for j in range(6):\n","    draw.line(((523, (j+1) * 50), (980, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line(((500 + (j+1) * 23, 50), (500 + (j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            if k_pr == k_lb:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            else:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp2, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            if k_pr == k_lb:\n","              draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            else:\n","              draw.pieslice(((500-17 + fret*23, 45 + (5-string)*50), (500-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  im = plt.imshow(np.array(im))\n","  \n","  ims.append([im])\n","  # if i == 10:\n","  #   break\n","\n","ani = animation.ArtistAnimation(fig, ims, interval=23)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"55EFGXuqO2tX","executionInfo":{"status":"error","timestamp":1656952625544,"user_tz":-540,"elapsed":1217,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"e80d8be0-b2a5-45c8-8ba7-fc841cadd507"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr/c/00_BN1-129-Eb_comp.npz\n","129\n","torch.Size([128, 1, 192, 1024])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-d52292b1a8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0moutputsvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrnsfrmr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-4796cb916160>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_liniear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mcls_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1 1 d -> b 1 d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1152x432 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["for i in zip(results[\"pp\"],results[\"tp\"]):\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcDxUDCfQl1y","executionInfo":{"status":"ok","timestamp":1656905479460,"user_tz":-540,"elapsed":8,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"}},"outputId":"272cea11-e388-4b3a-c748-7ba48036f007"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(0.9808306709265175, 0.9808306709265175)\n","(0.9572192513368984, 0.9572192513368984)\n","(0.9682539682539683, 0.9682539682539683)\n","(0.9925925925925926, 0.9925925925925926)\n","(0.9813432835820896, 0.9813432835820896)\n","(0.8535353535353535, 0.8535353535353535)\n","(0.9741935483870968, 0.9741935483870968)\n"]}]},{"cell_type":"code","source":["#%matplotlib nbagg\n","\n","file_name = anno_list[0]\n","anno = annos_path + file_name\n","load = np.load(anno)\n","print(anno)\n","tempo = int(file_name.split(\"-\")[1])\n","print(tempo)\n","label = load[\"labels\"]\n","repr = load[\"repr\"]\n","print(label.shape, repr.shape)\n","\n","fig = plt.figure()\n","\n","ims = []\n","\n","labels = label[:len(label)//128*128]\n","\n","repr = np.pad(repr, [(4,4), (0,0)], mode = \"constant\")\n","input_data = []\n","for i in range(len(repr)-8):\n","  input_data.append(repr[i:i+9])\n","repr = np.transpose(np.expand_dims(np.swapaxes(input_data, 0, 1), -1), (1,3,2,0))\n","input = []\n","for i in range(len(repr)//128):\n","  input.append(repr[i*128:(i+1)*128])\n","input_data = np.array(input)\n","reprs = np.zeros(((len(repr)//128*128, 6, 21)))\n","\n","results = {}\n","results[\"pp\"] = []\n","results[\"pr\"] = []\n","results[\"pf\"] = []\n","results[\"tp\"] = []\n","results[\"tr\"] = []\n","results[\"tf\"] = []\n","\n","for i in range(len(repr)//128):\n","  images = torch.tensor(input_data[i], dtype=torch.float32, device=\"cuda\")\n","  outputs = net(images)\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  note16 = 2580/4/tempo\n","  for i in range(int(batch_size//note16)):\n","    out = pre[int(i * note16):int((i+1) * note16)]\n","    mode_val, mode_num = stats.mode(out, axis=0)\n","    for j in range(len(out)):\n","      for k, fret in enumerate(mode_val[0]):\n","        pre[int(i * note16)+j][k] = fret\n","\n","  label = labels[i*128:(i+1)*128]\n","  gt = np.argmax(label, 2)\n","  results[\"pp\"].append(pitch_precision(pre,gt))\n","  results[\"pr\"].append(pitch_recall(pre,gt))\n","  results[\"pf\"].append(pitch_f_measure(pre,gt))\n","  results[\"tp\"].append(tab_precision(pre,gt))\n","  results[\"tr\"].append(tab_recall(pre,gt))\n","  results[\"tf\"].append(tab_f_measure(pre,gt))\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  pre = pre.to('cpu').detach().numpy().copy()\n","\n","  note16 = 2580/4/tempo\n","  for i in range(int(batch_size//note16)):\n","    out = pre[int(i * note16):int((i+1) * note16)]\n","    mode_val, mode_num = stats.mode(out, axis=0)\n","    for j in range(len(out)):\n","      for k, fret in enumerate(mode_val[0]):\n","        pre[int(i * note16)+j][k] = fret\n","\n","  for j, strings in enumerate(pre):\n","    for k, fret in enumerate(strings):\n","      reprs[i*128+j][k][fret] = 1\n","reprs = np.array(reprs)\n","\n","print(reprs.shape, labels.shape)\n","for i in results:\n","  print(i + str(np.average(results[i])))\n","\n","for rp, lb in zip(reprs, labels):\n","  im = Image.new('RGB', (500, 350), (255, 255, 255))\n","  draw = ImageDraw.Draw(im)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            if k_pr == k_lb:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            else:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  im = plt.imshow(np.array(im))\n","  \n","  ims.append([im])\n","\n","ani = animation.ArtistAnimation(fig, ims, interval=23)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"_jZHateh_JPB","executionInfo":{"status":"error","timestamp":1656112449364,"user_tz":-540,"elapsed":609,"user":{"displayName":"別宮広朗","userId":"05400009959039077885"}},"outputId":"dee2dd7f-62ab-401a-9f5c-4a11555f210a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/gozu/2021/MyTabCNN/data/spec_repr/c/00_BN1-129-Eb_comp.npz\n","129\n","(962, 6, 21) (962, 192)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-a99e589bf580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_f_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-897c881e53ac>\u001b[0m in \u001b[0;36mpitch_precision\u001b[0;34m(pred, gt)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpitch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab2pitch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpitch_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab2pitch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpitch_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (128,44) (0,) "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":576,"status":"error","timestamp":1655814554644,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"outputId":"c5f1b231-4698-410d-dd82-2fd73d3c2e68","id":"FxdxJeYnO9di"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1103, 6, 21) (1103, 192)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a0f4099eda24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-60f1d14be470>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m#print(x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x279744 and 5952x128)"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}],"source":["#%matplotlib nbagg\n","\n","anno_path = \"/content/drive/MyDrive/lab/2021/MyTabCNN/data/spec_repr/c/00_Jazz3-150-C_comp.npz\"\n","load = np.load(anno_path)\n","label = load[\"labels\"]\n","repr = load[\"repr\"]\n","print(label.shape, repr.shape)\n","\n","fig = plt.figure()\n","\n","ims = []\n","\n","labels = label[:len(label)//128*128]\n","\n","repr = np.pad(repr, [(50,50), (0,0)], mode = \"constant\")\n","input_data = []\n","for i in range(len(repr)-99):\n","  input_data.append(repr[i:i+100])\n","repr = np.transpose(np.expand_dims(np.swapaxes(input_data, 0, 1), -1), (1,3,2,0))\n","input = []\n","for i in range(len(repr)//128):\n","  input.append(repr[i*128:(i+1)*128])\n","input_data = np.array(input)\n","reprs = np.zeros(((len(repr)//128*128, 6, 21)))\n","\n","results = {}\n","results[\"pp\"] = []\n","results[\"pr\"] = []\n","results[\"pf\"] = []\n","results[\"tp\"] = []\n","results[\"tr\"] = []\n","results[\"tf\"] = []\n","\n","for i in range(len(repr)//128):\n","  images = torch.tensor(input_data[i], dtype=torch.float32, device=\"cuda\")\n","  outputs = net(images)\n","\n","  _, pre = torch.max(outputs.data, 2)\n","  label = labels[i*128:(i+1)*128]\n","  gt = np.argmax(label, 2)\n","  results[\"pp\"].append(pitch_precision(pre,gt))\n","  results[\"pr\"].append(pitch_recall(pre,gt))\n","  results[\"pf\"].append(pitch_f_measure(pre,gt))\n","  results[\"tp\"].append(tab_precision(pre,gt))\n","  results[\"tr\"].append(tab_recall(pre,gt))\n","  results[\"tf\"].append(tab_f_measure(pre,gt))\n","\n","  _, predicted = torch.max(outputs.data, 2)\n","  for j, strings in enumerate(predicted):\n","    for k, fret in enumerate(strings):\n","      reprs[i*128+j][k][fret] = 1\n","reprs = np.array(reprs)\n","\n","print(reprs.shape, labels.shape)\n","for i in results:\n","  print(i + str(np.average(results[i])))\n","\n","for rp, lb in zip(reprs, labels):\n","  im = Image.new('RGB', (500, 350), (255, 255, 255))\n","  draw = ImageDraw.Draw(im)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for j in range(6):\n","    draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","  for j in range(20):\n","    draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","  for string, (j_pr, j_lb) in enumerate(zip(rp, lb)):\n","    for fret, (k_pr, k_lb) in enumerate(zip(j_pr, j_lb)):\n","      if not fret == 0:\n","          if k_pr == 1:\n","            draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","          if k_lb == 1:\n","            if k_pr == k_lb:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 255))\n","            else:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(0, 0, 255))\n","\n","  im = plt.imshow(np.array(im))\n","  \n","  ims.append([im])\n","\n","ani = animation.ArtistAnimation(fig, ims, interval=23)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76,"output_embedded_package_id":"1ONvp6CFTcONrOn2V3KpUScz3nH3cTGwG"},"executionInfo":{"elapsed":10740,"status":"ok","timestamp":1655109978392,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"bfE9Op5R9FJI","outputId":"cd4ed398-0aaa-4b4f-eb42-95643873036b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["audio_path = \"/content/drive/MyDrive/lab/2021/MyTabCNN/data/GuitarSet/audio/audio_mic/00_Jazz3-150-C_comp_mic.wav\"\n","IPython.display.Audio(audio_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4485,"status":"ok","timestamp":1653473699699,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"3YbU1L6kU5p5","outputId":"e1cb808c-c8ed-4600-ce62-3b66bb3a93d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","Building wheels for collected packages: ffmpeg\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=1c171cef76bda50246777bb6df86cd038ee5099bc346a7c0d517e304f55258ec\n","  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n","Successfully built ffmpeg\n","Installing collected packages: ffmpeg\n","Successfully installed ffmpeg-1.4\n"]}],"source":["!pip install ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":762,"status":"ok","timestamp":1655106899493,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"gcw7o1KNkoMf","outputId":"013f2ea3-6b79-4ff6-e800-998f48315695"},"outputs":[{"data":{"text/plain":["MyCNN(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (drop1): Dropout2d(p=0.25, inplace=False)\n","  (drop2): Dropout(p=0.5, inplace=False)\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=5952, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=126, bias=True)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["net: MyCNN = MyCNN()\n","net= torch.load(\"/content/drive/MyDrive/lab/2021/MyTabCNN/model/mytabcnn-model.path\",map_location='cuda:0')\n","net.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425,"output_embedded_package_id":"1J3G-OzEBuVKh_rM4C3SwjVgCa2s0_JDR"},"executionInfo":{"elapsed":102329,"status":"ok","timestamp":1655107149475,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"d0jIDET4rfSi","outputId":"e1f289e9-2671-4aef-bf2d-54bbecd0d9c9"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#%matplotlib nbagg\n","data = load[\"repr\"]\n","print(data.shape)\n","fig = plt.figure()\n","ims2 = []\n","data = np.pad(data, [(4,4), (0,0)], mode = \"constant\")\n","input_data = []\n","for i in range(len(data)-8):\n","  input_data.append(data[i:i+9])\n","data = np.transpose(np.expand_dims(np.swapaxes(input_data, 0, 1), -1), (1,3,2,0))\n","input = []\n","print(data.shape)\n","for i in range(len(data)//128):\n","  input.append(data[i*128:(i+1)*128])\n","input_data = np.array(input)\n","for i in range(len(data)//128):\n","  images = torch.tensor(input_data[i], dtype=torch.float32, device=\"cuda\")\n","  outputs = net(images)\n","  _, predicted = torch.max(outputs.data, 2)\n","  data = np.zeros(((128, 6, 21)))\n","  for i, strings in enumerate(predicted):\n","    for j, fret in enumerate(strings):\n","      data[i][j][fret] = 1\n","  #print(data[0])\n","\n","  for i in data:\n","    im = Image.new('RGB', (500, 350), (255, 255, 255))\n","    draw = ImageDraw.Draw(im)\n","\n","    for j in range(6):\n","      draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","    for j in range(20):\n","      draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","    for string, j in enumerate(i):\n","      for fret, k in enumerate(j):\n","        if not fret == 0:\n","            if k == 1:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","    im = plt.imshow(np.array(im))\n","      \n","    ims2.append([im])\n","  \n","ani = animation.ArtistAnimation(fig, ims2, interval=23)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554,"output_embedded_package_id":"1FirSYKjCFsHLJGBL4TW-1laj6FkVBEhU"},"executionInfo":{"elapsed":133369,"status":"ok","timestamp":1653641313788,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"JPIMWNjyfyp_","outputId":"1ef3a169-cb5e-43f2-c153-e12d9e1e610c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#%matplotlib nbagg\n","training_generator, validation_generator, partitionv = partition_data(0)\n","fig = plt.figure()\n","ims2 = []\n","for h in range(9):\n","  input_data = validation_generator[h]\n","  images = torch.tensor(np.transpose(input_data[0], (0,3,1,2)), dtype=torch.float32)\n","  print(images.dtype)\n","  outputs = net(images)\n","  _, predicted = torch.max(outputs.data, 2)\n","  data = np.zeros(((128, 6, 21)))\n","  for i, strings in enumerate(predicted):\n","    for j, fret in enumerate(strings):\n","      data[i][j][fret] = 1\n","  #print(data[0])\n","\n","  for i in data:\n","    im = Image.new('RGB', (500, 350), (255, 255, 255))\n","    draw = ImageDraw.Draw(im)\n","\n","    for j in range(6):\n","      draw.line(((23, (j+1) * 50), (480, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","    for j in range(20):\n","      draw.line((((j+1) * 23, 50), ((j+1) * 23, 300)), fill=(0, 0, 0), width=2)\n","\n","    for string, j in enumerate(i):\n","      for fret, k in enumerate(j):\n","        if not fret == 0:\n","            if k == 1:\n","              draw.pieslice(((-17 + fret*23, 45 + (5-string)*50), (-7 + fret*23, 55 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","    im = plt.imshow(np.array(im))\n","    \n","    ims2.append([im])\n","\n","ani = animation.ArtistAnimation(fig, ims2, interval=)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VF_dXelgy8P"},"outputs":[],"source":["from scipy.io import wavfile\n","import librosa\n","from librosa import display\n","\n","class AudioDataGenerator:\n","  def __init__(self, path, mode=\"c\"):\n","    self.path = path\n","\n","    # prepresentation and its labels storage\n","    self.output = {}\n","\n","    self.preproc_mode = mode\n","    self.downsample = True\n","    self.normalize = True\n","    self.sr_downs = 22050\n","\n","    # CQT parameters\n","    self.cqt_n_bins = 192\n","    self.cqt_bins_per_octave = 24\n","\n","    # STFT parameters\n","    self.n_fft = 2048\n","    self.hop_length = 512\n","\n","  def load_audiodata(self):\n","    file_path = self.path\n","    file_audio = file_path\n","    self.sr_original, data = wavfile.read(file_audio)\n","    self.sr_curr = self.sr_original\n","\n","    # preprocess audio, store in output dict\n","    self.output[\"repr\"] = np.swapaxes(self.preprocess_audio(data),0,1)\n","\n","    # construct labels\n","    frame_indices = range(len(self.output[\"repr\"]))\n","    times = librosa.frames_to_time(frame_indices, sr = self.sr_curr, hop_length=self.hop_length)\n","\n","    labels = np.zeros(((128, 6 ,21)))\n","    # store and return\n","    self.output[\"labels\"] = labels\n","    print(np.shape(self.output[\"repr\"]))\n","    print(np.shape(self.output[\"labels\"]))\n","    return self.output\n","\n","  def preprocess_audio(self, data):\n","      data = data.astype(float)\n","      if self.normalize:\n","          data = librosa.util.normalize(data)\n","      if self.downsample:\n","          data = librosa.resample(data, self.sr_original, self.sr_downs)\n","          self.sr_curr = self.sr_downs\n","      if self.preproc_mode == \"c\":\n","          data = np.abs(librosa.cqt(data,\n","              hop_length=self.hop_length, \n","              sr=self.sr_curr, \n","              n_bins=self.cqt_n_bins, \n","              bins_per_octave=self.cqt_bins_per_octave))\n","          cqt_amplitude = data\n","          fig = plt.figure()\n","          ax = fig.add_subplot()\n","          librosa.display.specshow(librosa.amplitude_to_db(cqt_amplitude, ref=np.max), sr=self.sr_curr, x_axis='time', y_axis='cqt_hz')\n","          plt.colorbar(format='%+2.0f dB')\n","          ax.set_title('constant-Q power spectrum')\n","          plt.tight_layout()\n","          plt.show()\n","    \n","      elif self.preproc_mode == \"m\":\n","          data = librosa.feature.melspectrogram(y=data, sr=self.sr_curr, n_fft=self.n_fft, hop_length=self.hop_length)\n","      elif self.preproc_mode == \"cm\":\n","          cqt = np.abs(librosa.cqt(data, \n","              hop_length=self.hop_length, \n","              sr=self.sr_curr, \n","              n_bins=self.cqt_n_bins, \n","              bins_per_octave=self.cqt_bins_per_octave))\n","          mel = librosa.feature.melspectrogram(y=data, sr=self.sr_curr, n_fft=self.n_fft, hop_length=self.hop_length)\n","          data = np.concatenate((cqt,mel),axis = 0)\n","      elif self.preproc_mode == \"s\":\n","          data = np.abs(librosa.stft(data, n_fft=self.n_fft, hop_length=self.hop_length))\n","      else:\n","          print (\"invalid representation mode.\")\n","      print(np.shape(data))\n","\n","      return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvT00EGu0g_4"},"outputs":[],"source":["class DataGenerator2():\n","    \n","    def __init__(self, data, batch_size=128, shuffle=False, label_dim = (6,21), spec_repr=\"c\", con_win_size=9):\n","        \n","        self.list_IDs = np.arange(len(data[\"repr\"]))\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.label_dim = label_dim\n","        self.spec_repr = spec_repr\n","        self.con_win_size = con_win_size\n","        self.halfwin = con_win_size // 2\n","        \n","        if self.spec_repr == \"c\":\n","            self.X_dim = (self.batch_size, 192, self.con_win_size, 1)\n","        elif self.spec_repr == \"m\":\n","            self.X_dim = (self.batch_size, 128, self.con_win_size, 1)\n","        elif self.spec_repr == \"cm\":\n","            self.X_dim = (self.batch_size, 320, self.con_win_size, 1)\n","        elif self.spec_repr == \"s\":\n","            self.X_dim = (self.batch_size, 1025, self.con_win_size, 1)\n","            \n","        self.y_dim = (self.batch_size, self.label_dim[0], self.label_dim[1])\n","        \n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # number of batches per epoch\n","        return int(np.floor(float(len(self.data[\"repr\"])) / self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        # generate indices of the batch(バッチごとのインデクス)\n","        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n","        \n","        # find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        \n","        # generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","        \n","        return X, y\n","    \n","    def on_epoch_end(self):\n","        # Updates indexes after each epoch\n","        self.indexes = np.arange(len(self.data[\"repr\"]))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self, list_IDs_temp):\n","        #Generates data containing batch_size samples\n","        # X : (n_samples, *dim, n_channels)\n","        \n","        # Initialization\n","        X = np.empty(self.X_dim)\n","        y = np.empty(self.y_dim)\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            # determine filename\n","            frame_idx = ID\n","            #print(i, ID)\n","            \n","            # load a context window centered around the frame index\n","            loaded = self.data\n","            full_x = np.pad(loaded[\"repr\"], [(self.halfwin,self.halfwin), (0,0)], mode='constant')\n","            sample_x = full_x[frame_idx : frame_idx + self.con_win_size]\n","            X[i,] = np.expand_dims(np.swapaxes(sample_x, 0, 1), -1)\n","\n","            # Store label\n","            y[i,] = loaded[\"labels\"][0]\n","\n","        return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1591,"status":"error","timestamp":1648672560674,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"GqeAf-U_XVGS","outputId":"6ece6cdb-48ba-44a3-dca6-c0c9fdfe987b"},"outputs":[{"ename":"ParameterError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParameterError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-67e247103d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/lab/2021/MyTabCNN/data/my_test_audio/WIN_20220331_03_10_44_Pro.wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_audiodata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-713f176546f4>\u001b[0m in \u001b[0;36mload_audiodata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# preprocess audio, store in output dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"repr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# construct labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-713f176546f4>\u001b[0m in \u001b[0;36mpreprocess_audio\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m               \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr_curr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m               \u001b[0mn_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcqt_n_bins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m               bins_per_octave=self.cqt_bins_per_octave))\n\u001b[0m\u001b[1;32m     58\u001b[0m           \u001b[0mcqt_amplitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py\u001b[0m in \u001b[0;36mcqt\u001b[0;34m(y, sr, hop_length, fmin, n_bins, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mpad_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py\u001b[0m in \u001b[0;36mvqt\u001b[0;34m(y, sr, hop_length, fmin, n_bins, gamma, bins_per_octave, tuning, filter_scale, norm, sparsity, window, scale, pad_mode, res_type, dtype)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;31m# Compute the vqt filter response and append to the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         vqt_resp.append(\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0m__cqt_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_hop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         )\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/constantq.py\u001b[0m in \u001b[0;36m__cqt_response\u001b[0;34m(y, n_fft, hop_length, fft_basis, mode, dtype)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;31m# Compute the STFT matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     D = stft(\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ones\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m     )\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;31m# Check audio is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# Pad the time series so that frames are centered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/util/utils.py\u001b[0m in \u001b[0;36mvalid_audio\u001b[0;34m(y, mono)\u001b[0m\n\u001b[1;32m    293\u001b[0m         raise ParameterError(\n\u001b[1;32m    294\u001b[0m             \u001b[0;34m\"Invalid shape for monophonic audio: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0;34m\"ndim={:d}, shape={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mParameterError\u001b[0m: Invalid shape for monophonic audio: ndim=2, shape=(804864, 1)"]}],"source":["audio_path = \"/content/drive/MyDrive/lab/2021/MyTabCNN/data/my_test_audio/WIN_20220331_03_10_44_Pro.wav\"\n","gen = AudioDataGenerator(path = audio_path, mode=\"c\")\n","validation = gen.load_audiodata()\n","IPython.display.Audio(audio_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387,"output_embedded_package_id":"18zqTzIyAi1nkPbALNfjFXupwC9fWJ_AE"},"executionInfo":{"elapsed":145674,"status":"ok","timestamp":1648637968109,"user":{"displayName":"五頭健太郎","userId":"10164916516000345785"},"user_tz":-540},"id":"4jkGvJ7OgGqc","outputId":"2d5ca1ea-f485-4858-f5a9-dad41da4d889"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["fig = plt.figure()\n","my_validation = DataGenerator2(validation)\n","ims3 = []\n","for h in range(9):\n","  input_data = my_validation[h]\n","  images = torch.Tensor(np.transpose(input_data[0], (0,3,1,2)))\n","  outputs = net(images)\n","  _, predicted = torch.max(outputs.data, 2)\n","  data = np.zeros(((128, 6, 21)))\n","  for i, strings in enumerate(predicted):\n","    for j, fret in enumerate(strings):\n","      data[i][j][fret] = 1\n","  #print(data[0])\n","\n","  for i in data:\n","    im = Image.new('RGB', (1000, 350), (255, 255, 255))\n","    draw = ImageDraw.Draw(im)\n","\n","    for j in range(6):\n","      draw.line(((92, (j+1) * 50), (1800, (j+1) * 50)), fill=(0, 0, 0), width=2)\n","    for j in range(10):\n","      draw.line((((j+1) * 92, 50), ((j+1) * 92, 300)), fill=(0, 0, 0), width=2)\n","\n","    for string, j in enumerate(i):\n","      for fret, k in enumerate(j):\n","        if fret <= 9:\n","          if not fret == 0:\n","            if k == 1:\n","              draw.pieslice(((-68 + fret*92, 30 + (5-string)*50), (-28 + fret*92, 70 + (5-string)*50)), start=0, end=360, fill=(255, 0, 0))\n","    im = plt.imshow(np.array(im))\n","    \n","    ims3.append([im])\n","\n","ani = animation.ArtistAnimation(fig, ims3, interval=20)\n","rc('animation', html='jshtml')\n","plt.close()\n","ani"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgGO3bAxVEqH"},"outputs":[],"source":["ani.save(\"/content/drive/MyDrive/lab/2021/MyTabCNN/data/my_test_audio/\" + os.path.splitext(os.path.basename(audio_path))[0]+\".mp4\", writer=\"ffmpeg\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"bekkuDataGenerator.ipynb","provenance":[]},"interpreter":{"hash":"ee2652462c3ef076369cbdf09a6715f1a7d8c5fa11cbe58a9308975a5bb1304d"},"kernelspec":{"display_name":"Python 3.9.9 64-bit (windows store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}